{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\npd.set_option('display.max_columns', 100)\n\n!pip install openpyxl\n\ndata_2021 = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2021 = data_2021.iloc[0, :].T\ndata_2021 = data_2021.iloc[1:, :]\ndata_2020 = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2020 = data_2020.iloc[0, :].T\ndata_2020 = data_2020.iloc[1:, :]\ndata_2019 = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2019 = data_2019.iloc[0, :].T\ndata_2019 = data_2019.iloc[1:, :]\ndata_2018 = pd.read_csv('../input/kaggle-survey-2018/multipleChoiceResponses.csv', low_memory = False, encoding='UTF-8')\nquestions_2018 = data_2018.iloc[0, :].T\ndata_2018 = data_2018.iloc[1:, :]\ndata_2017 = pd.read_csv('../input/kaggle-survey-2017/multipleChoiceResponses.csv', low_memory = False, encoding='ISO-8859-1')\nquestions_2017 = data_2017.iloc[0, :].T\ndata_2017 = data_2017.iloc[1:, :]\n\nnvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\ncloud_earnings = pd.read_excel('../input/3-tech-cloud-earnings/cloud.xlsx')\n# 2021 Yes. 2020 Yes. 2019 Yes. About TPUs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-04T01:51:22.041138Z","iopub.execute_input":"2021-11-04T01:51:22.041857Z","iopub.status.idle":"2021-11-04T01:51:39.249259Z","shell.execute_reply.started":"2021-11-04T01:51:22.041817Z","shell.execute_reply":"2021-11-04T01:51:39.248367Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"nvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\nnvda_earnings = nvda_earnings.rename(columns = {'Unnamed: 0': 'Revenue'})\nnvda_earnings","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:39.250992Z","iopub.execute_input":"2021-11-04T01:51:39.251255Z","iopub.status.idle":"2021-11-04T01:51:39.290921Z","shell.execute_reply.started":"2021-11-04T01:51:39.251224Z","shell.execute_reply":"2021-11-04T01:51:39.290143Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = nvda_earnings.T\ndf.columns = df.iloc[0]\ndf = df.drop(df.index[0])\ndf.drop('Total', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:39.292094Z","iopub.execute_input":"2021-11-04T01:51:39.292745Z","iopub.status.idle":"2021-11-04T01:51:39.301510Z","shell.execute_reply.started":"2021-11-04T01:51:39.292703Z","shell.execute_reply":"2021-11-04T01:51:39.300738Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as patches\n\nfig, ax = plt.subplots(figsize = (16,8))\ndf.plot(kind = 'bar', stacked=True, ax = ax)\nax.set(title = 'NVIDIA Earnings')\nfor c in ax.containers:\n    ax.bar_label(c, label_type='center')\n\n#for p in ax.patches:\n    #print(p)\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")\n\nplt.annotate('',\nha = 'center', va = 'bottom',\nxytext = (7.8, 1800),\nxy = (12.3, 3800),\narrowprops = { 'facecolor' : 'red', 'shrink' : 0.05 })\n\nplt.annotate('Data Center Revenue Explosion Begins',\n        fontsize = 14,\n        ha = 'center', va = 'bottom',\n        xytext = (8, 5000),\n        xy = (8, 3200),\n        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.05 })\n\n\nplt.annotate('Data Center revenue growth 100% YoY in 2020', xytext = (3, 6000), xy = (8, 6000), fontsize = 22, color = 'red', )\nplt.axhline(y=3200, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Source: Nvidia', (0,0), (-80,-80), fontsize=8, \n             xycoords='axes fraction', textcoords='offset points', va='top')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:39.302592Z","iopub.execute_input":"2021-11-04T01:51:39.302866Z","iopub.status.idle":"2021-11-04T01:51:40.241949Z","shell.execute_reply.started":"2021-11-04T01:51:39.302832Z","shell.execute_reply":"2021-11-04T01:51:40.241094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cloud_earnings.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:40.244552Z","iopub.execute_input":"2021-11-04T01:51:40.245022Z","iopub.status.idle":"2021-11-04T01:51:40.260051Z","shell.execute_reply.started":"2021-11-04T01:51:40.244980Z","shell.execute_reply":"2021-11-04T01:51:40.259231Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_colwidth\n\ndata_center_segment = nvda_earnings.iloc[[2]]\ndata_center_segment = data_center_segment.set_index(['Revenue'])\ndata_center_aws =  data_center_segment.copy() * 0.31\ndata_center_aws = data_center_aws.rename(index = {'data center': 'Aws'})\n\ndata_center_azure = data_center_segment.copy() * 0.22\ndata_center_azure = data_center_azure.rename(index = {'data center': 'Azure'})\n\ndata_center_gcp = data_center_segment.copy() * 0.08\ndata_center_gcp = data_center_gcp.rename(index = {'data center': 'GCP'})\n\ndata_center_others = data_center_segment.copy() * 0.39\ndata_center_others = data_center_others.rename(index = {'data center': 'Others'})\n\ndf = pd.concat([data_center_aws, data_center_azure, data_center_gcp, data_center_others])\ndf.iloc[2, 0] = 0\ndf.iloc[2, 1] = 0\ndf.iloc[2, 2] = 0 \ndf = df.T\n\nfig, ax = plt.subplots(figsize = (16,8))\n\ndf.plot(kind = 'bar', ax = ax)\nplt.axvline(x=2.5, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Google disclosed GCP as of 2019', xytext = (2.6, 600), xy = (8, 600), fontsize = 14, color = 'black' )\nax.set(title = \"Estimated Nvidia' data center revenue from the big 3\")\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:40.261090Z","iopub.execute_input":"2021-11-04T01:51:40.261300Z","iopub.status.idle":"2021-11-04T01:51:40.699485Z","shell.execute_reply.started":"2021-11-04T01:51:40.261275Z","shell.execute_reply":"2021-11-04T01:51:40.698672Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n<div class=\"alert alert-warning\">\n  <strong>Note: </strong> For all charts in this module, I only selected working Professionals.\n</div>\n</div>\n\n<br>\n<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\nNon-professionals were defined as those who answered Job Title as either: \n<ul>\n<li>Student</li>\n<li>Currently not employed</li>\n<li>Who didn't answer the question (NaN)</li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"def get_professionals(data, column):\n    data = data.loc[data[column] != 'Student']\n    data = data.loc[data[column] != 'Currently not employed']\n    data = data.loc[data[column] != 'Not employed']\n    data = data.loc[data[column].notna()]\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:40.700726Z","iopub.execute_input":"2021-11-04T01:51:40.701150Z","iopub.status.idle":"2021-11-04T01:51:40.706135Z","shell.execute_reply.started":"2021-11-04T01:51:40.701120Z","shell.execute_reply":"2021-11-04T01:51:40.705139Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1: Data Science Professionals distribution by industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# Exhibit 1. Data Science Professionals distribution by industry 2018 vs. 2021\n\n# Get data from 2021\n\nindustry_2021 = data_2021[data_2021['Q20'].notna()]\nc = industry_2021['Q20'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#c =industry_2021['Q20'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# Get data from 2018\n\nindustry_2018 = data_2018[data_2018['Q7'] != 'I am a student']\nindustry_2018 = industry_2018[industry_2018['Q7'].notna()]\nd = industry_2018['Q7'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#d = industry_2018['Q7'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# compute the industry\n\nk = pd.merge(left = d, right = c, on = 'industry')\nk = k.rename(columns = {'counts_x': '2018', 'counts_y': '2021'})\nk = k.sort_values(by=['2021'], ascending=False)\n\n# compute the difference\ndiff_industry = k.copy()\ndiff_industry['dff'] = k['2021'] - k['2018']\n\n# plot\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \nax1 = plt.subplot(gs[0])\n\nk.plot.barh(x = \"industry\", ax= ax1)\n#ax.grid(False)\nax1.set(title = \"Data Science professionals distribution by Industry. 2018 vs 2021\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax1.invert_yaxis()\n\nax2 = plt.subplot(gs[1])\ndiff_industry['dff'].plot(kind='barh', x = 'industry', ax = ax2,\n                    color=(diff_industry['dff'] > 0).map({True: 'g',\n                                                    False: 'r'}))\nax2.set(title = \"Change\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax2.set_yticks([])\n\nplt.gca().invert_yaxis()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-04T01:51:40.707526Z","iopub.execute_input":"2021-11-04T01:51:40.707889Z","iopub.status.idle":"2021-11-04T01:51:41.552281Z","shell.execute_reply.started":"2021-11-04T01:51:40.707847Z","shell.execute_reply":"2021-11-04T01:51:41.551644Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n\n<ul>\n<li> Computer/Technology field is no longer the only game in town. It declined <strong>7.5%</strong></li>\n\n<li> Academic/Education industry gained <strong>3%</strong></li>\n<li> Manufactruing industry gained <strong>2%</strong></li>\n\n<li> A sign that Data Science is <strong>spreading into all over the industry</strong>. </li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"code","source":"# ----------------\n# Job title filter\n# ----------------\n\njob_title = {'Other':'Other',\n     'Product Manager': 'Product/Project Manager',\n 'Program/Project Manager':'Product/Project Manager',\n 'Principal Investigator':'Product/Project Manager',\n 'Chief Officer':'Product/Project Manager',\n 'Manager':'Product/Project Manager',\n 'Software Developer/Software Engineer': 'Software Engineer',\n 'Operations Research Practitioner': 'Research Scientist',\n 'Computer Scientist': 'Research Scientist',\n 'Scientist/Researcher': 'Research Scientist',\n 'Researcher': 'Research Scientist',\n 'Data Scientist': 'Data Scientist',\n     'Business Analyst': 'Business Analyst',\n     'Engineer': 'Other',\n     'DBA/Database Engineer': 'DBA/Database Engineer',\n     'Data Analyst':'Data Analyst',\n     'Machine Learning Engineer': 'Machine Learning Engineer',\n     'Statistician':'Statistician',\n     'Predictive Modeler':'Research Scientist',\n     'Programmer': 'Software Engineer',\n     'Data Miner': 'Data Engineer',\n     'Consultant': 'Other',\n     'Research Assistant': 'Research Scientist',\n     'Chief Officer':'Product/Project Manager',\n     'Data Engineer':'Data Engineer',\n     'Developer Advocate': 'Developer Relations/Advocacy',\n     'Marketing Analyst': 'Business Analyst',\n     'Data Analyst': 'Data Analyst',\n     'Software Engineer': 'Software Engineer',\n     'Research Scientist': 'Research Scientist',\n     'Data Journalist': 'Data Analyst',\n     'Salesperson':'Developer Relations/Advocacy',\n     'Product/Project Manager': 'Product/Project Manager',\n     'Developer Relations/Advocacy': 'Developer Relations/Advocacy'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:41.553282Z","iopub.execute_input":"2021-11-04T01:51:41.553645Z","iopub.status.idle":"2021-11-04T01:51:41.560012Z","shell.execute_reply.started":"2021-11-04T01:51:41.553613Z","shell.execute_reply":"2021-11-04T01:51:41.559235Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1.1: Data Science Professional roles in different industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# cheat\npd.options.mode.chained_assignment = None \n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nworkforce_2021 = get_professionals(data_2021, 'Q5')\nprofessional_2021 = workforce_2021[workforce_2021['Q20'].notna()]\nprofessional_2021['Q5'] = professional_2021['Q5'].map(job_title)\nindustry_2021 = professional_2021['Q20'].unique()\ndf_2021 = professional_2021[['Q5','Q20']]\n\ntemp_d = {}\n\nfor industry in industry_2021:\n    temp_df = df_2021[df_2021['Q20'] == industry]\n    temp_dict = dict(temp_df['Q5'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2021 = {}\n\nh_lst = list(k['industry'])\n\nfor i in h_lst:\n    d_2021[i] = temp_d[i]\n\ndf_industry_2021 = pd.DataFrame.from_dict(d_2021, orient='index')\ndf_industry_2021.fillna(0, inplace = True)\ndf_industry_2021 = df_industry_2021.sort_values(by=df_industry_2021.index[0], ascending=False, axis=1)\ndf_industry_2021\n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nstudent_2018 = data_2018.loc[data_2018['Q7'] == 'I am a student']\nworkforce_2018 = data_2018.loc[data_2018['Q7'] != 'I am a student']\n\nprofessional_2018 = workforce_2018[workforce_2018['Q7'].notna()]\nprofessional_2018['Q6'] = professional_2018['Q6'].map(job_title)\n\nindustry_2018 = professional_2018['Q7'].unique()\n\ndf_2018 = professional_2018[['Q6','Q7']]\n\ntemp_d = {}\n\nfor industry in industry_2018:\n    temp_df = df_2018[df_2018['Q7'] == industry]\n    temp_dict = dict(temp_df['Q6'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2018 = {}\n\nfor i in h_lst:\n    d_2018[i] = temp_d[i]\n\ndf_industry_2018 = pd.DataFrame.from_dict(d_2018, orient='index')\ndf_industry_2018.fillna(0, inplace = True)\ndf_industry_2018 = df_industry_2018.sort_values(by=df_industry_2018.index[0], ascending=False, axis=1)\n#df_industry_2018\n\n# ---------------\n#  SUBPLOTS - 1x2\n# ---------------\n\nfig = plt.figure(figsize=(22,10))\n\nplt.subplot(121)   #  subplot 1\nplt.title('2018 heatmap')\nsns.heatmap(df_industry_2018, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(122)   #  subplot 2\nplt.title('2021 heatmap')\nsns.heatmap(df_industry_2021, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:41.561246Z","iopub.execute_input":"2021-11-04T01:51:41.561682Z","iopub.status.idle":"2021-11-04T01:51:44.746000Z","shell.execute_reply.started":"2021-11-04T01:51:41.561652Z","shell.execute_reply":"2021-11-04T01:51:44.745407Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Machine Learning Engineer role is added in 2021. The Heatmap suggests that the large portion of data scientist and software engineer moved to machine learning engineer.</li>\n    <li>According to <a href=\"https://www.snowflake.com/trending/machine-learning-engineer-vs-data-scientist\">Snowflake</a>, A machine learning engineer will focus on writing code and deploying machine learning products.</li>\n    \n<li>Decline in Research Scientist roles in Computer/Tech and Academic fields.</li>\n<li>A sign that the data science industry is <strong>shifting from research oriented to profit oriented business.</strong> </li>\n</ul>\n</div>\n\n","metadata":{}},{"cell_type":"code","source":"# Exhibit 1.1 Data Science distribution by company size 2021.\n\ntest = get_professionals(data_2021, 'Q5')\n#print(len(test))\ntest = test[test['Q21'].notna()]\n#print(len(test))\n\ncategory_test = test.groupby(['Q20', 'Q21']).size()\n#category_test.plot(kind='bar')\nnew_df = category_test.to_frame(name = 'size').reset_index()\nnew_df_2= pd.pivot(\n    data = new_df,\n    index = 'Q20',\n    columns = 'Q21',\n    values = 'size')\nnew_df_2.index.names = ['Industry']\nnew_df_2.columns.names = ['Company Size']\n\ncolumns_order = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees','10,000 or more employees']\n\nnew_df_2 = new_df_2.reindex(columns = columns_order)\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns='total')\n\n# -----\n\n\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns = 'total')\nres = new_df_2.div(new_df_2.sum(axis=1), axis = 0)\nres\n\n# -----\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n\nax1 = plt.subplot(gs[0])\n\nnew_df_2.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax1,\n              )\n\nax1.set(title = \"DS professional distibution by company size across different industry 2021\",\n      xlabel = \"Counts\",\n      ylabel = \"Industry\")\n\n\nax2 = plt.subplot(gs[1])\n\nres.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax2,\n              )\n\nax2.set(title='Company Size portion within industry',\n      xlabel = \"Percentage\",\n      ylabel = \" \")\n\nplt.legend(title = \"Company Size\", bbox_to_anchor=(1.04,1), loc=\"upper left\")\nax2.set_yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:44.747087Z","iopub.execute_input":"2021-11-04T01:51:44.747407Z","iopub.status.idle":"2021-11-04T01:51:45.957242Z","shell.execute_reply.started":"2021-11-04T01:51:44.747378Z","shell.execute_reply":"2021-11-04T01:51:45.956622Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"(0-49) sized company accounts the most except insurance/Risk industry.\n","metadata":{}},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\n\n# ----------------------------------------------------------------------------------------\n# 2021 (#18 and #19), 2020 (#18 and #19), 2019 (#26 and #27) About Computer vision and NLP\n# ----------------------------------------------------------------------------------------\n\n# ---------------------------------\n# COMPUTER VISION YES OR NO in 2021\n# ---------------------------------\n\nvision = test[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER']]\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nvision = vision.fillna(0)\nvision[vision != 0] = 1\nvision_df = vision[vision==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nvision_df = vision_df.set_index('Algo').T\nstuff_2020 = vision_df\n\nvision['yes'] = vision[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_OTHER']].sum(axis = 1)\nvision['yes'] = vision['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nvision['no'] = (vision['yes'].apply(lambda x: x == 0) | vision['Q18_Part_6'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nvision['Q20'] = test['Q20']\nvision = vision.drop(columns=['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER'])\nvision.replace({False: 0, True: 1}, inplace=True)\nvision_df = vision[vision['yes'] == 1].groupby('Q20').size()\n\ntotal_boss = vision['Q20'].value_counts()\n\nboss = pd.DataFrame(vision_df)\ntotal_boss = pd.DataFrame(total_boss)\nfinal_boss = total_boss.join(boss)\nfinal_boss.rename(columns = {final_boss.columns[0]: 'NO', final_boss.columns[1]: 'YES'}, inplace = True)\n#final_boss\n\n# ---------------------\n# NLP YES OR NO in 2021\n# ---------------------\n\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nnlp = nlp.fillna(0)\nnlp[nlp != 0] = 1\nnlp_df = nlp[nlp==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nnlp_df = nlp_df.set_index('Algo').T\n\nnlp['yes'] = nlp[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_OTHER']].sum(axis = 1)\nnlp['yes'] = nlp['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nnlp['no'] = (nlp['yes'].apply(lambda x: x == 0) | nlp['Q19_Part_5'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nnlp['Q20'] = test['Q20']\nnlp = nlp.drop(columns=['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER'])\nnlp.replace({False: 0, True: 1}, inplace=True)\nnlp_df = nlp[nlp['yes'] == 1].groupby('Q20').size()\n\ntotal_boss2 = nlp['Q20'].value_counts()\n\nboss2 = pd.DataFrame(nlp_df)\ntotal_boss2 = pd.DataFrame(total_boss2)\nfinal_boss2 = total_boss.join(boss2)\nfinal_boss2.rename(columns = {final_boss2.columns[1]: 'hello'}, inplace = True)\n#final_boss2['perc'] = final_boss2['hello'] * 100 / final_boss2['Q20']\nfinal_boss2.rename(columns = {final_boss2.columns[0]: 'NO', final_boss2.columns[1]: 'YES'}, inplace = True)\nfinal_boss2\n\n# --------------- \n#  SUBPLOTS - 1x2\n# ---------------\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(18,11))\n\nplt.subplot(121)   #  subplot 1\nfinal_boss.plot(kind='barh', ax = ax1)\nax1.set(title = \"Computer Vision Yes / No\")\n\nfor i,j in zip(ax1.containers[0], ax1.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(1)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax1.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax1.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nfig.subplots_adjust(wspace=1)\n\nplt.subplot(122)   #  subplot 2\nfinal_boss2.plot(kind='barh', ax = ax2)\nax2.set(title = \"NLP Yes / No\")\n\nfor i,j in zip(ax2.containers[0], ax2.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(2)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax2.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax2.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:45.958404Z","iopub.execute_input":"2021-11-04T01:51:45.958859Z","iopub.status.idle":"2021-11-04T01:51:47.604100Z","shell.execute_reply.started":"2021-11-04T01:51:45.958829Z","shell.execute_reply":"2021-11-04T01:51:47.603269Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# ---------------------\n# ML Algos 2019 to 2021\n# ---------------------\n\n# ----\n# 2021\n# ----\ntest = get_professionals(data_2021, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2021')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2021 = algo_df\n\n# ----\n# 2020\n# ----\n\ntest = get_professionals(data_2020, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2020')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2020 = algo_df\n\n# ----\n# 2019\n# ----\n\nold_colnames = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11', 'Q24_Part_12']\n#new_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11']\n\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\n\n\npd.set_option('display.max_columns', None)\ndata_2019.head()\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\nalgos = data_2019[['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2019')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2019 = algo_df\n\n# ---------------\n# Merge the frame\n# ---------------\n\nalgo_set = stuff_2021.append([stuff_2020, stuff_2019])\nalgo_set = algo_set.T\n\n# --------------\n# Plot the chart\n# --------------\n\nfig, ax1 = plt.subplots(figsize = (16,8))\nalgo_set.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"ML Algo\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:47.605404Z","iopub.execute_input":"2021-11-04T01:51:47.605602Z","iopub.status.idle":"2021-11-04T01:51:48.942682Z","shell.execute_reply.started":"2021-11-04T01:51:47.605578Z","shell.execute_reply":"2021-11-04T01:51:48.941964Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Heatmap of occupation across different industries. Data scientist and software engineer names down notably compare to 2018.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\ntest = test[test['Q26'].notna()]\ntest['Q26'].unique()\n#test = test[test['Q26'] != '$0 ($USD)']\ntest = test.groupby(['Q26', 'Q20']).size()\ndf = test.to_frame(name = 'size').reset_index()\ndf= pd.pivot(\n    data = df,\n    index = 'Q20',\n    columns = 'Q26',\n    values = 'size')\ndf.index.names = ['Industry']\ndf.columns.names = ['Money Spent']\n\n#c = ['$0 ($USD)', '$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\nc = ['$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\ndf = df.reindex(c, axis = 1)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ndf.plot(kind = 'barh', ax = ax1)\nax1.set(title = \"Money Spent on ML or Cloud computing service by industry\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:48.945638Z","iopub.execute_input":"2021-11-04T01:51:48.945853Z","iopub.status.idle":"2021-11-04T01:51:50.116766Z","shell.execute_reply.started":"2021-11-04T01:51:48.945827Z","shell.execute_reply":"2021-11-04T01:51:50.115945Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = {'$0 ($USD)': '$0 ($USD)',\n     '$1-$99': '$1-$99',\n     '$100-$999': '$100-$999',\n     '$1000-$9,999': '$1000-$9,999',\n     '$10,000-$99,999': '$10,000-$99,999',\n     '$100,000 or more ($USD)': '$100,000 or +',\n     '> $100,000 ($USD)': '$100,000 or +',\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:50.117953Z","iopub.execute_input":"2021-11-04T01:51:50.118207Z","iopub.status.idle":"2021-11-04T01:51:50.122610Z","shell.execute_reply.started":"2021-11-04T01:51:50.118153Z","shell.execute_reply":"2021-11-04T01:51:50.121756Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"temp_2021 = get_professionals(data_2021, 'Q5')\n\ntemp_2021 = temp_2021[temp_2021['Q3'] == 'United States of America']\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\n\nfig, ax = plt.subplots(figsize = (16,8))\ndf_2021.plot(kind='bar', ax = ax)\nax.set(title = 'US companies money spent')","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:50.123626Z","iopub.execute_input":"2021-11-04T01:51:50.123829Z","iopub.status.idle":"2021-11-04T01:51:50.887807Z","shell.execute_reply.started":"2021-11-04T01:51:50.123805Z","shell.execute_reply":"2021-11-04T01:51:50.886868Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntemp_2021 = get_professionals(data_2021, 'Q5')\ntemp_2020 = get_professionals(data_2020, 'Q5')\n\n\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\n#data_2019['Q11'] = data_2019['Q11'].map(c)\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\n\nmoney_spent_2020 = temp_2020[temp_2020['Q25'].notna()]\nmoney_spent_2020['Q25'] = money_spent_2020['Q25'].map(c)\nmoney_spent_2020 = money_spent_2020[money_spent_2020['Q25'] != '$0 ($USD)']\n\nmoney_spent_2019 = data_2019[data_2019['Q11'].notna()]\nmoney_spent_2019['Q11'] = money_spent_2019['Q11'].map(c)\n\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\ndf_2020 = pd.DataFrame(money_spent_2020['Q25'].value_counts(), index = row_order)\ndf_2019 = pd.DataFrame(money_spent_2019['Q11'].value_counts(), index = row_order)\n\ndf_final = pd.concat([df_2021, df_2020, df_2019], axis = 1)\ndf_final.rename(columns = {'Q26': '2021', 'Q25': '2020', 'Q11': '2019'}, inplace= True)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ndf_final.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"Money Spent by company size\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:50.889313Z","iopub.execute_input":"2021-11-04T01:51:50.889704Z","iopub.status.idle":"2021-11-04T01:51:52.003933Z","shell.execute_reply.started":"2021-11-04T01:51:50.889662Z","shell.execute_reply":"2021-11-04T01:51:52.003057Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_2021 = get_professionals(data_2021, 'Q5')\n\ntemp_2021 = temp_2021[temp_2021['Q3'] == 'China']\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\n\ndf_2021","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:52.005321Z","iopub.execute_input":"2021-11-04T01:51:52.005949Z","iopub.status.idle":"2021-11-04T01:51:52.359950Z","shell.execute_reply.started":"2021-11-04T01:51:52.005901Z","shell.execute_reply":"2021-11-04T01:51:52.359138Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\ndata_2021['Q3'].value_counts()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-04T01:51:52.361216Z","iopub.execute_input":"2021-11-04T01:51:52.361417Z","iopub.status.idle":"2021-11-04T01:51:52.369928Z","shell.execute_reply.started":"2021-11-04T01:51:52.361394Z","shell.execute_reply":"2021-11-04T01:51:52.369017Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n\n# Which of the following cloud computing platforms do you use on a regular basis? \n# 2021 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\t\n# 2020 Q26_A_Part_1\tQ26_A_Part_2\tQ26_A_Part_3\tQ26_A_Part_4\tQ26_A_Part_5\tQ26_A_Part_6\tQ26_A_Part_7\tQ26_A_Part_8\tQ26_A_Part_9\tQ26_A_Part_10\tQ26_A_Part_11\tQ26_A_OTHER\n# 2019 Q29_Part_1\tQ29_Part_2\tQ29_Part_3\tQ29_Part_4\tQ29_Part_5\tQ29_Part_6\tQ29_Part_7\tQ29_Part_8\tQ29_Part_9\tQ29_Part_10\tQ29_Part_11\tQ29_Part_12\n\n# Do you use any of the following cloud computing products on a regular basis? (Select all that apply)\n# 2021  Q29_A_Part_1\tQ29_A_Part_2\tQ29_A_Part_3\tQ29_A_Part_4\tQ29_A_OTHER\n#Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected the relevant answer choices for Question 27-A (which of the following companies).\n# 2020 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\n# 2019 Q30_Part_1\tQ30_Part_2\tQ30_Part_3\tQ30_Part_4\tQ30_Part_5\tQ30_Part_6\tQ30_Part_7\tQ30_Part_8\tQ30_Part_9\tQ30_Part_10\tQ30_Part_11\n\n# Which of the following automated machine learning tools (or partial AutoML tools) do you use on aregular basis? (Select all that apply)\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\tQ28_A_OTHER\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\tQ32_OTHER_TEXT\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:52.371082Z","iopub.execute_input":"2021-11-04T01:51:52.371358Z","iopub.status.idle":"2021-11-04T01:51:52.379173Z","shell.execute_reply.started":"2021-11-04T01:51:52.371330Z","shell.execute_reply":"2021-11-04T01:51:52.378588Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pros_2021 = get_professionals(data_2021, 'Q5')\npros_2020 = get_professionals(data_2020, 'Q5')\n\npros_2019 = data_2019[data_2019['Q5'].notna()]\npros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\npros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:52.380004Z","iopub.execute_input":"2021-11-04T01:51:52.380647Z","iopub.status.idle":"2021-11-04T01:51:52.992370Z","shell.execute_reply.started":"2021-11-04T01:51:52.380610Z","shell.execute_reply":"2021-11-04T01:51:52.991736Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cloud usage\n\ncloud_2021 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8',\n 'Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_2021 = pros_2021[cloud_2021]\ndf_2021\n\ncount_2021 = pd.Series(df_2021[cloud_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_2021 = pd.DataFrame(count_2021)\ndf_count_2021 = df_count_2021.reset_index()\ndf_count_2021.columns = ['Cloud', 'Counts']\n\n# --------------------------------------------\n\ncloud_2020 = ['Q26_A_Part_1','Q26_A_Part_2','Q26_A_Part_3','Q26_A_Part_4','Q26_A_Part_5','Q26_A_Part_6',\n'Q26_A_Part_7','Q26_A_Part_8','Q26_A_Part_9','Q26_A_Part_10','Q26_A_Part_11','Q26_A_OTHER']\ndf_2020 = pros_2020[cloud_2020]\n\ncount_2020 = pd.Series(df_2020[cloud_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_2020 = pd.DataFrame(count_2020)\ndf_count_2020 = df_count_2020.reset_index()\ndf_count_2020.columns = ['Cloud', 'Counts']\n\n# ----------------------------------------------\n\n\ncloud_2019 = ['Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7',\n              'Q29_Part_8','Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12'] #Q29_OTHER_TEXT\n\ndf_2019 = pros_2019[cloud_2019]\n\ncount_2019 = pd.Series(df_2019[cloud_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_2019 = pd.DataFrame(count_2019)\ndf_count_2019 = df_count_2019.reset_index()\ndf_count_2019.columns = ['Cloud', 'Counts']\ndf_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\ndf_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\ndf_count_2019\n\n\n\n#cloud_2020 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\n#df_2020 = data_2020[]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:52.993333Z","iopub.execute_input":"2021-11-04T01:51:52.994085Z","iopub.status.idle":"2021-11-04T01:51:53.045903Z","shell.execute_reply.started":"2021-11-04T01:51:52.994050Z","shell.execute_reply":"2021-11-04T01:51:53.045308Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#df_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\n#df_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\n#df_count_2019","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.046946Z","iopub.execute_input":"2021-11-04T01:51:53.047275Z","iopub.status.idle":"2021-11-04T01:51:53.050259Z","shell.execute_reply.started":"2021-11-04T01:51:53.047248Z","shell.execute_reply":"2021-11-04T01:51:53.049430Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\ncloud_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_df['Counts'][4] = 451\ncloud_df = cloud_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\ncloud_df","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.051489Z","iopub.execute_input":"2021-11-04T01:51:53.051776Z","iopub.status.idle":"2021-11-04T01:51:53.080052Z","shell.execute_reply.started":"2021-11-04T01:51:53.051749Z","shell.execute_reply":"2021-11-04T01:51:53.079531Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"cloud_df = cloud_df.T\ncloud_df.columns = cloud_df.iloc[0]\ncloud_df = cloud_df.drop(cloud_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_df = cloud_df.iloc[::-1] # reverse ro\ncloud_df\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ncloud_df.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n             )\nax1.set(title = \"Cloud usage by kaggle community\")\n#cloud_df.plot.area(figsize = (18,9))","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.081026Z","iopub.execute_input":"2021-11-04T01:51:53.081332Z","iopub.status.idle":"2021-11-04T01:51:53.504721Z","shell.execute_reply.started":"2021-11-04T01:51:53.081307Z","shell.execute_reply":"2021-11-04T01:51:53.503833Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove\n\nfor_perc = cloud_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n             )\nax1.set(title = \"Cloud market share surveyed from kaggle\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.506221Z","iopub.execute_input":"2021-11-04T01:51:53.506435Z","iopub.status.idle":"2021-11-04T01:51:53.875830Z","shell.execute_reply.started":"2021-11-04T01:51:53.506409Z","shell.execute_reply":"2021-11-04T01:51:53.874596Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Do you use any of the following cloud computing products on a regular basis? (Select all that apply)\n# 2021  Q29_A_Part_1\tQ29_A_Part_2\tQ29_A_Part_3\tQ29_A_Part_4\tQ29_A_OTHER\n#Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected the relevant answer choices for Question 27-A (which of the following companies).\n# 2020 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\n# 2019 Q30_Part_1\tQ30_Part_2\tQ30_Part_3\tQ30_Part_4\tQ30_Part_5\tQ30_Part_6\tQ30_Part_7\tQ30_Part_8\tQ30_Part_9\tQ30_Part_10\tQ30_Part_11\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.876962Z","iopub.execute_input":"2021-11-04T01:51:53.877200Z","iopub.status.idle":"2021-11-04T01:51:53.880884Z","shell.execute_reply.started":"2021-11-04T01:51:53.877149Z","shell.execute_reply":"2021-11-04T01:51:53.880046Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloud_computing_2019 = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_OTHER_TEXT']\ndf_computing_2019 = pros_2019[cloud_computing_2019]\ncount_compute_2019 = pd.Series(df_computing_2019[cloud_computing_2019].squeeze().values.ravel()).value_counts()\n\n#-----------------\ndf_count_compute_2019 = pd.DataFrame(count_compute_2019)\ndf_count_compute_2019 = df_count_compute_2019.reset_index()\ndf_count_compute_2019.columns = ['Cloud Compute', 'Counts']\n#------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].str.strip()\ndf_count_compute_2019 = df_count_compute_2019[(df_count_compute_2019['Cloud Compute'] == 'AWS Elastic Compute Cloud (EC2)') |\n                      (df_count_compute_2019['Cloud Compute'] == 'Google Compute Engine (GCE)') |\n                     (df_count_compute_2019['Cloud Compute'] == 'Azure Virtual Machines') |\n                     (df_count_compute_2019['Cloud Compute'] == 'None')\n                                             ]\n#----------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].replace({\n                                                'AWS Elastic Compute Cloud (EC2)': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Compute Engine (GCE)': 'Google Cloud Compute Engine',\n                                                'Azure Virtual Machines': 'Microsoft Azure Virtual Machines',\n                                                'None': 'No / None'\n                                               })\n\n\n\ncloud_computing_2020 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8','Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_computing_2020 = pros_2020[cloud_computing_2020]\ncount_compute_2020 = pd.Series(df_computing_2020[cloud_computing_2020].squeeze().values.ravel()).value_counts()\n#------------\ndf_count_compute_2020 = pd.DataFrame(count_compute_2020)\ndf_count_compute_2020 = df_count_compute_2020.reset_index()\ndf_count_compute_2020.columns = ['Cloud Compute', 'Counts']\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].str.strip()\ndf_count_compute_2020 = df_count_compute_2020[(df_count_compute_2020['Cloud Compute'] == 'Amazon EC2') |\n                      (df_count_compute_2020['Cloud Compute'] == 'Google Cloud Compute Engine') |\n                     (df_count_compute_2020['Cloud Compute'] == 'Azure Cloud Services') |\n                     (df_count_compute_2020['Cloud Compute'] == 'No / None')\n                     ]\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].replace({\n                                                'Amazon EC2': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Cloud Compute Engine': 'Google Cloud Compute Engine',\n                                                'Azure Cloud Services': 'Microsoft Azure Virtual Machines'\n                                               })\n\n\n\n#----------\ncloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\ndf_computing_2021 = pros_2021[cloud_computing_2021]\ncount_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n# ----------\ndf_count_compute_2021 = pd.DataFrame(count_compute_2021)\ndf_count_compute_2021 = df_count_compute_2021.reset_index()\ndf_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n#------------\ndf_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()\ndf_count_compute_2021 = df_count_compute_2021[(df_count_compute_2021['Cloud Compute'] != 'Other')]","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.882121Z","iopub.execute_input":"2021-11-04T01:51:53.882377Z","iopub.status.idle":"2021-11-04T01:51:53.931660Z","shell.execute_reply.started":"2021-11-04T01:51:53.882349Z","shell.execute_reply":"2021-11-04T01:51:53.930954Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#----------\ncloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\ndf_computing_2021 = pros_2021[cloud_computing_2021]\ncount_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n# ----------\ndf_count_compute_2021 = pd.DataFrame(count_compute_2021)\ndf_count_compute_2021 = df_count_compute_2021.reset_index()\ndf_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n#------------\ndf_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.932765Z","iopub.execute_input":"2021-11-04T01:51:53.932990Z","iopub.status.idle":"2021-11-04T01:51:53.946107Z","shell.execute_reply.started":"2021-11-04T01:51:53.932963Z","shell.execute_reply":"2021-11-04T01:51:53.945429Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"cloud_compute_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_compute_df = df_count_compute_2021.merge(df_count_compute_2020, on = 'Cloud Compute').merge(df_count_compute_2019, how = 'left')\ncloud_compute_df = cloud_compute_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.947345Z","iopub.execute_input":"2021-11-04T01:51:53.947698Z","iopub.status.idle":"2021-11-04T01:51:53.962710Z","shell.execute_reply.started":"2021-11-04T01:51:53.947661Z","shell.execute_reply":"2021-11-04T01:51:53.961914Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"cloud_compute_df = cloud_compute_df.T\ncloud_compute_df.columns = cloud_compute_df.iloc[0]\ncloud_compute_df = cloud_compute_df.drop(cloud_compute_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_compute_df = cloud_compute_df.iloc[::-1] # reverse ro\ncloud_compute_df","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.963762Z","iopub.execute_input":"2021-11-04T01:51:53.964064Z","iopub.status.idle":"2021-11-04T01:51:53.981747Z","shell.execute_reply.started":"2021-11-04T01:51:53.964029Z","shell.execute_reply":"2021-11-04T01:51:53.980982Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize = (16,8))\ncloud_compute_df.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728')\n             )","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:53.982904Z","iopub.execute_input":"2021-11-04T01:51:53.983102Z","iopub.status.idle":"2021-11-04T01:51:54.233800Z","shell.execute_reply.started":"2021-11-04T01:51:53.983078Z","shell.execute_reply":"2021-11-04T01:51:54.233208Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"for_perc = cloud_compute_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',)\n             )\nax1.set(title = \"Cloud compute market share surveyed from kaggle\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:54.234806Z","iopub.execute_input":"2021-11-04T01:51:54.235227Z","iopub.status.idle":"2021-11-04T01:51:54.483651Z","shell.execute_reply.started":"2021-11-04T01:51:54.235183Z","shell.execute_reply":"2021-11-04T01:51:54.481811Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"\n# Machine learning tools\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\nml_product_2019 = ['Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8','Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12']\ndf_ml_product_2019 = pros_2019[ml_product_2019]\ncount_ml_product_2019 = pd.Series(df_ml_product_2019[ml_product_2019].squeeze().values.ravel()).value_counts()\n#count_ml_product_2019\n\ndf_count_ml_2019 = pd.DataFrame(count_ml_product_2019)\ndf_count_ml_2019 = df_count_ml_2019.reset_index()\ndf_count_ml_2019.columns = ['ML engine', 'Counts']\n\n#-------\n\nml_product_2020 = ['Q28_A_Part_1','Q28_A_Part_2','Q28_A_Part_3','Q28_A_Part_4','Q28_A_Part_5','Q28_A_Part_6','Q28_A_Part_7','Q28_A_Part_8','Q28_A_Part_9','Q28_A_Part_10']\ndf_ml_product_2020 = pros_2020[ml_product_2020]\ncount_ml_product_2020 = pd.Series(df_ml_product_2020[ml_product_2020].squeeze().values.ravel()).value_counts()\n#count_ml_product_2020\n\ndf_count_ml_2020 = pd.DataFrame(count_ml_product_2020)\ndf_count_ml_2020 = df_count_ml_2020.reset_index()\ndf_count_ml_2020.columns = ['ML engine', 'Counts']\n\n#-------\n\nml_product_2021 = ['Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_OTHER']\ndf_ml_product_2021 = pros_2021[ml_product_2021]\ncount_ml_product_2021 = pd.Series(df_ml_product_2021[ml_product_2021].squeeze().values.ravel()).value_counts()\n#count_ml_product_2021\n\ndf_count_ml_2021 = pd.DataFrame(count_ml_product_2021)\ndf_count_ml_2021 = df_count_ml_2021.reset_index()\ndf_count_ml_2021.columns = ['ML engine', 'Counts']\n\n\ndf_count_ml_2020","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:54.485362Z","iopub.execute_input":"2021-11-04T01:51:54.485672Z","iopub.status.idle":"2021-11-04T01:51:54.528644Z","shell.execute_reply.started":"2021-11-04T01:51:54.485632Z","shell.execute_reply":"2021-11-04T01:51:54.527908Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npd.options.mode.chained_assignment = None  # default='warn'\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:54.529694Z","iopub.execute_input":"2021-11-04T01:51:54.530048Z","iopub.status.idle":"2021-11-04T01:51:54.533693Z","shell.execute_reply.started":"2021-11-04T01:51:54.530018Z","shell.execute_reply":"2021-11-04T01:51:54.532835Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# AutoML regular basis\n\n# Q37_A_Part_1\tQ37_A_Part_2\tQ37_A_Part_3\tQ37_A_Part_4\tQ37_A_Part_5\tQ37_A_Part_6\tQ37_A_Part_7\tQ37_A_OTHER\n# Q34_A_Part_1\tQ34_A_Part_2\tQ34_A_Part_3\tQ34_A_Part_4\tQ34_A_Part_5\tQ34_A_Part_6\tQ34_A_Part_7\tQ34_A_Part_8\tQ34_A_Part_9\tQ34_A_Part_10\tQ34_A_Part_11\tQ34_A_OTHER\t\n# autoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\n\nautoML_2021 = ['Q37_A_Part_1','Q37_A_Part_2','Q37_A_Part_3','Q37_A_Part_4','Q37_A_Part_5','Q37_A_Part_6','Q37_A_Part_7','Q37_A_OTHER']\ndf_autoML_2021 = pros_2021[autoML_2021]\ncount_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\ndf_count_autoML_2021 = df_count_autoML_2021.reset_index()\ndf_count_autoML_2021.columns = ['AutoML', 'Counts']\n#df_count_autoML_2021\n\n#-------\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\nautoML_2020 = ['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_OTHER']\ndf_autoML_2020 = pros_2020[autoML_2020]\ncount_autoML_2020 = pd.Series(df_autoML_2020[autoML_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2020 = pd.DataFrame(count_autoML_2020)\ndf_count_autoML_2020 = df_count_autoML_2020.reset_index()\ndf_count_autoML_2020.columns = ['AutoML', 'Counts']\n#df_count_autoML_2020\n\n# ---------------\n\nautoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\ndf_autoML_2019 = pros_2019[autoML_2019]\ncount_autoML_2019 = pd.Series(df_autoML_2019[autoML_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2019 = pd.DataFrame(count_autoML_2019)\ndf_count_autoML_2019 = df_count_autoML_2019.reset_index()\ndf_count_autoML_2019.columns = ['AutoML', 'Counts']\n\n# --------------\n\nautoML_df = df_count_autoML_2021.merge(df_count_autoML_2020, on = 'AutoML', how = 'outer').merge(df_count_autoML_2019, how = 'outer')\nautoML_df = autoML_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\nautoML_df = autoML_df.drop(autoML_df.index[[0,7,8,9,10,12,13,14,15]]) # Get rid of None and Others, auto sklearn, keras, autoML, Tpot,MLbox, Xcessiv\nautoML_df.at[16, 'AutoML'] = 'Google Cloud AutoML'\nautoML_df.at[11, 'AutoML'] = 'H2O Driverless AI'\nautoML_df['AutoML'] = autoML_df['AutoML'].str.strip()\nautoML_df = autoML_df.groupby(['AutoML']).sum()\nautoML_df.sort_values(by=['2021'], ascending = False).reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T02:58:35.571912Z","iopub.execute_input":"2021-11-04T02:58:35.572356Z","iopub.status.idle":"2021-11-04T02:58:35.653958Z","shell.execute_reply.started":"2021-11-04T02:58:35.572305Z","shell.execute_reply":"2021-11-04T02:58:35.653198Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# autoML in 2 years\n\n# 2021 : Q37_B_Part_1\tQ37_B_Part_2\tQ37_B_Part_3\tQ37_B_Part_4\tQ37_B_Part_5\tQ37_B_Part_6\tQ37_B_Part_7\tQ37_B_OTHER\n\n\nautoML_2021 = ['Q37_B_Part_1','Q37_B_Part_2','Q37_B_Part_3','Q37_B_Part_4','Q37_B_Part_5','Q37_B_Part_6','Q37_B_Part_7','Q37_B_OTHER']\ndf_autoML_2021 = pros_2021[autoML_2021]\ncount_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\ndf_count_autoML_2021 = df_count_autoML_2021.reset_index()\ndf_count_autoML_2021.columns = ['Cloud Compute', 'Counts']\n\n#autoML Familiar\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\nautoML_2020 = ['Q34_B_Part_1','Q34_B_Part_2','Q34_B_Part_3','Q34_B_Part_4','Q34_B_Part_5','Q34_B_Part_6','Q34_B_Part_7','Q34_B_Part_8','Q34_B_Part_9','Q34_B_Part_10','Q34_B_Part_11','Q34_B_OTHER']\ndf_autoML_2020 = pros_2020[autoML_2020]\ncount_autoML_2020 = pd.Series(df_autoML_2020[autoML_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2020 = pd.DataFrame(count_autoML_2020)\ndf_count_autoML_2020 = df_count_autoML_2020.reset_index()\ndf_count_autoML_2020.columns = ['Cloud Compute', 'Counts']\n\n\n# autoML Familiar\n\nautoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\ndf_autoML_2019 = pros_2019[autoML_2019]\ncount_autoML_2019 = pd.Series(df_autoML_2019[autoML_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2019 = pd.DataFrame(count_autoML_2019)\ndf_count_autoML_2019 = df_count_autoML_2019.reset_index()\ndf_count_autoML_2019.columns = ['Cloud Compute', 'Counts']","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:54.606247Z","iopub.execute_input":"2021-11-04T01:51:54.606643Z","iopub.status.idle":"2021-11-04T01:51:54.645351Z","shell.execute_reply.started":"2021-11-04T01:51:54.606616Z","shell.execute_reply":"2021-11-04T01:51:54.644769Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for q in questions_2020:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:54.648768Z","iopub.execute_input":"2021-11-04T01:51:54.649199Z","iopub.status.idle":"2021-11-04T01:51:54.693383Z","shell.execute_reply.started":"2021-11-04T01:51:54.649157Z","shell.execute_reply":"2021-11-04T01:51:54.692573Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"for q in questions_2019:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T01:51:54.694460Z","iopub.execute_input":"2021-11-04T01:51:54.694683Z","iopub.status.idle":"2021-11-04T01:51:54.708858Z","shell.execute_reply.started":"2021-11-04T01:51:54.694655Z","shell.execute_reply":"2021-11-04T01:51:54.708447Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}