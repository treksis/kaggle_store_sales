{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\npd.set_option('display.max_columns', 100)\n\n!pip install openpyxl\n\ndata_2021 = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2021 = data_2021.iloc[0, :].T\ndata_2021 = data_2021.iloc[1:, :]\ndata_2020 = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2020 = data_2020.iloc[0, :].T\ndata_2020 = data_2020.iloc[1:, :]\ndata_2019 = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2019 = data_2019.iloc[0, :].T\ndata_2019 = data_2019.iloc[1:, :]\ndata_2018 = pd.read_csv('../input/kaggle-survey-2018/multipleChoiceResponses.csv', low_memory = False, encoding='UTF-8')\nquestions_2018 = data_2018.iloc[0, :].T\ndata_2018 = data_2018.iloc[1:, :]\ndata_2017 = pd.read_csv('../input/kaggle-survey-2017/multipleChoiceResponses.csv', low_memory = False, encoding='ISO-8859-1')\nquestions_2017 = data_2017.iloc[0, :].T\ndata_2017 = data_2017.iloc[1:, :]\n\nnvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\ncloud_earnings = pd.read_excel('../input/3-tech-cloud-earnings/cloud.xlsx')\n# 2021 Yes. 2020 Yes. 2019 Yes. About TPUs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T02:58:30.313713Z","iopub.execute_input":"2021-11-02T02:58:30.314152Z","iopub.status.idle":"2021-11-02T02:58:47.465621Z","shell.execute_reply.started":"2021-11-02T02:58:30.314053Z","shell.execute_reply":"2021-11-02T02:58:47.464759Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"nvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\nnvda_earnings = nvda_earnings.rename(columns = {'Unnamed: 0': 'Revenue'})\nnvda_earnings","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:47.467420Z","iopub.execute_input":"2021-11-02T02:58:47.468011Z","iopub.status.idle":"2021-11-02T02:58:47.505558Z","shell.execute_reply.started":"2021-11-02T02:58:47.467959Z","shell.execute_reply":"2021-11-02T02:58:47.504664Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = nvda_earnings.T\ndf.columns = df.iloc[0]\ndf = df.drop(df.index[0])\ndf.drop('Total', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:47.507016Z","iopub.execute_input":"2021-11-02T02:58:47.507662Z","iopub.status.idle":"2021-11-02T02:58:47.519499Z","shell.execute_reply.started":"2021-11-02T02:58:47.507625Z","shell.execute_reply":"2021-11-02T02:58:47.518664Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as patches\n\nfig, ax = plt.subplots(figsize = (16,8))\ndf.plot(kind = 'bar', stacked=True, ax = ax)\nax.set(title = 'NVIDIA Earnings')\nfor c in ax.containers:\n    ax.bar_label(c, label_type='center')\n\n#for p in ax.patches:\n    #print(p)\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")\n\nplt.annotate('',\nha = 'center', va = 'bottom',\nxytext = (7.8, 1800),\nxy = (12.3, 3800),\narrowprops = { 'facecolor' : 'red', 'shrink' : 0.05 })\n\nplt.annotate('Data Center Revenue Explosion Begins',\n        fontsize = 14,\n        ha = 'center', va = 'bottom',\n        xytext = (8, 5000),\n        xy = (8, 3200),\n        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.05 })\n\n\nplt.annotate('Data Center revenue growth 100% YoY in 2020', xytext = (3, 6000), xy = (8, 6000), fontsize = 22, color = 'red', )\nplt.axhline(y=3200, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Source: Nvidia', (0,0), (-80,-80), fontsize=8, \n             xycoords='axes fraction', textcoords='offset points', va='top')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:47.521499Z","iopub.execute_input":"2021-11-02T02:58:47.521733Z","iopub.status.idle":"2021-11-02T02:58:48.482498Z","shell.execute_reply.started":"2021-11-02T02:58:47.521704Z","shell.execute_reply":"2021-11-02T02:58:48.481683Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"cloud_earnings.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:48.484042Z","iopub.execute_input":"2021-11-02T02:58:48.484312Z","iopub.status.idle":"2021-11-02T02:58:48.500897Z","shell.execute_reply.started":"2021-11-02T02:58:48.484277Z","shell.execute_reply":"2021-11-02T02:58:48.499813Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_colwidth\n\ndata_center_segment = nvda_earnings.iloc[[2]]\ndata_center_segment = data_center_segment.set_index(['Revenue'])\ndata_center_aws =  data_center_segment.copy() * 0.31\ndata_center_aws = data_center_aws.rename(index = {'data center': 'Aws'})\n\ndata_center_azure = data_center_segment.copy() * 0.22\ndata_center_azure = data_center_azure.rename(index = {'data center': 'Azure'})\n\ndata_center_gcp = data_center_segment.copy() * 0.08\ndata_center_gcp = data_center_gcp.rename(index = {'data center': 'GCP'})\n\ndata_center_others = data_center_segment.copy() * 0.39\ndata_center_others = data_center_others.rename(index = {'data center': 'Others'})\n\ndf = pd.concat([data_center_aws, data_center_azure, data_center_gcp, data_center_others])\ndf.iloc[2, 0] = 0\ndf.iloc[2, 1] = 0\ndf.iloc[2, 2] = 0 \ndf = df.T\n\nfig, ax = plt.subplots(figsize = (16,8))\n\ndf.plot(kind = 'bar', ax = ax)\nplt.axvline(x=2.5, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Google disclosed GCP as of 2019', xytext = (2.6, 600), xy = (8, 600), fontsize = 14, color = 'black' )\nax.set(title = \"Estimated Nvidia' data center revenue from the big 3\")\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:48.501917Z","iopub.execute_input":"2021-11-02T02:58:48.502200Z","iopub.status.idle":"2021-11-02T02:58:48.949584Z","shell.execute_reply.started":"2021-11-02T02:58:48.502170Z","shell.execute_reply":"2021-11-02T02:58:48.949024Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n<div class=\"alert alert-warning\">\n  <strong>Note: </strong> For all charts in this module, I only selected working Professionals.\n</div>\n</div>\n\n<br>\n<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\nNon-professionals were defined as those who answered Job Title as either: \n<ul>\n<li>Student</li>\n<li>Currently not employed</li>\n<li>Who didn't answer the question (NaN)</li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"def get_professionals(data, column):\n    data = data.loc[data[column] != 'Student']\n    data = data.loc[data[column] != 'Currently not employed']\n    data = data.loc[data[column] != 'Not employed']\n    data = data.loc[data[column].notna()]\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:48.950638Z","iopub.execute_input":"2021-11-02T02:58:48.951016Z","iopub.status.idle":"2021-11-02T02:58:48.955354Z","shell.execute_reply.started":"2021-11-02T02:58:48.950979Z","shell.execute_reply":"2021-11-02T02:58:48.954504Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1: Data Science Professionals distribution by industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# Exhibit 1. Data Science Professionals distribution by industry 2018 vs. 2021\n\n# Get data from 2021\n\nindustry_2021 = data_2021[data_2021['Q20'].notna()]\nc = industry_2021['Q20'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#c =industry_2021['Q20'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# Get data from 2018\n\nindustry_2018 = data_2018[data_2018['Q7'] != 'I am a student']\nindustry_2018 = industry_2018[industry_2018['Q7'].notna()]\nd = industry_2018['Q7'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#d = industry_2018['Q7'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# compute the industry\n\nk = pd.merge(left = d, right = c, on = 'industry')\nk = k.rename(columns = {'counts_x': '2018', 'counts_y': '2021'})\nk = k.sort_values(by=['2021'], ascending=False)\n\n# compute the difference\ndiff_industry = k.copy()\ndiff_industry['dff'] = k['2021'] - k['2018']\n\n# plot\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \nax1 = plt.subplot(gs[0])\n\nk.plot.barh(x = \"industry\", ax= ax1)\n#ax.grid(False)\nax1.set(title = \"Data Science professionals distribution by Industry. 2018 vs 2021\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax1.invert_yaxis()\n\nax2 = plt.subplot(gs[1])\ndiff_industry['dff'].plot(kind='barh', x = 'industry', ax = ax2,\n                    color=(diff_industry['dff'] > 0).map({True: 'g',\n                                                    False: 'r'}))\nax2.set(title = \"Change\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax2.set_yticks([])\n\nplt.gca().invert_yaxis()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T02:58:48.956584Z","iopub.execute_input":"2021-11-02T02:58:48.956785Z","iopub.status.idle":"2021-11-02T02:58:49.802027Z","shell.execute_reply.started":"2021-11-02T02:58:48.956760Z","shell.execute_reply":"2021-11-02T02:58:49.801322Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n\n<ul>\n<li> Computer/Technology field is no longer the only game in town. It declined <strong>7.5%</strong></li>\n\n<li> Academic/Education industry gained <strong>3%</strong></li>\n<li> Manufactruing industry gained <strong>2%</strong></li>\n\n<li> A sign that Data Science is <strong>spreading into all over the industry</strong>. </li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"code","source":"# ----------------\n# Job title filter\n# ----------------\n\njob_title = {'Other':'Other',\n     'Product Manager': 'Product/Project Manager',\n 'Program/Project Manager':'Product/Project Manager',\n 'Principal Investigator':'Product/Project Manager',\n 'Chief Officer':'Product/Project Manager',\n 'Manager':'Product/Project Manager',\n 'Software Developer/Software Engineer': 'Software Engineer',\n 'Operations Research Practitioner': 'Research Scientist',\n 'Computer Scientist': 'Research Scientist',\n 'Scientist/Researcher': 'Research Scientist',\n 'Researcher': 'Research Scientist',\n 'Data Scientist': 'Data Scientist',\n     'Business Analyst': 'Business Analyst',\n     'Engineer': 'Other',\n     'DBA/Database Engineer': 'DBA/Database Engineer',\n     'Data Analyst':'Data Analyst',\n     'Machine Learning Engineer': 'Machine Learning Engineer',\n     'Statistician':'Statistician',\n     'Predictive Modeler':'Research Scientist',\n     'Programmer': 'Software Engineer',\n     'Data Miner': 'Data Engineer',\n     'Consultant': 'Other',\n     'Research Assistant': 'Research Scientist',\n     'Chief Officer':'Product/Project Manager',\n     'Data Engineer':'Data Engineer',\n     'Developer Advocate': 'Developer Relations/Advocacy',\n     'Marketing Analyst': 'Business Analyst',\n     'Data Analyst': 'Data Analyst',\n     'Software Engineer': 'Software Engineer',\n     'Research Scientist': 'Research Scientist',\n     'Data Journalist': 'Data Analyst',\n     'Salesperson':'Developer Relations/Advocacy',\n     'Product/Project Manager': 'Product/Project Manager',\n     'Developer Relations/Advocacy': 'Developer Relations/Advocacy'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:49.803070Z","iopub.execute_input":"2021-11-02T02:58:49.803264Z","iopub.status.idle":"2021-11-02T02:58:49.810035Z","shell.execute_reply.started":"2021-11-02T02:58:49.803240Z","shell.execute_reply":"2021-11-02T02:58:49.809035Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1.1: Data Science Professional roles in different industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# cheat\npd.options.mode.chained_assignment = None \n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nworkforce_2021 = get_professionals(data_2021, 'Q5')\nprofessional_2021 = workforce_2021[workforce_2021['Q20'].notna()]\nprofessional_2021['Q5'] = professional_2021['Q5'].map(job_title)\nindustry_2021 = professional_2021['Q20'].unique()\ndf_2021 = professional_2021[['Q5','Q20']]\n\ntemp_d = {}\n\nfor industry in industry_2021:\n    temp_df = df_2021[df_2021['Q20'] == industry]\n    temp_dict = dict(temp_df['Q5'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2021 = {}\n\nh_lst = list(k['industry'])\n\nfor i in h_lst:\n    d_2021[i] = temp_d[i]\n\ndf_industry_2021 = pd.DataFrame.from_dict(d_2021, orient='index')\ndf_industry_2021.fillna(0, inplace = True)\ndf_industry_2021 = df_industry_2021.sort_values(by=df_industry_2021.index[0], ascending=False, axis=1)\ndf_industry_2021\n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nstudent_2018 = data_2018.loc[data_2018['Q7'] == 'I am a student']\nworkforce_2018 = data_2018.loc[data_2018['Q7'] != 'I am a student']\n\nprofessional_2018 = workforce_2018[workforce_2018['Q7'].notna()]\nprofessional_2018['Q6'] = professional_2018['Q6'].map(job_title)\n\nindustry_2018 = professional_2018['Q7'].unique()\n\ndf_2018 = professional_2018[['Q6','Q7']]\n\ntemp_d = {}\n\nfor industry in industry_2018:\n    temp_df = df_2018[df_2018['Q7'] == industry]\n    temp_dict = dict(temp_df['Q6'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2018 = {}\n\nfor i in h_lst:\n    d_2018[i] = temp_d[i]\n\ndf_industry_2018 = pd.DataFrame.from_dict(d_2018, orient='index')\ndf_industry_2018.fillna(0, inplace = True)\ndf_industry_2018 = df_industry_2018.sort_values(by=df_industry_2018.index[0], ascending=False, axis=1)\n#df_industry_2018\n\n# ---------------\n#  SUBPLOTS - 1x2\n# ---------------\n\nfig = plt.figure(figsize=(22,10))\n\nplt.subplot(121)   #  subplot 1\nplt.title('2018 heatmap')\nsns.heatmap(df_industry_2018, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(122)   #  subplot 2\nplt.title('2021 heatmap')\nsns.heatmap(df_industry_2021, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:49.812770Z","iopub.execute_input":"2021-11-02T02:58:49.813073Z","iopub.status.idle":"2021-11-02T02:58:52.955696Z","shell.execute_reply.started":"2021-11-02T02:58:49.813044Z","shell.execute_reply":"2021-11-02T02:58:52.955119Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Machine Learning Engineer role is added in 2021. The Heatmap suggests that the large portion of data scientist and software engineer moved to machine learning engineer.</li>\n    <li>According to <a href=\"https://www.snowflake.com/trending/machine-learning-engineer-vs-data-scientist\">Snowflake</a>, A machine learning engineer will focus on writing code and deploying machine learning products.</li>\n    \n<li>Decline in Research Scientist roles in Computer/Tech and Academic fields.</li>\n<li>A sign that the data science industry is <strong>shifting from research oriented to profit oriented business.</strong> </li>\n</ul>\n</div>\n\n","metadata":{}},{"cell_type":"code","source":"# Exhibit 1.1 Data Science distribution by company size 2021.\n\ntest = get_professionals(data_2021, 'Q5')\n#print(len(test))\ntest = test[test['Q21'].notna()]\n#print(len(test))\n\ncategory_test = test.groupby(['Q20', 'Q21']).size()\n#category_test.plot(kind='bar')\nnew_df = category_test.to_frame(name = 'size').reset_index()\nnew_df_2= pd.pivot(\n    data = new_df,\n    index = 'Q20',\n    columns = 'Q21',\n    values = 'size')\nnew_df_2.index.names = ['Industry']\nnew_df_2.columns.names = ['Company Size']\n\ncolumns_order = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees','10,000 or more employees']\n\nnew_df_2 = new_df_2.reindex(columns = columns_order)\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns='total')\n\n# -----\n\n\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns = 'total')\nres = new_df_2.div(new_df_2.sum(axis=1), axis = 0)\nres\n\n# -----\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n\nax1 = plt.subplot(gs[0])\n\nnew_df_2.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax1,\n              )\n\nax1.set(title = \"DS professional distibution by company size across different industry 2021\",\n      xlabel = \"Counts\",\n      ylabel = \"Industry\")\n\n\nax2 = plt.subplot(gs[1])\n\nres.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax2,\n              )\n\nax2.set(title='Company Size portion within industry',\n      xlabel = \"Percentage\",\n      ylabel = \" \")\n\nplt.legend(title = \"Company Size\", bbox_to_anchor=(1.04,1), loc=\"upper left\")\nax2.set_yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:52.956973Z","iopub.execute_input":"2021-11-02T02:58:52.957224Z","iopub.status.idle":"2021-11-02T02:58:54.179644Z","shell.execute_reply.started":"2021-11-02T02:58:52.957195Z","shell.execute_reply":"2021-11-02T02:58:54.178797Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"(0-49) sized company accounts the most except insurance/Risk industry.\n","metadata":{}},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\n\n# ----------------------------------------------------------------------------------------\n# 2021 (#18 and #19), 2020 (#18 and #19), 2019 (#26 and #27) About Computer vision and NLP\n# ----------------------------------------------------------------------------------------\n\n# ---------------------------------\n# COMPUTER VISION YES OR NO in 2021\n# ---------------------------------\n\nvision = test[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER']]\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nvision = vision.fillna(0)\nvision[vision != 0] = 1\nvision_df = vision[vision==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nvision_df = vision_df.set_index('Algo').T\nstuff_2020 = vision_df\n\nvision['yes'] = vision[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_OTHER']].sum(axis = 1)\nvision['yes'] = vision['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nvision['no'] = (vision['yes'].apply(lambda x: x == 0) | vision['Q18_Part_6'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nvision['Q20'] = test['Q20']\nvision = vision.drop(columns=['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER'])\nvision.replace({False: 0, True: 1}, inplace=True)\nvision_df = vision[vision['yes'] == 1].groupby('Q20').size()\n\ntotal_boss = vision['Q20'].value_counts()\n\nboss = pd.DataFrame(vision_df)\ntotal_boss = pd.DataFrame(total_boss)\nfinal_boss = total_boss.join(boss)\nfinal_boss.rename(columns = {final_boss.columns[0]: 'NO', final_boss.columns[1]: 'YES'}, inplace = True)\n#final_boss\n\n# ---------------------\n# NLP YES OR NO in 2021\n# ---------------------\n\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nnlp = nlp.fillna(0)\nnlp[nlp != 0] = 1\nnlp_df = nlp[nlp==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nnlp_df = nlp_df.set_index('Algo').T\n\nnlp['yes'] = nlp[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_OTHER']].sum(axis = 1)\nnlp['yes'] = nlp['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nnlp['no'] = (nlp['yes'].apply(lambda x: x == 0) | nlp['Q19_Part_5'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nnlp['Q20'] = test['Q20']\nnlp = nlp.drop(columns=['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER'])\nnlp.replace({False: 0, True: 1}, inplace=True)\nnlp_df = nlp[nlp['yes'] == 1].groupby('Q20').size()\n\ntotal_boss2 = nlp['Q20'].value_counts()\n\nboss2 = pd.DataFrame(nlp_df)\ntotal_boss2 = pd.DataFrame(total_boss2)\nfinal_boss2 = total_boss.join(boss2)\nfinal_boss2.rename(columns = {final_boss2.columns[1]: 'hello'}, inplace = True)\n#final_boss2['perc'] = final_boss2['hello'] * 100 / final_boss2['Q20']\nfinal_boss2.rename(columns = {final_boss2.columns[0]: 'NO', final_boss2.columns[1]: 'YES'}, inplace = True)\nfinal_boss2\n\n# --------------- \n#  SUBPLOTS - 1x2\n# ---------------\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(18,11))\n\nplt.subplot(121)   #  subplot 1\nfinal_boss.plot(kind='barh', ax = ax1)\nax1.set(title = \"Computer Vision Yes / No\")\n\nfor i,j in zip(ax1.containers[0], ax1.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(1)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax1.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax1.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nfig.subplots_adjust(wspace=1)\n\nplt.subplot(122)   #  subplot 2\nfinal_boss2.plot(kind='barh', ax = ax2)\nax2.set(title = \"NLP Yes / No\")\n\nfor i,j in zip(ax2.containers[0], ax2.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(2)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax2.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax2.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:54.180666Z","iopub.execute_input":"2021-11-02T02:58:54.180880Z","iopub.status.idle":"2021-11-02T02:58:55.841555Z","shell.execute_reply.started":"2021-11-02T02:58:54.180854Z","shell.execute_reply":"2021-11-02T02:58:55.840563Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# ---------------------\n# ML Algos 2019 to 2021\n# ---------------------\n\n# ----\n# 2021\n# ----\ntest = get_professionals(data_2021, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2021')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2021 = algo_df\n\n# ----\n# 2020\n# ----\n\ntest = get_professionals(data_2020, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2020')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2020 = algo_df\n\n# ----\n# 2019\n# ----\n\nold_colnames = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11', 'Q24_Part_12']\n#new_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11']\n\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\n\n\npd.set_option('display.max_columns', None)\ndata_2019.head()\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\nalgos = data_2019[['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2019')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2019 = algo_df\n\n# ---------------\n# Merge the frame\n# ---------------\n\nalgo_set = stuff_2021.append([stuff_2020, stuff_2019])\nalgo_set = algo_set.T\n\n# --------------\n# Plot the chart\n# --------------\n\nfig, ax1 = plt.subplots(figsize = (16,8))\nalgo_set.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"ML Algo\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:55.843112Z","iopub.execute_input":"2021-11-02T02:58:55.843447Z","iopub.status.idle":"2021-11-02T02:58:57.210088Z","shell.execute_reply.started":"2021-11-02T02:58:55.843405Z","shell.execute_reply":"2021-11-02T02:58:57.209267Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Heatmap of occupation across different industries. Data scientist and software engineer names down notably compare to 2018.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\ntest = test[test['Q26'].notna()]\ntest['Q26'].unique()\n#test = test[test['Q26'] != '$0 ($USD)']\ntest = test.groupby(['Q26', 'Q20']).size()\ndf = test.to_frame(name = 'size').reset_index()\ndf= pd.pivot(\n    data = df,\n    index = 'Q20',\n    columns = 'Q26',\n    values = 'size')\ndf.index.names = ['Industry']\ndf.columns.names = ['Money Spent']\n\n#c = ['$0 ($USD)', '$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\nc = ['$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\ndf = df.reindex(c, axis = 1)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ndf.plot(kind = 'barh', ax = ax1)\nax1.set(title = \"Money Spent on ML or Cloud computing service by industry\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:57.211494Z","iopub.execute_input":"2021-11-02T02:58:57.211781Z","iopub.status.idle":"2021-11-02T02:58:58.365116Z","shell.execute_reply.started":"2021-11-02T02:58:57.211742Z","shell.execute_reply":"2021-11-02T02:58:58.364246Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = {'$0 ($USD)': '$0 ($USD)',\n     '$1-$99': '$1-$99',\n     '$100-$999': '$100-$999',\n     '$1000-$9,999': '$1000-$9,999',\n     '$10,000-$99,999': '$10,000-$99,999',\n     '$100,000 or more ($USD)': '$100,000 or +',\n     '> $100,000 ($USD)': '$100,000 or +',\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:58.366724Z","iopub.execute_input":"2021-11-02T02:58:58.367059Z","iopub.status.idle":"2021-11-02T02:58:58.371942Z","shell.execute_reply.started":"2021-11-02T02:58:58.367013Z","shell.execute_reply":"2021-11-02T02:58:58.371124Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"temp_2021 = get_professionals(data_2021, 'Q5')\n\ntemp_2021 = temp_2021[temp_2021['Q3'] == 'United States of America']\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\n\nfig, ax = plt.subplots(figsize = (16,8))\ndf_2021.plot(kind='bar', ax = ax)\nax.set(title = 'US companies money spent')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:58.373436Z","iopub.execute_input":"2021-11-02T02:58:58.373727Z","iopub.status.idle":"2021-11-02T02:58:59.176610Z","shell.execute_reply.started":"2021-11-02T02:58:58.373689Z","shell.execute_reply":"2021-11-02T02:58:59.175883Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntemp_2021 = get_professionals(data_2021, 'Q5')\ntemp_2020 = get_professionals(data_2020, 'Q5')\n\n\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\n#data_2019['Q11'] = data_2019['Q11'].map(c)\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\n\nmoney_spent_2020 = temp_2020[temp_2020['Q25'].notna()]\nmoney_spent_2020['Q25'] = money_spent_2020['Q25'].map(c)\nmoney_spent_2020 = money_spent_2020[money_spent_2020['Q25'] != '$0 ($USD)']\n\nmoney_spent_2019 = data_2019[data_2019['Q11'].notna()]\nmoney_spent_2019['Q11'] = money_spent_2019['Q11'].map(c)\n\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\ndf_2020 = pd.DataFrame(money_spent_2020['Q25'].value_counts(), index = row_order)\ndf_2019 = pd.DataFrame(money_spent_2019['Q11'].value_counts(), index = row_order)\n\ndf_final = pd.concat([df_2021, df_2020, df_2019], axis = 1)\ndf_final.rename(columns = {'Q26': '2021', 'Q25': '2020', 'Q11': '2019'}, inplace= True)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ndf_final.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"Money Spent by company size\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:58:59.177644Z","iopub.execute_input":"2021-11-02T02:58:59.177860Z","iopub.status.idle":"2021-11-02T02:59:00.275452Z","shell.execute_reply.started":"2021-11-02T02:58:59.177821Z","shell.execute_reply":"2021-11-02T02:59:00.274506Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_2021 = get_professionals(data_2021, 'Q5')\n\ntemp_2021 = temp_2021[temp_2021['Q3'] == 'China']\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\n\ndf_2021","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:00.276676Z","iopub.execute_input":"2021-11-02T02:59:00.276938Z","iopub.status.idle":"2021-11-02T02:59:00.654950Z","shell.execute_reply.started":"2021-11-02T02:59:00.276909Z","shell.execute_reply":"2021-11-02T02:59:00.654363Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\ndata_2021['Q3'].value_counts()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-02T02:59:00.656006Z","iopub.execute_input":"2021-11-02T02:59:00.656212Z","iopub.status.idle":"2021-11-02T02:59:00.665671Z","shell.execute_reply.started":"2021-11-02T02:59:00.656188Z","shell.execute_reply":"2021-11-02T02:59:00.664808Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n\n# Which of the following cloud computing platforms do you use on a regular basis? \n# 2021 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\t\n# 2020 Q26_A_Part_1\tQ26_A_Part_2\tQ26_A_Part_3\tQ26_A_Part_4\tQ26_A_Part_5\tQ26_A_Part_6\tQ26_A_Part_7\tQ26_A_Part_8\tQ26_A_Part_9\tQ26_A_Part_10\tQ26_A_Part_11\tQ26_A_OTHER\n# 2019 Q29_Part_1\tQ29_Part_2\tQ29_Part_3\tQ29_Part_4\tQ29_Part_5\tQ29_Part_6\tQ29_Part_7\tQ29_Part_8\tQ29_Part_9\tQ29_Part_10\tQ29_Part_11\tQ29_Part_12\n\n# Do you use any of the following cloud computing products on a regular basis? (Select all that apply)\n# 2021  Q29_A_Part_1\tQ29_A_Part_2\tQ29_A_Part_3\tQ29_A_Part_4\tQ29_A_OTHER\n#Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected the relevant answer choices for Question 27-A (which of the following companies).\n# 2020 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\n# 2019 Q30_Part_1\tQ30_Part_2\tQ30_Part_3\tQ30_Part_4\tQ30_Part_5\tQ30_Part_6\tQ30_Part_7\tQ30_Part_8\tQ30_Part_9\tQ30_Part_10\tQ30_Part_11\n\n# Which of the following automated machine learning tools (or partial AutoML tools) do you use on aregular basis? (Select all that apply)\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\tQ28_A_OTHER\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\tQ32_OTHER_TEXT\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:00.667204Z","iopub.execute_input":"2021-11-02T02:59:00.667676Z","iopub.status.idle":"2021-11-02T02:59:00.678802Z","shell.execute_reply.started":"2021-11-02T02:59:00.667635Z","shell.execute_reply":"2021-11-02T02:59:00.678061Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pros_2021 = get_professionals(data_2021, 'Q5')\npros_2020 = get_professionals(data_2020, 'Q5')\n\npros_2019 = data_2019[data_2019['Q5'].notna()]\npros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\npros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:00.679825Z","iopub.execute_input":"2021-11-02T02:59:00.680562Z","iopub.status.idle":"2021-11-02T02:59:01.332552Z","shell.execute_reply.started":"2021-11-02T02:59:00.680456Z","shell.execute_reply":"2021-11-02T02:59:01.331917Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cloud usage\n\ncloud_2021 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8',\n 'Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_2021 = pros_2021[cloud_2021]\ndf_2021\n\ncount_2021 = pd.Series(df_2021[cloud_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_2021 = pd.DataFrame(count_2021)\ndf_count_2021 = df_count_2021.reset_index()\ndf_count_2021.columns = ['Cloud', 'Counts']\n\n# --------------------------------------------\n\ncloud_2020 = ['Q26_A_Part_1','Q26_A_Part_2','Q26_A_Part_3','Q26_A_Part_4','Q26_A_Part_5','Q26_A_Part_6',\n'Q26_A_Part_7','Q26_A_Part_8','Q26_A_Part_9','Q26_A_Part_10','Q26_A_Part_11','Q26_A_OTHER']\ndf_2020 = pros_2020[cloud_2020]\n\ncount_2020 = pd.Series(df_2020[cloud_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_2020 = pd.DataFrame(count_2020)\ndf_count_2020 = df_count_2020.reset_index()\ndf_count_2020.columns = ['Cloud', 'Counts']\n\n# ----------------------------------------------\n\n\ncloud_2019 = ['Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7',\n              'Q29_Part_8','Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12'] #Q29_OTHER_TEXT\n\ndf_2019 = pros_2019[cloud_2019]\n\ncount_2019 = pd.Series(df_2019[cloud_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_2019 = pd.DataFrame(count_2019)\ndf_count_2019 = df_count_2019.reset_index()\ndf_count_2019.columns = ['Cloud', 'Counts']\ndf_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\ndf_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\ndf_count_2019\n\n\n\n#cloud_2020 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\n#df_2020 = data_2020[]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:01.334095Z","iopub.execute_input":"2021-11-02T02:59:01.334629Z","iopub.status.idle":"2021-11-02T02:59:01.388083Z","shell.execute_reply.started":"2021-11-02T02:59:01.334587Z","shell.execute_reply":"2021-11-02T02:59:01.387441Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#df_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\n#df_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\n#df_count_2019","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:01.389124Z","iopub.execute_input":"2021-11-02T02:59:01.389448Z","iopub.status.idle":"2021-11-02T02:59:01.393060Z","shell.execute_reply.started":"2021-11-02T02:59:01.389422Z","shell.execute_reply":"2021-11-02T02:59:01.392183Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\ncloud_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_df['Counts'][4] = 451\ncloud_df = cloud_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\ncloud_df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:01.394299Z","iopub.execute_input":"2021-11-02T02:59:01.394990Z","iopub.status.idle":"2021-11-02T02:59:01.427280Z","shell.execute_reply.started":"2021-11-02T02:59:01.394943Z","shell.execute_reply":"2021-11-02T02:59:01.426468Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"cloud_df = cloud_df.T\ncloud_df.columns = cloud_df.iloc[0]\ncloud_df = cloud_df.drop(cloud_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_df = cloud_df.iloc[::-1] # reverse ro\ncloud_df\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ncloud_df.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n             )\nax1.set(title = \"Cloud usage by kaggle community\")\n#cloud_df.plot.area(figsize = (18,9))","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:01.428328Z","iopub.execute_input":"2021-11-02T02:59:01.428685Z","iopub.status.idle":"2021-11-02T02:59:01.820633Z","shell.execute_reply.started":"2021-11-02T02:59:01.428657Z","shell.execute_reply":"2021-11-02T02:59:01.819844Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove\n\nfor_perc = cloud_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n             )\nax1.set(title = \"Cloud market share surveyed from kaggle\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:01.821725Z","iopub.execute_input":"2021-11-02T02:59:01.822032Z","iopub.status.idle":"2021-11-02T02:59:02.192418Z","shell.execute_reply.started":"2021-11-02T02:59:01.822003Z","shell.execute_reply":"2021-11-02T02:59:02.191573Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Do you use any of the following cloud computing products on a regular basis? (Select all that apply)\n# 2021  Q29_A_Part_1\tQ29_A_Part_2\tQ29_A_Part_3\tQ29_A_Part_4\tQ29_A_OTHER\n#Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected the relevant answer choices for Question 27-A (which of the following companies).\n# 2020 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\n# 2019 Q30_Part_1\tQ30_Part_2\tQ30_Part_3\tQ30_Part_4\tQ30_Part_5\tQ30_Part_6\tQ30_Part_7\tQ30_Part_8\tQ30_Part_9\tQ30_Part_10\tQ30_Part_11\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.193690Z","iopub.execute_input":"2021-11-02T02:59:02.193992Z","iopub.status.idle":"2021-11-02T02:59:02.200543Z","shell.execute_reply.started":"2021-11-02T02:59:02.193952Z","shell.execute_reply":"2021-11-02T02:59:02.199794Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloud_computing_2019 = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_OTHER_TEXT']\ndf_computing_2019 = pros_2019[cloud_computing_2019]\ncount_compute_2019 = pd.Series(df_computing_2019[cloud_computing_2019].squeeze().values.ravel()).value_counts()\n\n#-----------------\ndf_count_compute_2019 = pd.DataFrame(count_compute_2019)\ndf_count_compute_2019 = df_count_compute_2019.reset_index()\ndf_count_compute_2019.columns = ['Cloud Compute', 'Counts']\n#------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].str.strip()\ndf_count_compute_2019 = df_count_compute_2019[(df_count_compute_2019['Cloud Compute'] == 'AWS Elastic Compute Cloud (EC2)') |\n                      (df_count_compute_2019['Cloud Compute'] == 'Google Compute Engine (GCE)') |\n                     (df_count_compute_2019['Cloud Compute'] == 'Azure Virtual Machines') |\n                     (df_count_compute_2019['Cloud Compute'] == 'None')\n                                             ]\n#----------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].replace({\n                                                'AWS Elastic Compute Cloud (EC2)': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Compute Engine (GCE)': 'Google Cloud Compute Engine',\n                                                'Azure Virtual Machines': 'Microsoft Azure Virtual Machines',\n                                                'None': 'No / None'\n                                               })\n\n\n\ncloud_computing_2020 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8','Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_computing_2020 = pros_2020[cloud_computing_2020]\ncount_compute_2020 = pd.Series(df_computing_2020[cloud_computing_2020].squeeze().values.ravel()).value_counts()\n#------------\ndf_count_compute_2020 = pd.DataFrame(count_compute_2020)\ndf_count_compute_2020 = df_count_compute_2020.reset_index()\ndf_count_compute_2020.columns = ['Cloud Compute', 'Counts']\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].str.strip()\ndf_count_compute_2020 = df_count_compute_2020[(df_count_compute_2020['Cloud Compute'] == 'Amazon EC2') |\n                      (df_count_compute_2020['Cloud Compute'] == 'Google Cloud Compute Engine') |\n                     (df_count_compute_2020['Cloud Compute'] == 'Azure Cloud Services') |\n                     (df_count_compute_2020['Cloud Compute'] == 'No / None')\n                     ]\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].replace({\n                                                'Amazon EC2': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Cloud Compute Engine': 'Google Cloud Compute Engine',\n                                                'Azure Cloud Services': 'Microsoft Azure Virtual Machines'\n                                               })\n\n\n\n#----------\ncloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\ndf_computing_2021 = pros_2021[cloud_computing_2021]\ncount_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n# ----------\ndf_count_compute_2021 = pd.DataFrame(count_compute_2021)\ndf_count_compute_2021 = df_count_compute_2021.reset_index()\ndf_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n#------------\ndf_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()\ndf_count_compute_2021 = df_count_compute_2021[(df_count_compute_2021['Cloud Compute'] != 'Other')]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.205023Z","iopub.execute_input":"2021-11-02T02:59:02.205264Z","iopub.status.idle":"2021-11-02T02:59:02.250705Z","shell.execute_reply.started":"2021-11-02T02:59:02.205226Z","shell.execute_reply":"2021-11-02T02:59:02.250083Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"#----------\ncloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\ndf_computing_2021 = pros_2021[cloud_computing_2021]\ncount_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n# ----------\ndf_count_compute_2021 = pd.DataFrame(count_compute_2021)\ndf_count_compute_2021 = df_count_compute_2021.reset_index()\ndf_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n#------------\ndf_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.251638Z","iopub.execute_input":"2021-11-02T02:59:02.252216Z","iopub.status.idle":"2021-11-02T02:59:02.264393Z","shell.execute_reply.started":"2021-11-02T02:59:02.252185Z","shell.execute_reply":"2021-11-02T02:59:02.263538Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"cloud_compute_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_compute_df = df_count_compute_2021.merge(df_count_compute_2020, on = 'Cloud Compute').merge(df_count_compute_2019, how = 'left')\ncloud_compute_df = cloud_compute_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.265788Z","iopub.execute_input":"2021-11-02T02:59:02.266172Z","iopub.status.idle":"2021-11-02T02:59:02.289573Z","shell.execute_reply.started":"2021-11-02T02:59:02.266132Z","shell.execute_reply":"2021-11-02T02:59:02.288796Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"cloud_compute_df = cloud_compute_df.T\ncloud_compute_df.columns = cloud_compute_df.iloc[0]\ncloud_compute_df = cloud_compute_df.drop(cloud_compute_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_compute_df = cloud_compute_df.iloc[::-1] # reverse ro\ncloud_compute_df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.290561Z","iopub.execute_input":"2021-11-02T02:59:02.290769Z","iopub.status.idle":"2021-11-02T02:59:02.302651Z","shell.execute_reply.started":"2021-11-02T02:59:02.290743Z","shell.execute_reply":"2021-11-02T02:59:02.301896Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize = (16,8))\ncloud_compute_df.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728')\n             )","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.303644Z","iopub.execute_input":"2021-11-02T02:59:02.304589Z","iopub.status.idle":"2021-11-02T02:59:02.605570Z","shell.execute_reply.started":"2021-11-02T02:59:02.304554Z","shell.execute_reply":"2021-11-02T02:59:02.604705Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"for_perc = cloud_compute_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\nfig, ax1 = plt.subplots(figsize = (16,8))\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax1,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',)\n             )\nax1.set(title = \"Cloud compute market share surveyed from kaggle\")","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.606750Z","iopub.execute_input":"2021-11-02T02:59:02.607006Z","iopub.status.idle":"2021-11-02T02:59:02.904554Z","shell.execute_reply.started":"2021-11-02T02:59:02.606977Z","shell.execute_reply":"2021-11-02T02:59:02.902476Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npd.options.mode.chained_assignment = None  # default='warn'\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.905579Z","iopub.execute_input":"2021-11-02T02:59:02.905787Z","iopub.status.idle":"2021-11-02T02:59:02.909430Z","shell.execute_reply.started":"2021-11-02T02:59:02.905760Z","shell.execute_reply":"2021-11-02T02:59:02.908752Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"cloud_computing_2019 = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_OTHER_TEXT']\ndf_computing_2019 = pros_2019[cloud_computing_2019]\ncount_compute_2019 = pd.Series(df_computing_2019[cloud_computing_2019].squeeze().values.ravel()).value_counts()\n\n#-----------------\ndf_count_compute_2019 = pd.DataFrame(count_compute_2019)\ndf_count_compute_2019 = df_count_compute_2019.reset_index()\ndf_count_compute_2019.columns = ['Cloud Compute', 'Counts']","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.910288Z","iopub.execute_input":"2021-11-02T02:59:02.910752Z","iopub.status.idle":"2021-11-02T02:59:02.934263Z","shell.execute_reply.started":"2021-11-02T02:59:02.910722Z","shell.execute_reply":"2021-11-02T02:59:02.933495Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\ndata_2021","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:02.935375Z","iopub.execute_input":"2021-11-02T02:59:02.935587Z","iopub.status.idle":"2021-11-02T02:59:03.222190Z","shell.execute_reply.started":"2021-11-02T02:59:02.935562Z","shell.execute_reply":"2021-11-02T02:59:03.221320Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for q in questions_2020:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:03.223324Z","iopub.execute_input":"2021-11-02T02:59:03.223562Z","iopub.status.idle":"2021-11-02T02:59:03.271690Z","shell.execute_reply.started":"2021-11-02T02:59:03.223532Z","shell.execute_reply":"2021-11-02T02:59:03.270734Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"for q in questions_2019:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T02:59:03.272982Z","iopub.execute_input":"2021-11-02T02:59:03.273213Z","iopub.status.idle":"2021-11-02T02:59:03.301979Z","shell.execute_reply.started":"2021-11-02T02:59:03.273184Z","shell.execute_reply":"2021-11-02T02:59:03.299375Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}