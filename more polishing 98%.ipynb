{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as patches\n\npd.set_option('display.max_columns', 100)\npd.options.mode.chained_assignment = None  # default='warn'\n\n!pip install openpyxl\n\ndata_2021 = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2021 = data_2021.iloc[0, :].T\ndata_2021 = data_2021.iloc[1:, :]\ndata_2020 = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2020 = data_2020.iloc[0, :].T\ndata_2020 = data_2020.iloc[1:, :]\ndata_2019 = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2019 = data_2019.iloc[0, :].T\ndata_2019 = data_2019.iloc[1:, :]\ndata_2018 = pd.read_csv('../input/kaggle-survey-2018/multipleChoiceResponses.csv', low_memory = False, encoding='UTF-8')\nquestions_2018 = data_2018.iloc[0, :].T\ndata_2018 = data_2018.iloc[1:, :]\ndata_2017 = pd.read_csv('../input/kaggle-survey-2017/multipleChoiceResponses.csv', low_memory = False, encoding='ISO-8859-1')\nquestions_2017 = data_2017.iloc[0, :].T\ndata_2017 = data_2017.iloc[1:, :]\n\nnvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\ncloud_earnings = pd.read_excel('../input/3-tech-cloud-earnings/cloud.xlsx')\n# 2021 Yes. 2020 Yes. 2019 Yes. About TPUs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-22T00:50:49.088629Z","iopub.execute_input":"2021-11-22T00:50:49.089061Z","iopub.status.idle":"2021-11-22T00:51:08.319570Z","shell.execute_reply.started":"2021-11-22T00:50:49.088945Z","shell.execute_reply":"2021-11-22T00:51:08.318615Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def get_professionals(data, column):\n    data = data.loc[data[column] != 'Student']\n    data = data.loc[data[column] != 'Currently not employed']\n    data = data.loc[data[column] != 'Not employed']\n    data = data.loc[data[column].notna()]\n    return data\n\npros_2021 = get_professionals(data_2021, 'Q5')\npros_2020 = get_professionals(data_2020, 'Q5')\n\npros_2019 = data_2019[data_2019['Q5'].notna()]\npros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\npros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:08.322106Z","iopub.execute_input":"2021-11-22T00:51:08.322441Z","iopub.status.idle":"2021-11-22T00:51:09.119995Z","shell.execute_reply.started":"2021-11-22T00:51:08.322397Z","shell.execute_reply":"2021-11-22T00:51:09.118793Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"nvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\nnvda_earnings = nvda_earnings.rename(columns = {'Unnamed: 0': 'Revenue'})\nnvda_earnings","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:09.121580Z","iopub.execute_input":"2021-11-22T00:51:09.121869Z","iopub.status.idle":"2021-11-22T00:51:09.167053Z","shell.execute_reply.started":"2021-11-22T00:51:09.121836Z","shell.execute_reply":"2021-11-22T00:51:09.165972Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = nvda_earnings.T\ndf.columns = df.iloc[0]\ndf = df.drop(df.index[0])\ndf.drop('Total', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:09.170181Z","iopub.execute_input":"2021-11-22T00:51:09.170523Z","iopub.status.idle":"2021-11-22T00:51:09.179882Z","shell.execute_reply.started":"2021-11-22T00:51:09.170481Z","shell.execute_reply":"2021-11-22T00:51:09.178808Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as patches\n\nfig, ax = plt.subplots(figsize = (16,8))\ndf.plot(kind = 'bar', stacked=True, ax = ax)\nax.set(title = 'NVIDIA Earnings')\nfor c in ax.containers:\n    ax.bar_label(c, label_type='center')\n\n#for p in ax.patches:\n    #print(p)\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")\n\nplt.annotate('',\nha = 'center', va = 'bottom',\nxytext = (7.8, 1800),\nxy = (12.3, 3800),\narrowprops = { 'facecolor' : 'red', 'shrink' : 0.05 })\n\nplt.annotate('Data Center Revenue Explosion Begins',\n        fontsize = 14,\n        ha = 'center', va = 'bottom',\n        xytext = (8, 5000),\n        xy = (8, 3200),\n        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.05 })\n\n\nplt.annotate('Data Center revenue growth 100% YoY in 2020', xytext = (3, 6000), xy = (8, 6000), fontsize = 22, color = 'red', )\nplt.axhline(y=3200, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Source: Nvidia', (0,0), (-80,-80), fontsize=8, \n             xycoords='axes fraction', textcoords='offset points', va='top')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:09.181239Z","iopub.execute_input":"2021-11-22T00:51:09.182288Z","iopub.status.idle":"2021-11-22T00:51:10.247548Z","shell.execute_reply.started":"2021-11-22T00:51:09.182248Z","shell.execute_reply":"2021-11-22T00:51:10.246812Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cloud_earnings.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:10.248721Z","iopub.execute_input":"2021-11-22T00:51:10.249443Z","iopub.status.idle":"2021-11-22T00:51:10.266891Z","shell.execute_reply.started":"2021-11-22T00:51:10.249395Z","shell.execute_reply":"2021-11-22T00:51:10.266106Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_colwidth\n\ndata_center_segment = nvda_earnings.iloc[[2]]\ndata_center_segment = data_center_segment.set_index(['Revenue'])\ndata_center_aws =  data_center_segment.copy() * 0.31\ndata_center_aws = data_center_aws.rename(index = {'data center': 'Aws'})\n\ndata_center_azure = data_center_segment.copy() * 0.22\ndata_center_azure = data_center_azure.rename(index = {'data center': 'Azure'})\n\ndata_center_gcp = data_center_segment.copy() * 0.08\ndata_center_gcp = data_center_gcp.rename(index = {'data center': 'GCP'})\n\ndata_center_others = data_center_segment.copy() * 0.39\ndata_center_others = data_center_others.rename(index = {'data center': 'Others'})\n\ndf = pd.concat([data_center_aws, data_center_azure, data_center_gcp, data_center_others])\ndf.iloc[2, 0] = 0\ndf.iloc[2, 1] = 0\ndf.iloc[2, 2] = 0 \ndf = df.T\n\nfig, ax = plt.subplots(figsize = (16,8))\n\ndf.plot(kind = 'bar', ax = ax)\nplt.axvline(x=2.5, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Google disclosed GCP as of 2019', xytext = (2.6, 600), xy = (8, 600), fontsize = 14, color = 'black' )\nax.set(title = \"Estimated Nvidia' data center revenue from the big 3\")\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:10.268319Z","iopub.execute_input":"2021-11-22T00:51:10.268612Z","iopub.status.idle":"2021-11-22T00:51:10.766861Z","shell.execute_reply.started":"2021-11-22T00:51:10.268578Z","shell.execute_reply":"2021-11-22T00:51:10.765944Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n<div class=\"alert alert-warning\">\n  <strong>Note: </strong> For all charts in this module, I only selected working Professionals.\n</div>\n</div>\n\n<br>\n<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\nNon-professionals were defined as those who answered Job Title as either: \n<ul>\n<li>Student</li>\n<li>Currently not employed</li>\n<li>Who didn't answer the question (NaN)</li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1: Data Science Professionals distribution by industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# Exhibit 1. Data Science Professionals distribution by industry 2018 vs. 2021\n\n# Get data from 2021\n\nindustry_2021 = data_2021[data_2021['Q20'].notna()]\nc = industry_2021['Q20'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#c =industry_2021['Q20'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# Get data from 2018\n\nindustry_2018 = data_2018[data_2018['Q7'] != 'I am a student']\nindustry_2018 = industry_2018[industry_2018['Q7'].notna()]\nd = industry_2018['Q7'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#d = industry_2018['Q7'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# compute the industry\n\nk = pd.merge(left = d, right = c, on = 'industry')\nk = k.rename(columns = {'counts_x': '2018', 'counts_y': '2021'})\nk = k.sort_values(by=['2021'], ascending=False)\n\n# compute the difference\ndiff_industry = k.copy()\ndiff_industry['dff'] = k['2021'] - k['2018']\n\n# plot\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \nax1 = plt.subplot(gs[0])\n\nk.plot.barh(x = \"industry\", ax= ax1)\n#ax.grid(False)\nax1.set(title = \"Data Science professionals distribution by Industry. 2018 vs 2021\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax1.invert_yaxis()\n\nax2 = plt.subplot(gs[1])\ndiff_industry['dff'].plot(kind='barh', x = 'industry', ax = ax2,\n                    color=(diff_industry['dff'] > 0).map({True: 'g',\n                                                    False: 'r'}))\nax2.set(title = \"Change\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax2.set_yticks([])\n\nplt.gca().invert_yaxis()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-22T00:51:10.768311Z","iopub.execute_input":"2021-11-22T00:51:10.769007Z","iopub.status.idle":"2021-11-22T00:51:11.742715Z","shell.execute_reply.started":"2021-11-22T00:51:10.768970Z","shell.execute_reply":"2021-11-22T00:51:11.741798Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n\n<ul>\n<li> Computer/Technology field is no longer the only game in town. It declined <strong>7.5%</strong></li>\n\n<li> Academic/Education industry gained <strong>3%</strong></li>\n<li> Manufactruing industry gained <strong>2%</strong></li>\n\n<li> A sign that Data Science is <strong>penetrating broadly</strong>. </li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"code","source":"# ----------------\n# Job title filter\n# ----------------\n\njob_title = {'Other':'Other',\n     'Product Manager': 'Product/Project Manager',\n 'Program/Project Manager':'Product/Project Manager',\n 'Principal Investigator':'Product/Project Manager',\n 'Chief Officer':'Product/Project Manager',\n 'Manager':'Product/Project Manager',\n 'Software Developer/Software Engineer': 'Software Engineer',\n 'Operations Research Practitioner': 'Research Scientist',\n 'Computer Scientist': 'Research Scientist',\n 'Scientist/Researcher': 'Research Scientist',\n 'Researcher': 'Research Scientist',\n 'Data Scientist': 'Data Scientist',\n     'Business Analyst': 'Business Analyst',\n     'Engineer': 'Other',\n     'DBA/Database Engineer': 'DBA/Database Engineer',\n     'Data Analyst':'Data Analyst',\n     'Machine Learning Engineer': 'Machine Learning Engineer',\n     'Statistician':'Statistician',\n     'Predictive Modeler':'Research Scientist',\n     'Programmer': 'Software Engineer',\n     'Data Miner': 'Data Engineer',\n     'Consultant': 'Other',\n     'Research Assistant': 'Research Scientist',\n     'Chief Officer':'Product/Project Manager',\n     'Data Engineer':'Data Engineer',\n     'Developer Advocate': 'Developer Relations/Advocacy',\n     'Marketing Analyst': 'Business Analyst',\n     'Data Analyst': 'Data Analyst',\n     'Software Engineer': 'Software Engineer',\n     'Research Scientist': 'Research Scientist',\n     'Data Journalist': 'Data Analyst',\n     'Salesperson':'Developer Relations/Advocacy',\n     'Product/Project Manager': 'Product/Project Manager',\n     'Developer Relations/Advocacy': 'Developer Relations/Advocacy'\n}","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-22T00:51:11.744348Z","iopub.execute_input":"2021-11-22T00:51:11.744686Z","iopub.status.idle":"2021-11-22T00:51:11.752809Z","shell.execute_reply.started":"2021-11-22T00:51:11.744641Z","shell.execute_reply":"2021-11-22T00:51:11.752159Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1.1: Data Science Professional roles in different industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# cheat\npd.options.mode.chained_assignment = None \n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nworkforce_2021 = get_professionals(data_2021, 'Q5')\nprofessional_2021 = workforce_2021[workforce_2021['Q20'].notna()]\nprofessional_2021['Q5'] = professional_2021['Q5'].map(job_title)\nindustry_2021 = professional_2021['Q20'].unique()\ndf_2021 = professional_2021[['Q5','Q20']]\n\ntemp_d = {}\n\nfor industry in industry_2021:\n    temp_df = df_2021[df_2021['Q20'] == industry]\n    temp_dict = dict(temp_df['Q5'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2021 = {}\n\nh_lst = list(k['industry'])\n\nfor i in h_lst:\n    d_2021[i] = temp_d[i]\n\ndf_industry_2021 = pd.DataFrame.from_dict(d_2021, orient='index')\ndf_industry_2021.fillna(0, inplace = True)\ndf_industry_2021 = df_industry_2021.sort_values(by=df_industry_2021.index[0], ascending=False, axis=1)\ndf_industry_2021\n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nstudent_2018 = data_2018.loc[data_2018['Q7'] == 'I am a student']\nworkforce_2018 = data_2018.loc[data_2018['Q7'] != 'I am a student']\n\nprofessional_2018 = workforce_2018[workforce_2018['Q7'].notna()]\nprofessional_2018['Q6'] = professional_2018['Q6'].map(job_title)\n\nindustry_2018 = professional_2018['Q7'].unique()\n\ndf_2018 = professional_2018[['Q6','Q7']]\n\ntemp_d = {}\n\nfor industry in industry_2018:\n    temp_df = df_2018[df_2018['Q7'] == industry]\n    temp_dict = dict(temp_df['Q6'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2018 = {}\n\nfor i in h_lst:\n    d_2018[i] = temp_d[i]\n\ndf_industry_2018 = pd.DataFrame.from_dict(d_2018, orient='index')\ndf_industry_2018.fillna(0, inplace = True)\ndf_industry_2018 = df_industry_2018.sort_values(by=df_industry_2018.index[0], ascending=False, axis=1)\n#df_industry_2018\n\n# ---------------\n#  SUBPLOTS - 1x2\n# ---------------\n\nfig = plt.figure(figsize=(22,10))\n\nplt.subplot(121)   #  subplot 1\nplt.title('2018 heatmap')\nsns.heatmap(df_industry_2018, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(122)   #  subplot 2\nplt.title('2021 heatmap')\nsns.heatmap(df_industry_2021, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nplt.axvline(x = 2, ymin= -0.05, ymax= 1.1, color='red', linestyle='solid', linewidth=5)\nplt.axvline(x = 3, ymin= -0.05, ymax= 1.1, color='red', linestyle='solid', linewidth=5)\n\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-22T00:51:11.755632Z","iopub.execute_input":"2021-11-22T00:51:11.756233Z","iopub.status.idle":"2021-11-22T00:51:15.450950Z","shell.execute_reply.started":"2021-11-22T00:51:11.756198Z","shell.execute_reply":"2021-11-22T00:51:15.449826Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Machine Learning Engineer role is added in 2021. <strong>Large portion of data scientist and software engineer moved to machine learning engineer.</strong></li>\n    \n<li><strong>Decline in Research Scientist roles</strong> in Computer/Tech and Academic fields.</li>\n</ul>\n</div>\n\n","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfrom math import pi\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n# activities at work\n\n# Q24_Part_1\tQ24_Part_2\tQ24_Part_3\tQ24_Part_4\tQ24_Part_5\tQ24_Part_6\tQ24_Part_7\tQ24_OTHER\n\nactivities_2021 = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_OTHER']\n\nrole_2021 = ['Q5']\n\nrole_activities_2021 = ['Q5','Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_OTHER']\n\njob_name = ['Data Scientist', 'Machine Learning Engineer',  'Software Engineer', 'Data Analyst', 'Research Scientist']\n\ndf_role_act_2021 = pros_2021[role_activities_2021]\n\ndf_role_act_2021 = df_role_act_2021[df_role_act_2021['Q5'].isin(job_name)]\n\ndf_role_act_2021[activities_2021] = df_role_act_2021[activities_2021].notnull().astype('int')\n\n# --------------\n\ndf_SE = df_role_act_2021[df_role_act_2021['Q5'] == 'Software Engineer']\ndf_SE = df_SE.groupby(by='Q5', dropna=False).sum()\ndf_SE = df_SE.rename(columns = {'Q24_Part_1': 'Analyze data', \n                     'Q24_Part_2': 'Build infrastructure', \n                     'Q24_Part_3': 'Build ML prototypes', \n                     'Q24_Part_4': 'Deploy & Improve',\n                     'Q24_Part_5': 'Improve existing ML',\n                     'Q24_Part_6': 'Do research',\n                     'Q24_Part_7': 'None',\n                     'Q24_OTHER': 'Other'\n                    })\n\ndf_SE = df_SE.T.reset_index()\n\n# --------------\n\ndf_DS = df_role_act_2021[df_role_act_2021['Q5'] == 'Data Scientist']\ndf_DS = df_DS.groupby(by='Q5', dropna=False).sum()\ndf_DS = df_DS.rename(columns = {'Q24_Part_1': 'Analyze data', \n                     'Q24_Part_2': 'Build infrastructure', \n                     'Q24_Part_3': 'Build ML prototypes', \n                     'Q24_Part_4': 'Deploy & Improve',\n                     'Q24_Part_5': 'Improve existing ML',\n                     'Q24_Part_6': 'Do research',\n                     'Q24_Part_7': 'None',\n                     'Q24_OTHER': 'Other'\n                    })\ndf_DS = df_DS.T.reset_index()\n\n# -------------\n\ndf_MLE = df_role_act_2021[df_role_act_2021['Q5'] == 'Machine Learning Engineer']\n#print(df)\ndf_MLE = df_MLE.groupby(by='Q5', dropna=False).sum()\ndf_MLE = df_MLE.rename(columns = {'Q24_Part_1': 'Analyze data', \n                     'Q24_Part_2': 'Build infrastructure', \n                     'Q24_Part_3': 'Build ML prototypes', \n                     'Q24_Part_4': 'Deploy & Improve',\n                     'Q24_Part_5': 'Improve existing ML',\n                     'Q24_Part_6': 'Do research',\n                     'Q24_Part_7': 'None',\n                     'Q24_OTHER': 'Other'\n                    })\ndf_MLE = df_MLE.T.reset_index()\n\n#----------\n\n\n\ndf_MLE['percent'] = (df_MLE['Machine Learning Engineer'] / \n                  df_MLE['Machine Learning Engineer'].sum()) * 100\ndf_MLE = df_MLE.drop('Machine Learning Engineer', axis = 1)\n\ndf_DS['percent'] = (df_DS['Data Scientist'] / \n                  df_DS['Data Scientist'].sum()) * 100\ndf_DS = df_DS.drop('Data Scientist', axis = 1)\n\ndf_SE['percent'] = (df_SE['Software Engineer'] / \n                  df_SE['Software Engineer'].sum()) * 100\ndf_SE = df_SE.drop('Software Engineer', axis = 1)\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatterpolar(\n      r=df_SE['percent'],\n      theta=df_SE['index'],\n      fill='toself',\n      name='Software Engineer'\n))\n\n\nfig.add_trace(go.Scatterpolar(\n      r=df_DS['percent'],\n      theta=df_DS['index'],\n      fill='toself',\n      name='Data Scientist'\n))\n\nfig.add_trace(go.Scatterpolar(\n      r=df_MLE['percent'],\n      theta=df_MLE['index'],\n      fill='toself',\n      name='Machine Learning Engineer'\n))\n\n\nfig.update_layout(\n     title={\n        'text': \"Tasks in workplace SE vs. DS vs. MLE\",\n        'y':0.92,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n  polar=dict(\n    radialaxis=dict(\n      visible=True,\n      range=[0, 27]\n    )),\n  showlegend=True\n)\n\nfig.show()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-22T00:51:15.452829Z","iopub.execute_input":"2021-11-22T00:51:15.453147Z","iopub.status.idle":"2021-11-22T00:51:16.925163Z","shell.execute_reply.started":"2021-11-22T00:51:15.453104Z","shell.execute_reply":"2021-11-22T00:51:16.923959Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Machine learning engineer's tasks are hybrid of traditional software engineer and data scientist. <strong>MLEs conduct more resources on managing products than analyzing data or building infrastructure.</strong></li>\n    <li>The rise of Machine learning enginner and decline in research scientist in academic field suggests that <strong>the data science industry is moving from research to business/operation oriented</strong></li>\n\n</ul>\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Exhibit 1.1 Data Science distribution by company size 2021.\n\ntest = get_professionals(data_2021, 'Q5')\n#print(len(test))\ntest = test[test['Q21'].notna()]\n#print(len(test))\n\ncategory_test = test.groupby(['Q20', 'Q21']).size()\n#category_test.plot(kind='bar')\nnew_df = category_test.to_frame(name = 'size').reset_index()\nnew_df_2= pd.pivot(\n    data = new_df,\n    index = 'Q20',\n    columns = 'Q21',\n    values = 'size')\nnew_df_2.index.names = ['Industry']\nnew_df_2.columns.names = ['Company Size']\n\ncolumns_order = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees','10,000 or more employees']\n\nnew_df_2 = new_df_2.reindex(columns = columns_order)\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns='total')\n\n# -----\n\n\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns = 'total')\nres = new_df_2.div(new_df_2.sum(axis=1), axis = 0)\nres\n\n# -----\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n\nax1 = plt.subplot(gs[0])\n\nnew_df_2.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax1,\n              )\n\nax1.set(title = \"DS professional distibution by company size across different industry 2021\",\n      xlabel = \"Counts\",\n      ylabel = \"Industry\")\n\n\nax2 = plt.subplot(gs[1])\n\nres.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax2,\n              )\n\nax2.set(title='Company Size portion within industry',\n      xlabel = \"Percentage\",\n      ylabel = \" \")\n\nplt.legend(title = \"Company Size\", bbox_to_anchor=(1.04,1), loc=\"upper left\")\nax2.set_yticks([])\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-22T00:51:16.926978Z","iopub.execute_input":"2021-11-22T00:51:16.927311Z","iopub.status.idle":"2021-11-22T00:51:18.366056Z","shell.execute_reply.started":"2021-11-22T00:51:16.927269Z","shell.execute_reply":"2021-11-22T00:51:18.365118Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>The survey data suggests that Data science professionals are distributed proportionally across general industry.</li>\n    <li>Start-up (0-49 employees) accounts the most in Non-profit/Service.</li>\n    <li>Large corporation (10,000 + employees) accounts the most in Insurance/Risk Assessment </li>\n</ul>\n</div>\n","metadata":{}},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\ntest = test[test['Q26'].notna()]\ntest['Q26'].unique()\n#test = test[test['Q26'] != '$0 ($USD)']\ntest = test.groupby(['Q26', 'Q20']).size()\ndf = test.to_frame(name = 'size').reset_index()\ndf= pd.pivot(\n    data = df,\n    index = 'Q20',\n    columns = 'Q26',\n    values = 'size')\ndf.index.names = ['Industry']\ndf.columns.names = ['Money Spent']\n\n#c = ['$0 ($USD)', '$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\nc = ['$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\ndf = df.reindex(c, axis = 1)\ndf = df.sort_values(by='$100,000 or more ($USD)', ascending = False)\n\nfig, ax1 = plt.subplots(figsize = (21,10))\ndf.plot(kind = 'barh', ax = ax1)\nax1.set(title = \"Money Spent on ML or Cloud computing service by industry ranked in 100,000+ in 2021\",\n       xlabel = \"Counts\",\n       ylabel = \"Industry\")","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-22T00:51:18.367351Z","iopub.execute_input":"2021-11-22T00:51:18.367604Z","iopub.status.idle":"2021-11-22T00:51:19.898196Z","shell.execute_reply.started":"2021-11-22T00:51:18.367573Z","shell.execute_reply":"2021-11-22T00:51:19.897251Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Computers/Technology accounts the highest number of companies that spend over $100,000+</li>\n    <li>While the number of data science professionals working in Academic/Education industry ranked the second(in previous chart), the number of institutions that spend over 100,000+ are ranked only at 6th.</li>\n\n</ul>\n</div>\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = {'$0 ($USD)': '$0 ($USD)',\n     '$1-$99': '$1-$99',\n     '$100-$999': '$100-$999',\n     '$1000-$9,999': '$1000-$9,999',\n     '$10,000-$99,999': '$10,000-$99,999',\n     '$100,000 or more ($USD)': '$100,000 or +',\n     '> $100,000 ($USD)': '$100,000 or +',\n}\n\ntemp_2021 = get_professionals(data_2021, 'Q5')\ntemp_2020 = get_professionals(data_2020, 'Q5')\n\n\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\n#data_2019['Q11'] = data_2019['Q11'].map(c)\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\n\nmoney_spent_2020 = temp_2020[temp_2020['Q25'].notna()]\nmoney_spent_2020['Q25'] = money_spent_2020['Q25'].map(c)\nmoney_spent_2020 = money_spent_2020[money_spent_2020['Q25'] != '$0 ($USD)']\n\nmoney_spent_2019 = data_2019[data_2019['Q11'].notna()]\nmoney_spent_2019['Q11'] = money_spent_2019['Q11'].map(c)\n\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\ndf_2020 = pd.DataFrame(money_spent_2020['Q25'].value_counts(), index = row_order)\ndf_2019 = pd.DataFrame(money_spent_2019['Q11'].value_counts(), index = row_order)\n\ndf_final = pd.concat([df_2019, df_2020, df_2021], axis = 1)\ndf_final.rename(columns = {'Q26': '2021', 'Q25': '2020', 'Q11': '2019'}, inplace= True)\ndf_final = df_final.T\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ndf_final.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"The amount and number of companies/institutions spending on ML infrastructure from 2019 to 2021\",\n       xlabel = \"Year\",\n       ylabel = \"Counts\")\nax1.legend(title='money spent')","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-11-22T00:51:19.899625Z","iopub.execute_input":"2021-11-22T00:51:19.899935Z","iopub.status.idle":"2021-11-22T00:51:21.136162Z","shell.execute_reply.started":"2021-11-22T00:51:19.899901Z","shell.execute_reply":"2021-11-22T00:51:21.135186Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Total aggregate spending on ML went up from 2019 to 2021. The dip in 2020 is likely due to covid-19</li>\n\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"hardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\nhardware_2021_df = pros_2021[hardware_2021]\ncount_hardware_2021 = pd.Series(hardware_2021_df[hardware_2021].squeeze().values.ravel()).value_counts()\n\nhardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\nhardware_2020_df = pros_2020[hardware_2020]\ncount_hardware_2020 = pd.Series(hardware_2020_df[hardware_2020].squeeze().values.ravel()).value_counts()\n\nhardware_2019 = ['Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5','Q21_OTHER_TEXT']\nhardware_2019_df = pros_2019[hardware_2019]\ncount_hardware_2019 = pd.Series(hardware_2019_df[hardware_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_hardware_2021 = pd.DataFrame(count_hardware_2021)\ndf_count_hardware_2021 = df_count_hardware_2021.reset_index()\ndf_count_hardware_2021.columns = ['manage', '2021']\n\ndf_count_hardware_2020 = pd.DataFrame(count_hardware_2020)\ndf_count_hardware_2020 = df_count_hardware_2020.reset_index()\ndf_count_hardware_2020.columns = ['manage', '2020']\n\ndf_count_hardware_2019 = pd.DataFrame(count_hardware_2019)\ndf_count_hardware_2019 = df_count_hardware_2019.reset_index()\ndf_count_hardware_2019.columns = ['manage', '2019']\n\ndf_count_hardware_2019 = df_count_hardware_2019.iloc[1:6]\ndf_count_hardware_2019 = df_count_hardware_2019.set_index('manage').T[['GPUs', 'TPUs','Other']]\n\ndf_count_hardware_2020 = df_count_hardware_2020.set_index('manage').T[['GPUs', 'TPUs', 'Other']]\n\ndf_count_hardware_2021 = df_count_hardware_2021.set_index('manage').T\ndf_count_hardware_2021.columns = df_count_hardware_2021.columns.str.strip()\ndf_count_hardware_2021 = df_count_hardware_2021[['NVIDIA GPUs','Google Cloud TPUs','Other','AWS Inferentia Chips','AWS Trainium Chips']]\ndf_count_hardware_2021 = df_count_hardware_2021.rename(columns = {'NVIDIA GPUs': 'GPUs',\n                                                                    'Google Cloud TPUs': 'TPUs',\n                                                                    'Other': 'Other',\n                                                                    'AWS Inferentia Chips': 'AWS Inferentia',\n                                                                    'AWS Trainium Chips': 'AWS Trainium'})\n\ndf_hardware_merged = df_count_hardware_2019.append(df_count_hardware_2020).append(df_count_hardware_2021).fillna(0)\n\nfig, ax = plt.subplots(figsize=(18,6))\ndf_hardware_merged.plot(kind='bar', ax=ax)\nax.set(title = 'Special hardware usage trend',\n    xlabel = 'year',\n      ylabel = 'number of respondants',\n      )\n\nax.annotate(\"AWS's custom chips are added in 2021\", xy=(2.1, 1000), xytext=(2.3, 2000),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nax.legend(title='Special hardware')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:21.137728Z","iopub.execute_input":"2021-11-22T00:51:21.138067Z","iopub.status.idle":"2021-11-22T00:51:21.578308Z","shell.execute_reply.started":"2021-11-22T00:51:21.138033Z","shell.execute_reply":"2021-11-22T00:51:21.577182Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>AWS launched its own chipset in early 2021. Newly added</li>\n    <li>While GPU usage stagnated <strong>there is significant jump in TPU usage in 2021</strong></li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"large_spender_2020 = pros_2020.loc[pros_2020['Q25'].isin(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)'])]\nhardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\n\nspender_hardware_2020 = pd.DataFrame()\n\nfor idx, comp_size in enumerate(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)']):\n    spender_comp_size = large_spender_2020.loc[large_spender_2020['Q25'] == comp_size]\n    idx = pd.Series(spender_comp_size[hardware_2020].squeeze().values.ravel()).value_counts()\n    spender_hardware_2020[comp_size] = idx\n    \nspender_hardware_2020 = spender_hardware_2020.rename(columns = {'$100,000 or more ($USD)': '100,000 +'})\nspender_hardware_2020 = spender_hardware_2020.T[['GPUs','TPUs', 'Other']]\n\nlarge_spender_2021 = pros_2021.loc[pros_2021['Q26'].isin(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)'])]\n\nhardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\n# ------------------\n\nspender_hardware_2021 = pd.DataFrame()\n\nfor idx, comp_size in enumerate(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)']):\n    spender_comp_size = large_spender_2021.loc[large_spender_2021['Q26'] == comp_size]\n    idx = pd.Series(spender_comp_size[hardware_2021].squeeze().values.ravel()).value_counts()\n    spender_hardware_2021[comp_size] = idx\n    \nspender_hardware_2021 = spender_hardware_2021.rename(columns = {'$100,000 or more ($USD)': '100,000 +'})\nspender_hardware_2021 = spender_hardware_2021[1:].T\n\n# ---- plot\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (22,10))\n\nplt.subplot(121)\nspender_hardware_2020.plot(kind='bar', ax=ax1)\nax1.set(title = \"Special hardware usage by spending size in 2020\")\nax1.legend(loc=1, prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.2)\n\nplt.subplot(122)\nspender_hardware_2021.plot(kind='bar', ax=ax2)\nax2.set(title = \"Special hardware usage by spending size in 2021\")\nax2.legend(loc=1, prop={'size': 9})","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:21.580226Z","iopub.execute_input":"2021-11-22T00:51:21.580467Z","iopub.status.idle":"2021-11-22T00:51:22.332301Z","shell.execute_reply.started":"2021-11-22T00:51:21.580438Z","shell.execute_reply":"2021-11-22T00:51:22.331211Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Broad increase in TPU usage.</li>\n\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"# ---------------------\n# ML Algos 2019 to 2021\n# ---------------------\n\n# ----\n# 2021\n# ----\ntest = get_professionals(data_2021, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2021')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2021 = algo_df\n\n# ----\n# 2020\n# ----\n\ntest = get_professionals(data_2020, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2020')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2020 = algo_df\n\n# ----\n# 2019\n# ----\n\nold_colnames = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11', 'Q24_Part_12']\n#new_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11']\n\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\n\n\npd.set_option('display.max_columns', None)\ndata_2019.head()\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\nalgos = data_2019[['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2019')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2019 = algo_df\n\n# ---------------\n# Merge the frame\n# ---------------\n\nalgo_set = stuff_2021.append([stuff_2020, stuff_2019])\nalgo_set = algo_set.T\nalgo_set = algo_set[['2019', '2020', '2021']]\nalgo_set = algo_set.sort_values(by='2021',ascending = False)\n\n# -------------\n\ngpu_algo = ['Q12_Part_1',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\ntpu_algo = ['Q12_Part_2',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\nalgo = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\ngpu_use_algo = pros_2021[gpu_algo]\ngpu_use_algo = gpu_use_algo[gpu_use_algo['Q12_Part_1'].notna()]\n\ngpu_algo_count = pd.Series(gpu_use_algo[algo].squeeze().values.ravel()).value_counts()\ndf_gpu_algo_count = pd.DataFrame(gpu_algo_count)\n\n\n# ---------\n\n\ngpu_algo = ['Q12_Part_1',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\ntpu_algo = ['Q12_Part_2',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\nalgo = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\ntpu_algo_algo = pros_2021[tpu_algo]\ntpu_algo_algo = tpu_algo_algo[tpu_algo_algo['Q12_Part_2'].notna()]\n\ntpu_algo_count = pd.Series(tpu_algo_algo[algo].squeeze().values.ravel()).value_counts()\ndf_tpu_algo_count = pd.DataFrame(tpu_algo_count)\n\n# -----------\n\ngpu_tpu_algo = pd.DataFrame()\ngpu_tpu_algo['NVIDIA GPUs'] = df_gpu_algo_count\ngpu_tpu_algo['Google Cloud TPUs'] = df_tpu_algo_count\n\ngpu_tpu_algo = gpu_tpu_algo.T\ngpu_tpu_algo = gpu_tpu_algo.rename(columns = \n{'Linear or Logistic Regression': 'Regression',\n 'Decision Trees or Random Forests': 'Decision Trees',\n 'Convolutional Neural Networks': 'CNN',\n 'Gradient Boosting Machines (xgboost, lightgbm, etc)': 'Gradient Boosting',\n 'Dense Neural Networks (MLPs, etc)': 'DNN',\n 'Recurrent Neural Networks': 'RNN',\n 'Bayesian Approaches': 'Bayesian',\n 'Transformer Networks (BERT, gpt-3, etc)': 'Transformer',\n 'Generative Adversarial Networks': 'GAN',\n 'Evolutionary Approaches': 'Evolutionary',\n 'None': 'None',\n 'Other': 'Other'})\n\ngpu_tpu_algo = gpu_tpu_algo.T\ngpu_tpu_algo = gpu_tpu_algo.sort_values(by = 'Google Cloud TPUs', ascending = False)\n\n# --------------\n# Plot the chart\n# --------------\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (22,8))\n\nplt.subplot(121)\nalgo_set.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"ML Algo\")\nplt.axvline(x = 2.5, ymin= -0.05, ymax= 1.1, color='black', linestyle='dashed', linewidth=3)\nplt.annotate(\"Deep learning algos\", xytext=(2.8, 6000), xy=(8, 3500), \n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nfig.subplots_adjust(wspace=0.2)\n\nplt.subplot(122)\ngpu_tpu_algo.plot(kind = 'bar', ax = ax2)\nax2.set(title = \"ML algo and GPU/TPU in 2021\")\nplt.axvline(x = 2.5, ymin= -0.05, ymax= 1.1, color='black', linestyle='dashed', linewidth=3)\nplt.annotate(\"Less CNN user than Gradient boost, but higher demand in GPU/TPU\", xytext=(2.8, 3000), xy=(2, 2500), \n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.annotate(\"\", xytext=(3, 3000), xy=(2.8, 2400), \n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:22.334556Z","iopub.execute_input":"2021-11-22T00:51:22.335038Z","iopub.status.idle":"2021-11-22T00:51:24.464819Z","shell.execute_reply.started":"2021-11-22T00:51:22.334980Z","shell.execute_reply":"2021-11-22T00:51:24.463987Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\n\n# ----------------------------------------------------------------------------------------\n# 2021 (#18 and #19), 2020 (#18 and #19), 2019 (#26 and #27) About Computer vision and NLP\n# ----------------------------------------------------------------------------------------\n\n# ---------------------------------\n# COMPUTER VISION YES OR NO in 2021\n# ---------------------------------\n\nvision = test[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER']]\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nvision = vision.fillna(0)\nvision[vision != 0] = 1\nvision_df = vision[vision==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nvision_df = vision_df.set_index('Algo').T\nstuff_2020 = vision_df\n\nvision['yes'] = vision[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_OTHER']].sum(axis = 1)\nvision['yes'] = vision['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nvision['no'] = (vision['yes'].apply(lambda x: x == 0) | vision['Q18_Part_6'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nvision['Q20'] = test['Q20']\nvision = vision.drop(columns=['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER'])\nvision.replace({False: 0, True: 1}, inplace=True)\nvision_df = vision[vision['yes'] == 1].groupby('Q20').size()\n\ntotal_boss = vision['Q20'].value_counts()\n\nboss = pd.DataFrame(vision_df)\ntotal_boss = pd.DataFrame(total_boss)\nfinal_boss = total_boss.join(boss)\nfinal_boss.rename(columns = {final_boss.columns[0]: 'NO', final_boss.columns[1]: 'YES'}, inplace = True)\n#final_boss\n\n# ---------------------\n# NLP YES OR NO in 2021\n# ---------------------\n\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nnlp = nlp.fillna(0)\nnlp[nlp != 0] = 1\nnlp_df = nlp[nlp==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nnlp_df = nlp_df.set_index('Algo').T\n\nnlp['yes'] = nlp[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_OTHER']].sum(axis = 1)\nnlp['yes'] = nlp['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nnlp['no'] = (nlp['yes'].apply(lambda x: x == 0) | nlp['Q19_Part_5'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nnlp['Q20'] = test['Q20']\nnlp = nlp.drop(columns=['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER'])\nnlp.replace({False: 0, True: 1}, inplace=True)\nnlp_df = nlp[nlp['yes'] == 1].groupby('Q20').size()\n\ntotal_boss2 = nlp['Q20'].value_counts()\n\nboss2 = pd.DataFrame(nlp_df)\ntotal_boss2 = pd.DataFrame(total_boss2)\nfinal_boss2 = total_boss.join(boss2)\nfinal_boss2.rename(columns = {final_boss2.columns[1]: 'hello'}, inplace = True)\n#final_boss2['perc'] = final_boss2['hello'] * 100 / final_boss2['Q20']\nfinal_boss2.rename(columns = {final_boss2.columns[0]: 'NO', final_boss2.columns[1]: 'YES'}, inplace = True)\nfinal_boss2\n\n# --------------- \n#  SUBPLOTS - 1x2\n# ---------------\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(18,11))\n\nplt.subplot(121)   #  subplot 1\nfinal_boss.plot(kind='barh', ax = ax1)\nax1.set(title = \"Computer Vision Yes / No\",\n       xlabel = \"Counts\",\n       ylabel = \"Industry\")\n\n\n\nfor i,j in zip(ax1.containers[0], ax1.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(1)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax1.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax1.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nfig.subplots_adjust(wspace=1)\n\nplt.subplot(122)   #  subplot 2\nfinal_boss2.plot(kind='barh', ax = ax2)\nax2.set(title = \"NLP Yes / No\",\n       xlabel = \"Counts\",\n       ylabel = \"Industry\")\n\nfor i,j in zip(ax2.containers[0], ax2.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(2)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax2.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax2.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:24.466578Z","iopub.execute_input":"2021-11-22T00:51:24.466865Z","iopub.status.idle":"2021-11-22T00:51:26.426597Z","shell.execute_reply.started":"2021-11-22T00:51:24.466833Z","shell.execute_reply":"2021-11-22T00:51:26.425589Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"industry_gpu = ['Q20', 'Q12_Part_1']\nindustry_by_gpu = pros_2021[industry_gpu]\nindustry_by_gpu = industry_by_gpu[industry_by_gpu['Q20'].notna()]\n\nindustry_list = list(industry_by_gpu['Q20'].unique())\n\nind_gpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_gpu = industry_by_gpu.loc[industry_by_gpu['Q20'] == ind]\n    idx = pd.Series(ind_gpu['Q12_Part_1'].squeeze().values.ravel()).value_counts()\n    ind_gpu_merged[ind] = idx\n    \n    \nindustry_tpu = ['Q20', 'Q12_Part_2']\nindustry_by_tpu = pros_2021[industry_tpu]\nindustry_by_tpu = industry_by_tpu[industry_by_tpu['Q20'].notna()]\n\nind_tpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_tpu = industry_by_tpu.loc[industry_by_tpu['Q20'] == ind]\n    idx = pd.Series(ind_tpu['Q12_Part_2'].squeeze().values.ravel()).value_counts()\n    ind_tpu_merged[ind] = idx\n\nind_gpu_tpu = ind_gpu_merged.append(ind_tpu_merged).T\nind_gpu_tpu.columns = ind_gpu_tpu.columns.str.strip()\nind_gpu_tpu = ind_gpu_tpu.sort_values(by = 'NVIDIA GPUs', ascending = False)\n\nfig, ax = plt.subplots(figsize = (11,10))\nind_gpu_tpu.plot(kind = 'barh', ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:26.428109Z","iopub.execute_input":"2021-11-22T00:51:26.428364Z","iopub.status.idle":"2021-11-22T00:51:27.075444Z","shell.execute_reply.started":"2021-11-22T00:51:26.428332Z","shell.execute_reply":"2021-11-22T00:51:27.074782Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n\n# Which of the following cloud computing platforms do you use on a regular basis? \n# 2021 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\t\n# 2020 Q26_A_Part_1\tQ26_A_Part_2\tQ26_A_Part_3\tQ26_A_Part_4\tQ26_A_Part_5\tQ26_A_Part_6\tQ26_A_Part_7\tQ26_A_Part_8\tQ26_A_Part_9\tQ26_A_Part_10\tQ26_A_Part_11\tQ26_A_OTHER\n# 2019 Q29_Part_1\tQ29_Part_2\tQ29_Part_3\tQ29_Part_4\tQ29_Part_5\tQ29_Part_6\tQ29_Part_7\tQ29_Part_8\tQ29_Part_9\tQ29_Part_10\tQ29_Part_11\tQ29_Part_12\n\n# Do you use any of the following cloud computing products on a regular basis? (Select all that apply)\n# 2021  Q29_A_Part_1\tQ29_A_Part_2\tQ29_A_Part_3\tQ29_A_Part_4\tQ29_A_OTHER\n#Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected the relevant answer choices for Question 27-A (which of the following companies).\n# 2020 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\n# 2019 Q30_Part_1\tQ30_Part_2\tQ30_Part_3\tQ30_Part_4\tQ30_Part_5\tQ30_Part_6\tQ30_Part_7\tQ30_Part_8\tQ30_Part_9\tQ30_Part_10\tQ30_Part_11\n\n# Which of the following automated machine learning tools (or partial AutoML tools) do you use on aregular basis? (Select all that apply)\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\tQ28_A_OTHER\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\tQ32_OTHER_TEXT\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:27.076874Z","iopub.execute_input":"2021-11-22T00:51:27.077220Z","iopub.status.idle":"2021-11-22T00:51:27.082115Z","shell.execute_reply.started":"2021-11-22T00:51:27.077191Z","shell.execute_reply":"2021-11-22T00:51:27.081528Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pros_2021 = get_professionals(data_2021, 'Q5')\npros_2020 = get_professionals(data_2020, 'Q5')\n\npros_2019 = data_2019[data_2019['Q5'].notna()]\npros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\npros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:27.083239Z","iopub.execute_input":"2021-11-22T00:51:27.083579Z","iopub.status.idle":"2021-11-22T00:51:27.749589Z","shell.execute_reply.started":"2021-11-22T00:51:27.083551Z","shell.execute_reply":"2021-11-22T00:51:27.748657Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cloud usage\n\ncloud_2021 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8',\n 'Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_2021 = pros_2021[cloud_2021]\ndf_2021\n\ncount_2021 = pd.Series(df_2021[cloud_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_2021 = pd.DataFrame(count_2021)\ndf_count_2021 = df_count_2021.reset_index()\ndf_count_2021.columns = ['Cloud', 'Counts']\n\n# --------------------------------------------\n\ncloud_2020 = ['Q26_A_Part_1','Q26_A_Part_2','Q26_A_Part_3','Q26_A_Part_4','Q26_A_Part_5','Q26_A_Part_6',\n'Q26_A_Part_7','Q26_A_Part_8','Q26_A_Part_9','Q26_A_Part_10','Q26_A_Part_11','Q26_A_OTHER']\ndf_2020 = pros_2020[cloud_2020]\n\ncount_2020 = pd.Series(df_2020[cloud_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_2020 = pd.DataFrame(count_2020)\ndf_count_2020 = df_count_2020.reset_index()\ndf_count_2020.columns = ['Cloud', 'Counts']\n\n# ----------------------------------------------\n\n\ncloud_2019 = ['Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7',\n              'Q29_Part_8','Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12'] #Q29_OTHER_TEXT\n\ndf_2019 = pros_2019[cloud_2019]\n\ncount_2019 = pd.Series(df_2019[cloud_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_2019 = pd.DataFrame(count_2019)\ndf_count_2019 = df_count_2019.reset_index()\ndf_count_2019.columns = ['Cloud', 'Counts']\ndf_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\ndf_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\n\n# -------- merge ------\n\n\n\ncloud_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_df['Counts'][4] = 451\ncloud_df = cloud_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\ncloud_df_bar = cloud_df.set_index('Cloud').T[::-1]\n\n# --------- 2nd chart -----\n\ncloud_df = cloud_df.T\ncloud_df.columns = cloud_df.iloc[0]\ncloud_df = cloud_df.drop(cloud_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_df = cloud_df.iloc[::-1] # reverse ro\n\nfor_perc = cloud_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\n# ------------ favorite and 2 years later ----------\n\ncloud_2_year_list = ['Q27_A_Part_1',\n          'Q27_A_Part_2',\n          'Q27_A_Part_3',\n          'Q27_A_Part_4',\n          'Q27_A_Part_5',\n          'Q27_A_Part_6',\n          'Q27_A_Part_7',\n          'Q27_A_Part_8',\n          'Q27_A_Part_9',\n          'Q27_A_Part_10',\n          'Q27_A_Part_11',\n          'Q27_A_OTHER']\n\ncloud_2_year_later = pros_2021[cloud_2_year_list]\n\ncount_cloud_2_year_later = pd.Series(cloud_2_year_later[cloud_2_year_list].squeeze().values.ravel()).value_counts()\ndf_count_cloud_2_year_later = pd.DataFrame(count_cloud_2_year_later).reset_index()\ndf_count_cloud_2_year_later.columns = ['Cloud', '2021']\ndf_count_cloud_2_year_later = df_count_cloud_2_year_later.set_index('Cloud').T\n\n\ncloud_best_exp = pd.Series(pros_2021['Q28'].squeeze().values.ravel()).value_counts()\ndf_cloud_best_exp = pd.DataFrame(cloud_best_exp).reset_index()\ndf_cloud_best_exp.columns = ['Cloud', '2021']\ndf_cloud_best_exp = df_cloud_best_exp.set_index('Cloud').T\n\n\n# ------------- plot ------\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(22,8))\n\n\nplt.subplot(121)   #  subplot 1\n\ncloud_df_bar.plot(kind = 'bar', ax= ax1)\nax1.set(title = \"Cloud platform usage in regular basis in kaggle survey\")\nax1.legend(loc='lower right', bbox_to_anchor=(1.34, 0), prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.4)\n\n\nplt.subplot(122) #  subplot 2\n\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax2,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n             )\nax2.set(title = \"Cloud computing usage by share\")\nax2.legend(loc='lower right', bbox_to_anchor=(1.34, 0), prop={'size': 9})\nax2.annotate('Share of none is decreasing', xy=(1.6, 0.55), xytext=(0.06, 0.6),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:27.750960Z","iopub.execute_input":"2021-11-22T00:51:27.751206Z","iopub.status.idle":"2021-11-22T00:51:28.922588Z","shell.execute_reply.started":"2021-11-22T00:51:27.751177Z","shell.execute_reply":"2021-11-22T00:51:28.921534Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"cloud_2_year_list = ['Q27_A_Part_1',\n          'Q27_A_Part_2',\n          'Q27_A_Part_3',\n          'Q27_A_Part_4',\n          'Q27_A_Part_5',\n          'Q27_A_Part_6',\n          'Q27_A_Part_7',\n          'Q27_A_Part_8',\n          'Q27_A_Part_9',\n          'Q27_A_Part_10',\n          'Q27_A_Part_11',\n          'Q27_A_OTHER']\n\ncloud_2_year_later = pros_2021[cloud_2_year_list]\n\ncount_cloud_2_year_later = pd.Series(cloud_2_year_later[cloud_2_year_list].squeeze().values.ravel()).value_counts()\ndf_count_cloud_2_year_later = pd.DataFrame(count_cloud_2_year_later).reset_index()\ndf_count_cloud_2_year_later.columns = ['Cloud', '2021']\ndf_count_cloud_2_year_later = df_count_cloud_2_year_later.set_index('Cloud').T\n\n\ncloud_best_exp = pd.Series(pros_2021['Q28'].squeeze().values.ravel()).value_counts()\ndf_cloud_best_exp = pd.DataFrame(cloud_best_exp).reset_index()\ndf_cloud_best_exp.columns = ['Cloud', '2021']\ndf_cloud_best_exp = df_cloud_best_exp.set_index('Cloud').T\n\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (22,8))\nplt.subplot(121)   #  subplot 1\n\ndf_count_cloud_2_year_later.plot(kind = 'bar', ax = ax1)\nax1.set(title = 'Cloud platform who answered the best developer experience with')\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(122) #  subplot 2\n\ndf_cloud_best_exp.plot(kind='bar', ax=ax2)\nax2.set(title = 'Cloud platform that respondant is willing to become more familiar in 2 year')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:28.924249Z","iopub.execute_input":"2021-11-22T00:51:28.924600Z","iopub.status.idle":"2021-11-22T00:51:29.612737Z","shell.execute_reply.started":"2021-11-22T00:51:28.924569Z","shell.execute_reply":"2021-11-22T00:51:29.611762Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloud_computing_2019 = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_OTHER_TEXT']\ndf_computing_2019 = pros_2019[cloud_computing_2019]\ncount_compute_2019 = pd.Series(df_computing_2019[cloud_computing_2019].squeeze().values.ravel()).value_counts()\n\n#-----------------\ndf_count_compute_2019 = pd.DataFrame(count_compute_2019)\ndf_count_compute_2019 = df_count_compute_2019.reset_index()\ndf_count_compute_2019.columns = ['Cloud Compute', 'Counts']\n#------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].str.strip()\ndf_count_compute_2019 = df_count_compute_2019[(df_count_compute_2019['Cloud Compute'] == 'AWS Elastic Compute Cloud (EC2)') |\n                      (df_count_compute_2019['Cloud Compute'] == 'Google Compute Engine (GCE)') |\n                     (df_count_compute_2019['Cloud Compute'] == 'Azure Virtual Machines') |\n                     (df_count_compute_2019['Cloud Compute'] == 'None')\n                                             ]\n#----------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].replace({\n                                                'AWS Elastic Compute Cloud (EC2)': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Compute Engine (GCE)': 'Google Cloud Compute Engine',\n                                                'Azure Virtual Machines': 'Microsoft Azure Virtual Machines',\n                                                'None': 'No / None'\n                                               })\n\n\n\ncloud_computing_2020 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8','Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_computing_2020 = pros_2020[cloud_computing_2020]\ncount_compute_2020 = pd.Series(df_computing_2020[cloud_computing_2020].squeeze().values.ravel()).value_counts()\n#------------\ndf_count_compute_2020 = pd.DataFrame(count_compute_2020)\ndf_count_compute_2020 = df_count_compute_2020.reset_index()\ndf_count_compute_2020.columns = ['Cloud Compute', 'Counts']\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].str.strip()\ndf_count_compute_2020 = df_count_compute_2020[(df_count_compute_2020['Cloud Compute'] == 'Amazon EC2') |\n                      (df_count_compute_2020['Cloud Compute'] == 'Google Cloud Compute Engine') |\n                     (df_count_compute_2020['Cloud Compute'] == 'Azure Cloud Services') |\n                     (df_count_compute_2020['Cloud Compute'] == 'No / None')\n                     ]\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].replace({\n                                                'Amazon EC2': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Cloud Compute Engine': 'Google Cloud Compute Engine',\n                                                'Azure Cloud Services': 'Microsoft Azure Virtual Machines'\n                                               })\n\n\n\n#----------\ncloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\ndf_computing_2021 = pros_2021[cloud_computing_2021]\ncount_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n# ----------\ndf_count_compute_2021 = pd.DataFrame(count_compute_2021)\ndf_count_compute_2021 = df_count_compute_2021.reset_index()\ndf_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n#------------\ndf_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()\ndf_count_compute_2021 = df_count_compute_2021[(df_count_compute_2021['Cloud Compute'] != 'Other')]\n\ncloud_compute_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_compute_df = df_count_compute_2021.merge(df_count_compute_2020, on = 'Cloud Compute').merge(df_count_compute_2019, how = 'left')\ncloud_compute_df = cloud_compute_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\n\ncloud_compute_df = cloud_compute_df.T\ncloud_compute_df.columns = cloud_compute_df.iloc[0]\ncloud_compute_df = cloud_compute_df.drop(cloud_compute_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_compute_df = cloud_compute_df.iloc[::-1] # reverse ro\n\n# ---- percentage ----\n\nfor_perc = cloud_compute_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\n# ------- in 2 years --------\n\n\ncloud_computing_in_2 = ['Q29_B_Part_1','Q29_B_Part_2','Q29_B_Part_3','Q29_B_Part_4','Q29_B_OTHER']\n\ncount_cloud_computing_in_2 = pd.Series(pros_2021[cloud_computing_in_2].squeeze().values.ravel()).value_counts()\n\ndf_count_cloud_computing_in_2 = pd.DataFrame(count_cloud_computing_in_2)\ndf_count_cloud_computing_in_2 = df_count_cloud_computing_in_2.reset_index()\ndf_count_cloud_computing_in_2.columns = ['Cloud Compute', '2021']\ndf_count_cloud_computing_in_2 = df_count_cloud_computing_in_2.set_index('Cloud Compute').T\n\n\n# --- plot ---\n\nfig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (22,8))\nplt.subplot(131)   #  subplot 1\n\ncloud_compute_df.plot(kind = 'bar', ax= ax1)\nax1.set(title = \"Cloud platform product usage in regular basis in kaggle survey\")\nax1.legend(loc='lower right', bbox_to_anchor=(1.35, 0), prop={'size': 9})\n\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(132) #  subplot 2\n\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax2,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',)\n             )\nax2.set(title = \"Cloud platform product by share\")\nax2.legend(loc='lower right', bbox_to_anchor=(1.36, 0), prop={'size': 9})\nax2.annotate('Share of none is decreasing', xy=(1.6, 0.62), xytext=(0.06, 0.7),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )\n\nplt.subplot(133)\n\ndf_count_cloud_computing_in_2.plot(kind='bar', ax=ax3, color=['#ff7f0e','#d62728','#1f77b4','#2ca02c','#7f7f7f'])\nax3.set(title = \"Respondants who is willing to get familiar with cloud platform product in 2 year\")\nax3.legend(loc='lower right', bbox_to_anchor=(1.36, 0), prop={'size': 9})\nax3.text(0.01, 2500, 'AWS is pushed back to the third place',\n        verticalalignment='bottom',\n        fontsize=12)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:29.614258Z","iopub.execute_input":"2021-11-22T00:51:29.615010Z","iopub.status.idle":"2021-11-22T00:51:30.478034Z","shell.execute_reply.started":"2021-11-22T00:51:29.614969Z","shell.execute_reply":"2021-11-22T00:51:30.477025Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data_storage_regular_2021 = ['Q30_A_Part_1', 'Q30_A_Part_2','Q30_A_Part_3', 'Q30_A_Part_4', 'Q30_A_Part_5', 'Q30_A_Part_6', 'Q30_A_Part_7', 'Q30_A_OTHER']\n\ndf_data_storage_regular_2021 = pros_2021[data_storage_regular_2021]\ncount_data_storage_regular_2021 = pd.Series(df_data_storage_regular_2021[data_storage_regular_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_data_storage_regular_2021 = pd.DataFrame(count_data_storage_regular_2021)\ndf_count_data_storage_regular_2021 = df_count_data_storage_regular_2021.reset_index()\ndf_count_data_storage_regular_2021.columns = ['Storage', 'Counts']\ndf_count_data_storage_regular_2021 = df_count_data_storage_regular_2021.set_index('Storage').T\n\n\n\nfig, ax1 = plt.subplots(figsize = (11,8))\n\ndf_count_data_storage_regular_2021.plot(kind='bar', ax = ax1)\nax1.set(title=\"Bonus, respondant who uses cloud data storage product on a regular basis\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:30.479615Z","iopub.execute_input":"2021-11-22T00:51:30.480258Z","iopub.status.idle":"2021-11-22T00:51:30.816264Z","shell.execute_reply.started":"2021-11-22T00:51:30.480208Z","shell.execute_reply":"2021-11-22T00:51:30.815132Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Machine learning tools\n# Google cloud Speect-to-Text, Google Cloud Natural Language, Google Cloud Vision, Google Cloud Translation are assumed under Google Cloud Machine Learning\n\n\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\nml_product_2019 = ['Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8','Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12']\ndf_ml_product_2019 = pros_2019[ml_product_2019]\ncount_ml_product_2019 = pd.Series(df_ml_product_2019[ml_product_2019].squeeze().values.ravel()).value_counts()\n#count_ml_product_2019\n\ndf_count_ml_2019 = pd.DataFrame(count_ml_product_2019)\ndf_count_ml_2019 = df_count_ml_2019.reset_index()\ndf_count_ml_2019.columns = ['ML engine', 'Counts']\n\n#-------\n\nml_product_2020 = ['Q28_A_Part_1','Q28_A_Part_2','Q28_A_Part_3','Q28_A_Part_4','Q28_A_Part_5','Q28_A_Part_6','Q28_A_Part_7','Q28_A_Part_8','Q28_A_Part_9','Q28_A_Part_10']\ndf_ml_product_2020 = pros_2020[ml_product_2020]\ncount_ml_product_2020 = pd.Series(df_ml_product_2020[ml_product_2020].squeeze().values.ravel()).value_counts()\n#count_ml_product_2020\n\ndf_count_ml_2020 = pd.DataFrame(count_ml_product_2020)\ndf_count_ml_2020 = df_count_ml_2020.reset_index()\ndf_count_ml_2020.columns = ['ML engine', 'Counts']\n\n#-------\n\nml_product_2021 = ['Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_OTHER']\ndf_ml_product_2021 = pros_2021[ml_product_2021]\ncount_ml_product_2021 = pd.Series(df_ml_product_2021[ml_product_2021].squeeze().values.ravel()).value_counts()\n#count_ml_product_2021\n\ndf_count_ml_2021 = pd.DataFrame(count_ml_product_2021)\ndf_count_ml_2021 = df_count_ml_2021.reset_index()\ndf_count_ml_2021.columns = ['ML engine', 'Counts']\n\n\n# --------------\n\n# Products are merged into one big category. \n# ex1) google vision, google NLP - > Google Cloud Vertex AI\n# ex2) Amazon forecast, recognition - > Amazon SageMaker\n\ndf_count_ml_2019 = df_count_ml_2019.drop(df_count_ml_2019.index[[0,5,7,8,9,11]])\n#df_count_ml_2019\n\ndf_count_ml_2020 = df_count_ml_2020.drop(df_count_ml_2020.index[[0,4,5,6,7,8,9]])\n#df_count_ml_2020\n\ndf_count_ml_2021 = df_count_ml_2021.drop(df_count_ml_2021.index[[0, 7]])\n#df_count_ml_2021\n\nengine_df = df_count_ml_2021.merge(df_count_ml_2020, on = 'ML engine', how = 'outer').merge(df_count_ml_2019, how = 'outer')\nengine_df = engine_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\nengine_df['ML engine'] = engine_df['ML engine'].str.strip()\nengine_df.at[8, 'ML engine'] = 'Google Cloud Vertex AI'\nengine_df.at[9, 'ML engine'] = 'Google Cloud Vertex AI'\nengine_df = engine_df.groupby(['ML engine']).sum()\nengine_df = engine_df.sort_values(by=['2021'], ascending = False).reset_index()\n\nengine_df = engine_df.set_index('ML engine').T[::-1]\ncolumns_clean = ['Amazon SageMaker','Azure Machine Learning Studio','Databricks','Google Cloud Vertex AI','DataRobot','Rapidminer','Alteryx','Dataiku']\nengine_df = engine_df[columns_clean]\n\ndummy_df = engine_df[['Amazon SageMaker','Azure Machine Learning Studio','Google Cloud Vertex AI']]\ndummy_df['multiplier'] = None\ndummy_df['multiplier'] = dummy_df.sum(axis=1).pct_change(periods = 1)\ngrowth_multiplier_2020 = dummy_df['multiplier'].iloc[1]\ngrowth_multiplier_2021 = dummy_df['multiplier'].iloc[2]\n\nfor col in ['Databricks', 'DataRobot', 'Rapidminer', 'Alteryx', 'Dataiku']:\n    engine_df[col].iloc[1] = engine_df[col].iloc[2]/(1+growth_multiplier_2021)\n    engine_df[col].iloc[0] = engine_df[col].iloc[1]/(1+growth_multiplier_2020)\n\nengine_df = engine_df.round(0)\n\n# color_dict = {'Databricks': '#FF0000', 'Rapidminer': '#0000FF'}\n# engine_df.plot(kind='bar', ax=ax1, color = [color_dict.get(x, '#333333') for x in engine_df.columns])\n\n\n# market share\n\nfor_perc_engine = engine_df\nfor_perc_engine = for_perc_engine.divide(for_perc_engine.sum(axis=1), axis = 0)\n\nfor_perc_engine = for_perc_engine.round(2)\n\n# future usage in 2 years\n\nmanaged_ml_2021_2_year = ['Q31_B_Part_1','Q31_B_Part_2',\n                          'Q31_B_Part_3','Q31_B_Part_4',\n                          'Q31_B_Part_5','Q31_B_Part_6',\n                          'Q31_B_Part_7','Q31_B_Part_8',\n                          'Q31_B_Part_9','Q31_B_OTHER']\n\ndf_managed_ml_2021_2_year = pros_2021[managed_ml_2021_2_year]\n\ncount_managed_ml_2021_2_year = pd.Series(df_managed_ml_2021_2_year[managed_ml_2021_2_year].squeeze().values.ravel()).value_counts()\n\ndf_count_managed_ml_2021_2_year = pd.DataFrame(count_managed_ml_2021_2_year)\ndf_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year.reset_index()\ndf_count_managed_ml_2021_2_year.columns = ['Managed ML', 'Counts']\ndf_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year.set_index('Managed ML').T\ndf_count_managed_ml_2021_2_year.columns = df_count_managed_ml_2021_2_year.columns.str.strip()\ndf_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year[['Amazon SageMaker','Azure Machine Learning Studio',\n                                 'Google Cloud Vertex AI','Databricks', 'DataRobot', 'Rapidminer', 'Alteryx', 'Dataiku']]\ndf_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year.T.sort_values(by= 'Counts', ascending = False).T\n\n\n\n# ----- plot ------\n\nfig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (22,8))\n\nplt.subplot(131)   #  subplot 1\n\nengine_df.plot(kind='bar', ax=ax1)\n\nplt.annotate('* The number of Databricks, Datarobot, RapidMiner, Alteryx and Dataiku in 2019 and 2020 were derived from the yearly avg industry growth', \n             (0,0), \n             (-50,-50), \n             fontsize=8, \n             xycoords='axes fraction', \n             textcoords='offset points', va='top')\n\nplt.annotate(\"* Google vertex AI is launched in 2021. Google vertex AI in 2019 and 2020 is the sum of google's listed products. This applies to AWS and Azure too\", \n             (0,0), \n             (-50,-60), \n             fontsize=8, \n             xycoords='axes fraction', \n             textcoords='offset points', va='top')\n\n\nax1.set(title = \"Managed ML product usage on regular basis\")\nax1.legend(loc='upper left', prop={'size': 9})\n\nax1.annotate('Google pushed back', xy=(1.85, 600), xytext=(0.06, 730),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )\n\n\nplt.subplot(132)   #  subplot 2\n\nfor_perc_engine.plot(kind='area', \n              stacked=True,\n              ax = ax2,\n             )\nax2.legend(loc='lower right', prop={'size': 9})\nax2.set(title = \"Share of managed ML product usage\")\n\nax2.annotate('Google loses shares', xy=(1.6, 0.72), xytext=(0.06, 0.65),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )\n\nplt.subplot(133)   #  subplot 3\n\ndf_count_managed_ml_2021_2_year.plot(kind='bar', ax = ax3,\n                                    color=['#d62728','#ff7f0e','#1f77b4','#2ca02c','#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\nax3.legend(loc='lower right', bbox_to_anchor=(1.36, 0), prop={'size': 9})\nax3.set(title = \"Willingness to become more familiar in the next 2 years\")\n\nax3.annotate('Google is back to 1st', xy=(-0.1, 1800), xytext=(0.06, 2000),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:30.818235Z","iopub.execute_input":"2021-11-22T00:51:30.818569Z","iopub.status.idle":"2021-11-22T00:51:31.807177Z","shell.execute_reply.started":"2021-11-22T00:51:30.818528Z","shell.execute_reply":"2021-11-22T00:51:31.805954Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:10:28.206456Z","iopub.execute_input":"2021-11-22T02:10:28.206772Z","iopub.status.idle":"2021-11-22T02:10:29.222625Z","shell.execute_reply.started":"2021-11-22T02:10:28.206720Z","shell.execute_reply":"2021-11-22T02:10:29.221481Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big_data_2_year = [\n    'Q32_B_Part_1',\n    'Q32_B_Part_2',\n    'Q32_B_Part_3',\n    'Q32_B_Part_4',\n    'Q32_B_Part_5',\n    'Q32_B_Part_6',\n    'Q32_B_Part_7',\n    'Q32_B_Part_8',\n    'Q32_B_Part_9',\n    'Q32_B_Part_10',\n    'Q32_B_Part_11',\n    'Q32_B_Part_12',\n    'Q32_B_Part_13',\n    'Q32_B_Part_14',\n    'Q32_B_Part_15',\n    'Q32_B_Part_16',\n    'Q32_B_Part_17',\n    'Q32_B_Part_18',\n    'Q32_B_Part_19',\n    'Q32_B_Part_20',\n    'Q32_B_OTHER'\n]\n\n\n\n\ndf_bigdata_2021_2 = pros_2021[big_data_2_year]\ncount_bigdata_2021_2 = pd.Series(df_bigdata_2021_2[big_data_2_year].squeeze().values.ravel()).value_counts()\n#count_bigdata_2021\n\ndf_count_bigdata_2021_2 = pd.DataFrame(count_bigdata_2021_2)\ndf_count_bigdata_2021_2 = df_count_bigdata_2021_2.reset_index()\ndf_count_bigdata_2021_2.columns = ['big data', 'Counts']\ndf_count_bigdata_2021_2 = df_count_bigdata_2021_2.set_index('big data').T\n\nfig, ax = plt.subplots(figsize = (22,8))\ndf_count_bigdata_2021_2.plot(kind='bar', ax =ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Big data products\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:32.704727Z","iopub.execute_input":"2021-11-22T00:51:32.705084Z","iopub.status.idle":"2021-11-22T00:51:32.776052Z","shell.execute_reply.started":"2021-11-22T00:51:32.705056Z","shell.execute_reply":"2021-11-22T00:51:32.775279Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"big_data_2021 = ['Q32_A_Part_1','Q32_A_Part_2',\n                 'Q32_A_Part_3','Q32_A_Part_4',\n                 'Q32_A_Part_5','Q32_A_Part_6',\n                 'Q32_A_Part_7','Q32_A_Part_8',\n                 'Q32_A_Part_9','Q32_A_Part_10',\n                 'Q32_A_Part_11','Q32_A_Part_12',\n                 'Q32_A_Part_13','Q32_A_Part_14',\n                 'Q32_A_Part_15','Q32_A_Part_16',\n                 'Q32_A_Part_17','Q32_A_Part_18',\n                 'Q32_A_Part_19','Q32_A_Part_20','Q32_A_OTHER']\n\n\n\ndf_bigdata_2021 = pros_2021[big_data_2021]\ncount_bigdata_2021 = pd.Series(df_bigdata_2021[big_data_2021].squeeze().values.ravel()).value_counts()\n#count_bigdata_2021\n\ndf_count_bigdata_2021 = pd.DataFrame(count_bigdata_2021)\ndf_count_bigdata_2021 = df_count_bigdata_2021.reset_index()\ndf_count_bigdata_2021.columns = ['big data', 'Counts']\n\n# --------------------\n\nbig_data_2020 = ['Q29_A_Part_1','Q29_A_Part_2',\n                 'Q29_A_Part_3','Q29_A_Part_4',\n                 'Q29_A_Part_5','Q29_A_Part_6',\n                 'Q29_A_Part_7','Q29_A_Part_8',\n                 'Q29_A_Part_9','Q29_A_Part_10',\n                 'Q29_A_Part_11','Q29_A_Part_12',\n                 'Q29_A_Part_13','Q29_A_Part_14',\n                 'Q29_A_Part_15','Q29_A_Part_16',\n                 'Q29_A_Part_17','Q29_A_OTHER']\n\ndf_bigdata_2020 = pros_2020[big_data_2020]\ncount_bigdata_2020 = pd.Series(df_bigdata_2020[big_data_2020].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_bigdata_2020 = pd.DataFrame(count_bigdata_2020)\ndf_count_bigdata_2020 = df_count_bigdata_2020.reset_index()\ndf_count_bigdata_2020.columns = ['big data', 'Counts']\n\n# ----------------------\n\nbig_data_2019 = ['Q34_Part_1','Q34_Part_2',\n                 'Q34_Part_3','Q34_Part_4',\n                 'Q34_Part_5','Q34_Part_6',\n                 'Q34_Part_7','Q34_Part_8',\n                 'Q34_Part_9','Q34_Part_10',\n                 'Q34_Part_11','Q34_Part_12',\n                 'Q34_OTHER_TEXT']\n\ndf_bigdata_2019 = pros_2019[big_data_2019]\ncount_bigdata_2019 = pd.Series(df_bigdata_2019[big_data_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_bigdata_2019 = pd.DataFrame(count_bigdata_2019)\ndf_count_bigdata_2019 = df_count_bigdata_2019.reset_index()\ndf_count_bigdata_2019.columns = ['big data', 'Counts']\ndf_count_bigdata_2019 = df_count_bigdata_2019[(df_count_bigdata_2019['big data'] == 'MySQL') |\n                                              (df_count_bigdata_2019['big data'] == 'PostgresSQL') |\n                                              (df_count_bigdata_2019['big data'] == 'Microsoft SQL Server') |\n                                              (df_count_bigdata_2019['big data'] == 'SQLite') |\n                                              (df_count_bigdata_2019['big data'] == 'Oracle Database') |\n                                              (df_count_bigdata_2019['big data'] == 'AWS Relational Database Service') |\n                                              (df_count_bigdata_2019['big data'] == 'Microsoft Access') |\n                                              (df_count_bigdata_2019['big data'] == 'Google Cloud SQL') |\n                                              (df_count_bigdata_2019['big data'] == 'Azure SQL Database') |\n                                              (df_count_bigdata_2019['big data'] == 'AWS DynamoDB')\n                                             ]\n\ndef open_source(x):\n    if x == 'MySQL':\n        return 1\n    elif x == 'PostgreSQL':\n        return 1\n    elif x == 'MongoDB':\n        return 1\n    elif x == 'SQLite':\n        return 1\n    elif x == 'PostgresSQL':\n        return 1\n    else:\n        return 0\n    \ndef aws(x):\n    if 'Amazon' in x:\n        return 1\n    elif 'AWS' in x:\n        return 1\n    else:\n        return 0\n    \ndef gcp(x):\n    if 'Google' in x:\n        return 1\n    else:\n        return 0\n    \ndef azure(x):\n    if 'Microsoft' in x:\n        return 1\n    elif 'Azure' in x:\n        return 1\n    else: return 0\n\ndf_count_bigdata_2021['big data'] = df_count_bigdata_2021['big data'].str.strip()\ndf_count_bigdata_2021['open source'] = df_count_bigdata_2021['big data'].apply(open_source)\ndf_count_bigdata_2021['aws'] = df_count_bigdata_2021['big data'].apply(aws)\ndf_count_bigdata_2021['gcp'] = df_count_bigdata_2021['big data'].apply(gcp)\ndf_count_bigdata_2021['azure'] = df_count_bigdata_2021['big data'].apply(azure)\n\nopen_source_2021 = df_count_bigdata_2021[df_count_bigdata_2021['open source'] == 1]\nopen_source_2021 = open_source_2021[['big data', 'Counts']]\n\naws_2021 = df_count_bigdata_2021[df_count_bigdata_2021['aws'] == 1]\ngcp_2021 = df_count_bigdata_2021[df_count_bigdata_2021['gcp'] == 1]\nazure_2021 = df_count_bigdata_2021[df_count_bigdata_2021['azure'] == 1]\nothers_2021 = df_count_bigdata_2021[(df_count_bigdata_2021['aws'] != 1) & \n                                    (df_count_bigdata_2021['gcp'] != 1) & \n                                    (df_count_bigdata_2021['azure'] != 1) &\n                                    (df_count_bigdata_2021['open source'] != 1)]\n\naws_2021['big data'].iloc[0] = 'aws'\ngcp_2021['big data'].iloc[0] = 'gcp'\nazure_2021['big data'].iloc[0] = 'azure'\n\ncommercial_2021 = aws_2021.iloc[:1].append([gcp_2021.iloc[:1], azure_2021.iloc[:1], others_2021])\nto_drop = ['None', 'Other']\ncommercial_2021 = commercial_2021[~commercial_2021['big data'].isin(to_drop)]\ncommercial_2021 = commercial_2021[['big data', 'Counts']]\n\nopen_source_2021 = open_source_2021.merge(commercial_2021, on = 'big data', how = 'outer')\nopen_source_2021 = open_source_2021.rename(columns = {'Counts_x' : 'open source_2021', 'Counts_y' : 'commercial_2021'})\n\nopen_source_2021 = open_source_2021.set_index('big data').T\n\n#fig, ax1 = plt.subplots(figsize = (16,8))\n#open_source_2021.plot(kind = 'bar', stacked = True, ax = ax1)\n\n\n# -------------\n\ndf_count_bigdata_2020['big data'] = df_count_bigdata_2020['big data'].str.strip()\ndf_count_bigdata_2020['open source'] = df_count_bigdata_2020['big data'].apply(open_source)\ndf_count_bigdata_2020['aws'] = df_count_bigdata_2020['big data'].apply(aws)\ndf_count_bigdata_2020['gcp'] = df_count_bigdata_2020['big data'].apply(gcp)\ndf_count_bigdata_2020['azure'] = df_count_bigdata_2020['big data'].apply(azure)\n\nopen_source_2020 = df_count_bigdata_2020[df_count_bigdata_2020['open source'] == 1]\nopen_source_2020 = open_source_2020[['big data', 'Counts']]\n\naws_2020 = df_count_bigdata_2020[df_count_bigdata_2020['aws'] == 1]\ngcp_2020 = df_count_bigdata_2020[df_count_bigdata_2020['gcp'] == 1]\nazure_2020 = df_count_bigdata_2020[df_count_bigdata_2020['azure'] == 1]\nothers_2020 = df_count_bigdata_2020[(df_count_bigdata_2020['aws'] != 1) & \n                                    (df_count_bigdata_2020['gcp'] != 1) & \n                                    (df_count_bigdata_2020['azure'] != 1) &\n                                    (df_count_bigdata_2020['open source'] != 1)]\n\naws_2020['big data'].iloc[0] = 'aws'\ngcp_2020['big data'].iloc[0] = 'gcp'\nazure_2020['big data'].iloc[0] = 'azure'\n\ncommercial_2020 = aws_2020.iloc[:1].append([gcp_2020.iloc[:1], azure_2020.iloc[:1], others_2020])\nto_drop = ['None', 'Other']\ncommercial_2020 = commercial_2020[~commercial_2020['big data'].isin(to_drop)]\ncommercial_2020 = commercial_2020[['big data', 'Counts']]\n\nopen_source_2020 = open_source_2020.merge(commercial_2020, on = 'big data', how = 'outer')\nopen_source_2020 = open_source_2020.rename(columns = {'Counts_x' : 'open source_2020', 'Counts_y' : 'commercial_2020'})\n\nopen_source_2020 = open_source_2020.set_index('big data').T\n\n# -------------\n\ndf_count_bigdata_2019['big data'] = df_count_bigdata_2019['big data'].str.strip()\ndf_count_bigdata_2019['open source'] = df_count_bigdata_2019['big data'].apply(open_source)\ndf_count_bigdata_2019['aws'] = df_count_bigdata_2019['big data'].apply(aws)\ndf_count_bigdata_2019['gcp'] = df_count_bigdata_2019['big data'].apply(gcp)\ndf_count_bigdata_2019['azure'] = df_count_bigdata_2019['big data'].apply(azure)\n\nopen_source_2019 = df_count_bigdata_2019[df_count_bigdata_2019['open source'] == 1]\nopen_source_2019 = open_source_2019[['big data', 'Counts']]\n\naws_2019 = df_count_bigdata_2019[df_count_bigdata_2019['aws'] == 1]\ngcp_2019 = df_count_bigdata_2019[df_count_bigdata_2019['gcp'] == 1]\nazure_2019 = df_count_bigdata_2019[df_count_bigdata_2019['azure'] == 1]\nothers_2019 = df_count_bigdata_2019[(df_count_bigdata_2019['aws'] != 1) & \n                                    (df_count_bigdata_2019['gcp'] != 1) & \n                                    (df_count_bigdata_2019['azure'] != 1) &\n                                    (df_count_bigdata_2019['open source'] != 1)]\n\naws_2019['big data'].iloc[0] = 'aws'\ngcp_2019['big data'].iloc[0] = 'gcp'\nazure_2019['big data'].iloc[0] = 'azure'\n\ncommercial_2019 = aws_2019.iloc[:1].append([gcp_2019.iloc[:1], azure_2019.iloc[:1], others_2019])\nto_drop = ['None', 'Other']\ncommercial_2019 = commercial_2019[~commercial_2019['big data'].isin(to_drop)]\ncommercial_2019 = commercial_2019[['big data', 'Counts']]\n\nopen_source_2019 = open_source_2019.merge(commercial_2019, on = 'big data', how = 'outer')\nopen_source_2019 = open_source_2019.rename(columns = {'Counts_x' : 'open source_2019', 'Counts_y' : 'commercial_2019'})\n\nopen_source_2019 = open_source_2019.set_index('big data').T\n\nbig_data_usage = pd.concat([open_source_2021, open_source_2020, open_source_2019])\nbig_data_usage['PostgresSQL'] = big_data_usage['PostgresSQL'].fillna(big_data_usage['PostgreSQL'])\nbig_data_usage = big_data_usage.drop(['PostgreSQL'], axis = 1)\n\n\n# --- plot ----\n\nbig_data_usage[\"total\"] = big_data_usage.sum(axis=1)\nexample = big_data_usage['total']\nexample_2021 = example[:2]\nexample_2020 = example[2:4]\nexample_2019 = example[4:6]\n\nk_2021 = pd.DataFrame(example_2021)\nk_2021 = k_2021.rename(index = ({'open source_2021': 'open source', 'commercial_2021': 'commercial'}), columns=({'total': '2021'}))\n\n\nk_2020 = pd.DataFrame(example_2020)\nk_2020 = k_2020.rename(index = ({'open source_2020': 'open source', 'commercial_2020': 'commercial'}), columns=({'total': '2020'}))\n\n\n\nk_2019 = pd.DataFrame(example_2019)\nk_2019 = k_2019.rename(index = ({'open source_2019': 'open source', 'commercial_2019': 'commercial'}), columns=({'total': '2019'}))\n\nk_2021['2020'] = k_2020\nk_2021['2019'] = k_2019\nk_2021 = k_2021.iloc[:, ::-1]\nk_2021 = k_2021.T\n\nk_2021.plot(kind='bar', stacked = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:15:26.402111Z","iopub.execute_input":"2021-11-22T02:15:26.402408Z","iopub.status.idle":"2021-11-22T02:15:27.352529Z","shell.execute_reply.started":"2021-11-22T02:15:26.402378Z","shell.execute_reply":"2021-11-22T02:15:27.351458Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"k_2021_pct = k_2021.pct_change(periods=1)\nk_2021_pct","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:29:15.073392Z","iopub.execute_input":"2021-11-22T02:29:15.073684Z","iopub.status.idle":"2021-11-22T02:29:15.085190Z","shell.execute_reply.started":"2021-11-22T02:29:15.073653Z","shell.execute_reply":"2021-11-22T02:29:15.084379Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"big_data_usage.drop(['total'], axis = 1, inplace = True)\nbig_data_usage = big_data_usage.T\n\nbig_data_usage_open_source = big_data_usage[['open source_2019', 'open source_2020', 'open source_2021']]\nbig_data_usage_open_source.dropna(axis = 0, how = 'all', inplace = True)\n\nbig_data_usage_commercial = big_data_usage[['commercial_2019', 'commercial_2020', 'commercial_2021']]\nbig_data_usage_commercial.dropna(axis = 0, how = 'all', inplace = True)\n\nfig, axes = plt.subplots(1,3, figsize=(16,8))\nfor ax, col in zip(axes, big_data_usage_open_source.columns):\n    big_data_usage_open_source[col].plot(kind='pie', legend=False, ax=ax, autopct='%0.2f', title=col)\n    ax.set(ylabel='', aspect='equal')\n\naxes[0].legend(bbox_to_anchor=(0, 0.5))\n\n\nfig, axes = plt.subplots(1,3, figsize=(16,8))\nfor ax, col in zip(axes, big_data_usage_commercial.columns):\n    big_data_usage_commercial[col].plot(kind='pie', legend=False, ax=ax, autopct='%0.2f', title=col)\n    ax.set(ylabel='', aspect='equal')\n\naxes[0].legend(bbox_to_anchor=(0, 0.5))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:15:29.597177Z","iopub.execute_input":"2021-11-22T02:15:29.598290Z","iopub.status.idle":"2021-11-22T02:15:30.539809Z","shell.execute_reply.started":"2021-11-22T02:15:29.598208Z","shell.execute_reply":"2021-11-22T02:15:30.538827Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"markdown","source":"Business Intelligence","metadata":{}},{"cell_type":"code","source":"big_data_2021 = ['Q32_A_Part_1','Q32_A_Part_2',\n                 'Q32_A_Part_3','Q32_A_Part_4',\n                 'Q32_A_Part_5','Q32_A_Part_6',\n                 'Q32_A_Part_7','Q32_A_Part_8',\n                 'Q32_A_Part_9','Q32_A_Part_10',\n                 'Q32_A_Part_11','Q32_A_Part_12',\n                 'Q32_A_Part_13','Q32_A_Part_14',\n                 'Q32_A_Part_15','Q32_A_Part_16',\n                 'Q32_A_Part_17','Q32_A_Part_18',\n                 'Q32_A_Part_19','Q32_A_Part_20','Q32_A_OTHER']\n\n\n\ndf_bigdata_2021 = pros_2021[big_data_2021]\ncount_bigdata_2021 = pd.Series(df_bigdata_2021[big_data_2021].squeeze().values.ravel()).value_counts()\n#count_bigdata_2021\n\ndf_count_bigdata_2021 = pd.DataFrame(count_bigdata_2021)\ndf_count_bigdata_2021 = df_count_bigdata_2021.reset_index()\ndf_count_bigdata_2021.columns = ['big data', 'Counts']\ndf_count_bigdata_2021 = df_count_bigdata_2021.set_index('big data').T\ndf_count_bigdata_2021.columns = df_count_bigdata_2021.columns.str.strip()\n\ndf_count_bigdata_2021_open_source = pd.DataFrame()\ndf_count_bigdata_2021_commercial = pd.DataFrame()\n\ndf_count_bigdata_2021_open_source = df_count_bigdata_2021[['MySQL', 'PostgreSQL', 'MongoDB', 'SQLite']]\ndf_count_bigdata_2021_commercial = df_count_bigdata_2021[['Microsoft SQL Server', \n                                                          'Oracle Database',\n                                                         'Google Cloud BigQuery',\n                                                         'Microsoft Azure SQL Database',\n                                                         'Amazon RDS',\n                                                         'Google Cloud SQL',\n                                                         'Amazon Redshift',\n                                                         'Snowflake',\n                                                         'Amazon DynamoDB',\n                                                         'Microsoft Azure Cosmos DB',\n                                                         'Google Cloud Firestore',\n                                                         'IBM Db2',\n                                                         'Google Cloud BigTable',\n                                                         'Amazon Aurora',\n                                                         'Google Cloud Spanner']]\n\n\nmost_often_dbs = pd.DataFrame(pros_2021['Q33'].value_counts())\nmost_often_dbs = most_often_dbs.T\nmost_often_dbs.columns = most_often_dbs.columns.str.strip()\nmost_often_dbs = most_often_dbs[['MySQL', 'PostgreSQL', 'MongoDB', 'SQLite']]\nmost_often_dbs = most_often_dbs.T\nmost_often_dbs = most_often_dbs.reset_index()\nmost_often_dbs = most_often_dbs.rename(columns = {'index':'big data'})\n\ndf_count_bigdata_2021_2.columns = df_count_bigdata_2021_2.columns.str.strip()\ndf_count_bigdata_2021_2_open = df_count_bigdata_2021_2[['MySQL', 'PostgreSQL', 'MongoDB', 'SQLite']]\ndf_count_bigdata_2021_2_open = df_count_bigdata_2021_2_open.T\ndf_count_bigdata_2021_2_open = df_count_bigdata_2021_2_open.reset_index()\n\ndf_count_bigdata_2021_open_source = df_count_bigdata_2021_open_source.T\ndf_count_bigdata_2021_open_source = df_count_bigdata_2021_open_source.reset_index()\n\nmerged_micro_db = df_count_bigdata_2021_open_source.merge(df_count_bigdata_2021_2_open, on ='big data').merge(most_often_dbs, on = 'big data')\nmerged_micro_db = merged_micro_db.rename(columns = {'Counts_x': 'regularly use',\n                                                   'Counts_y': 'Most often use',\n                                                   'Q33': 'Hope to get familiar in 2 years'})\nmerged_micro_db_open = merged_micro_db.set_index('big data').T\n\nmost_often_dbs = pd.DataFrame(pros_2021['Q33'].value_counts())\nmost_often_dbs = most_often_dbs.T\nmost_often_dbs.columns = most_often_dbs.columns.str.strip()\nmost_often_dbs = most_often_dbs[['Microsoft SQL Server', \n                                                          'Oracle Database',\n                                                         'Google Cloud BigQuery',\n                                                         'Microsoft Azure SQL Database',\n                                                         'Amazon RDS',\n                                                         'Google Cloud SQL',\n                                                         'Amazon Redshift',\n                                                         'Snowflake',\n                                                         'Amazon DynamoDB',\n                                                         'Microsoft Azure Cosmos DB',\n                                                         'Google Cloud Firestore',\n                                                         'IBM Db2',\n                                                         'Google Cloud BigTable',\n                                                         'Amazon Aurora',\n                                                         'Google Cloud Spanner']]\nmost_often_dbs = most_often_dbs.T\nmost_often_dbs = most_often_dbs.reset_index()\nmost_often_dbs = most_often_dbs.rename(columns = {'index':'big data'})\n\ndf_count_bigdata_2021_2.columns = df_count_bigdata_2021_2.columns.str.strip()\ndf_count_bigdata_2021_2_commercial = df_count_bigdata_2021_2[['Microsoft SQL Server', \n                                                          'Oracle Database',\n                                                         'Google Cloud BigQuery',\n                                                         'Microsoft Azure SQL Database',\n                                                         'Amazon RDS',\n                                                         'Google Cloud SQL',\n                                                         'Amazon Redshift',\n                                                         'Snowflake',\n                                                         'Amazon DynamoDB',\n                                                         'Microsoft Azure Cosmos DB',\n                                                         'Google Cloud Firestore',\n                                                         'IBM Db2',\n                                                         'Google Cloud BigTable',\n                                                         'Amazon Aurora',\n                                                         'Google Cloud Spanner']]\n\ndf_count_bigdata_2021_2_commercial = df_count_bigdata_2021_2_commercial.T\ndf_count_bigdata_2021_2_commercial = df_count_bigdata_2021_2_commercial.reset_index()\n\ndf_count_bigdata_2021_commercial = df_count_bigdata_2021_commercial.T\ndf_count_bigdata_2021_commercial = df_count_bigdata_2021_commercial.reset_index()\n\nmerged_micro_db = df_count_bigdata_2021_commercial.merge(df_count_bigdata_2021_2_commercial, on ='big data').merge(most_often_dbs, on = 'big data')\nmerged_micro_db = merged_micro_db.rename(columns = {'Counts_x': 'regularly use',\n                                                   'Counts_y': 'Most often use',\n                                                   'Q33': 'Hope to get familiar in 2 years'})\nmerged_micro_db_commercial = merged_micro_db.set_index('big data').T\n\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (22,8))\ngs = gridspec.GridSpec(1, 2, width_ratios=[1, 3]) \nax1 = plt.subplot(gs[0])\n\nmerged_micro_db_open.plot(kind='bar', ax= ax1)\n\nax1.set(title = \"Open source big data product\",\n      xlabel = \"Survey questions\",\n      ylabel = \"Counts\")\n\nax1.annotate('MongoDB > PostgreSQL', xy=(1, 1800), xytext=(0.06, 2000),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )\n\nax2 = plt.subplot(gs[1])\n\nmerged_micro_db_commercial.plot(kind='bar', ax= ax2)\n\nax2.set(title = \"Commercial big data product\",\n      xlabel = \"Survey questions\",\n      ylabel = \"Counts\")\n\nax2.annotate('Notable strength of Google family', xy=(0.95, 1500), xytext=(0.2, 1800),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-22T02:11:37.297043Z","iopub.execute_input":"2021-11-22T02:11:37.297840Z","iopub.status.idle":"2021-11-22T02:11:38.314719Z","shell.execute_reply.started":"2021-11-22T02:11:37.297793Z","shell.execute_reply":"2021-11-22T02:11:38.313913Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"viz_bi_2020 =['Q14_Part_1','Q14_Part_2',\n              'Q14_Part_3','Q14_Part_4',\n              'Q14_Part_5','Q14_Part_6',\n              'Q14_Part_7','Q14_Part_8',\n              'Q14_Part_9','Q14_Part_10',\n              'Q14_Part_11','Q14_OTHER',\n              'Q31_A_Part_1','Q31_A_Part_2',\n              'Q31_A_Part_3','Q31_A_Part_4',\n              'Q31_A_Part_5','Q31_A_Part_6',\n              'Q31_A_Part_7','Q31_A_Part_8',\n              'Q31_A_Part_9','Q31_A_Part_10',\n              'Q31_A_Part_11','Q31_A_Part_12',\n              'Q31_A_Part_13','Q31_A_Part_14','Q31_A_OTHER']\n\nlib_BI_2020 = pros_2020[viz_bi_2020].rename(columns ={\n    'Q14_Part_1': 'Matplotlib',\n    'Q14_Part_2': 'Seaborn',\n    'Q14_Part_3': 'Plotly',\n    'Q14_Part_4': 'Ggplot',\n    'Q14_Part_5': 'Shiny',\n    'Q14_Part_6': 'D3 js',\n    'Q14_Part_7': 'Altair',\n    'Q14_Part_8': 'Bokeh',\n    'Q14_Part_9': 'Geoplotlib',\n    'Q14_Part_10': 'Leaflet',\n    'Q14_Part_11': 'None',\n    'Q14_OTHER': 'Other',\n    \n    'Q31_A_Part_1': 'Amazon QuickSight',\n    'Q31_A_Part_2': 'MS Power BI',\n    'Q31_A_Part_3': 'Google Data Studio',\n    'Q31_A_Part_4': 'Looker',\n    'Q31_A_Part_5': 'Tableau',\n    'Q31_A_Part_6': 'Salesforce',\n    'Q31_A_Part_7': 'Einstein Analytics',\n    'Q31_A_Part_8': 'Qlik',\n    'Q31_A_Part_9': 'Domo',\n    'Q31_A_Part_10': 'TIBCO',\n    'Q31_A_Part_11': 'Alteryx',\n    'Q31_A_Part_12': 'Sisense',\n    'Q31_A_Part_13': 'SAP',\n    'Q31_A_Part_14': 'None',\n    'Q31_A_OTHER': 'Other'\n})\n\nlib_2020 = ['Matplotlib',\n    'Seaborn',\n    'Plotly',\n    'Ggplot']\n\nBI_2020 = ['Amazon QuickSight',\n    'MS Power BI',\n    'Google Data Studio',\n    'Looker',\n    'Tableau',\n    'Salesforce',\n    'Einstein Analytics',\n    'Qlik',\n    'Domo',\n    'TIBCO',\n    'Alteryx',\n    'Sisense',\n    'SAP'\n    ]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:34.151434Z","iopub.execute_input":"2021-11-22T00:51:34.151701Z","iopub.status.idle":"2021-11-22T00:51:34.169258Z","shell.execute_reply.started":"2021-11-22T00:51:34.151671Z","shell.execute_reply":"2021-11-22T00:51:34.168288Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\n# ----- library growth -----\n\ndata_viz_li_2019 = ['Q20_Part_1',\n                    'Q20_Part_2',\n                    'Q20_Part_3',\n                    'Q20_Part_4',\n                    'Q20_Part_5',\n                    'Q20_Part_6',\n                    'Q20_Part_7',\n                    'Q20_Part_8',\n                    'Q20_Part_9',\n                    'Q20_Part_10',\n                    'Q20_Part_11',\n                    'Q20_Part_12']\n\ndf_data_viz_li_2019 = pros_2019[data_viz_li_2019]\n\n\ncount_data_viz_li_2019 = pd.Series(df_data_viz_li_2019[data_viz_li_2019].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_data_viz_li_2019 = pd.DataFrame(count_data_viz_li_2019)\ndf_count_data_viz_li_2019 = df_count_data_viz_li_2019.reset_index()\ndf_count_data_viz_li_2019.columns = ['lib', 'Counts']\ndf_count_data_viz_li_2019\n\n\ndata_viz_li_2020 =['Q14_Part_1','Q14_Part_2',\n              'Q14_Part_3','Q14_Part_4',\n              'Q14_Part_5','Q14_Part_6',\n              'Q14_Part_7','Q14_Part_8',\n              'Q14_Part_9','Q14_Part_10',\n              'Q14_Part_11','Q14_OTHER']\n\ndf_data_viz_li_2020 = pros_2020[data_viz_li_2020]\n\n\ncount_data_viz_li_2020 = pd.Series(df_data_viz_li_2020[data_viz_li_2020].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_data_viz_li_2020 = pd.DataFrame(count_data_viz_li_2020)\ndf_count_data_viz_li_2020 = df_count_data_viz_li_2020.reset_index()\ndf_count_data_viz_li_2020.columns = ['lib', 'Counts']\ndf_count_data_viz_li_2020\n\nviz_bi_2021 = ['Q14_Part_1','Q14_Part_2',\n                         'Q14_Part_3','Q14_Part_4',\n                         'Q14_Part_5','Q14_Part_6',\n                         'Q14_Part_7','Q14_Part_8',\n                         'Q14_Part_9','Q14_Part_10',\n                         'Q14_Part_11','Q14_OTHER']\n\ndf_data_viz_li_2021 = pros_2021[viz_bi_2021]\n\n\ncount_data_viz_li_2021 = pd.Series(df_data_viz_li_2021[viz_bi_2021].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_data_viz_li_2021 = pd.DataFrame(count_data_viz_li_2021)\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.reset_index()\ndf_count_data_viz_li_2021.columns = ['lib', 'Counts']\n\n# ---------------\n\n#print(df_count_data_viz_li_2021)\n#print(df_count_data_viz_li_2020)\n#print(df_count_data_viz_li_2019)\n\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.merge(df_count_data_viz_li_2020, on = 'lib', how = 'outer')\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.merge(df_count_data_viz_li_2019, on = 'lib', how = 'outer')\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.rename(columns = {'Counts_x' : '2021 ', 'Counts_y' : '2020', 'Counts': '2019'})\ndf_count_data_viz_li_2021.at[8,'lib'] = 'D3.js'\ndf_count_data_viz_li_2021.at[8,'2019'] = df_count_data_viz_li_2021.at[12,'2019']\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021[:-1]\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.set_index('lib').T\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021[::-1]\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.drop(columns = ['None'])\n\ndf_count_data_viz_li_2021_perc = df_count_data_viz_li_2021.pct_change(periods = 1)[1:]\n\n# pct_change\ndata_viz_growth = pd.DataFrame()\ndata_viz_growth['total'] = df_count_data_viz_li_2021.sum(axis=1)\ndata_viz_growth_perc = data_viz_growth.pct_change(periods = 1)\n\n\navg_growth_2020 = round(data_viz_growth_perc.iloc[1].mean(),2)\navg_growth_2021 = round(data_viz_growth_perc.iloc[2].mean(),2)\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(22,8))\n\nplt.subplot(121)   #  subplot 1\n\ndf_count_data_viz_li_2021.plot(kind='bar', ax = ax1)\nax1.set(title = \"Visualization Library usage by professionals in kaggle survey\")\nax1.legend(loc=2, prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.2)\n\n\nplt.subplot(122)   #  subplot 2\n\ndf_count_data_viz_li_2021_perc.plot(kind = 'bar', ax=ax2)\nax2.legend(loc=4, prop={'size': 9})\nplt.axhline(y=0, xmin=-1, xmax= 2, color='red', linestyle='dotted', linewidth=5)\n\nplt.axhline(y=avg_growth_2020, xmin=0.05, xmax= 0.45, color='black', linestyle='dotted', linewidth=5)\nplt.axhline(y=avg_growth_2021, xmin=0.55, xmax= 0.95, color='black', linestyle='dotted', linewidth=5)\n\nax2.text(0.26, 0.08, 'Average growth rate ' +str(avg_growth_2020*100) + '%')\nax2.text(0.25, 0.35, 'Average growth rate '+ str(avg_growth_2021*100) + '%')\n\nax2.set(title = \"Visualization library usage growth rate compare to previous year\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:34.170977Z","iopub.execute_input":"2021-11-22T00:51:34.171571Z","iopub.status.idle":"2021-11-22T00:51:35.214918Z","shell.execute_reply.started":"2021-11-22T00:51:34.171520Z","shell.execute_reply":"2021-11-22T00:51:35.214073Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Covid related spike","metadata":{}},{"cell_type":"code","source":"viz_2021 = ['Q34_A_Part_1','Q34_A_Part_2',\n                    'Q34_A_Part_3','Q34_A_Part_4',\n                    'Q34_A_Part_5','Q34_A_Part_6',\n                    'Q34_A_Part_7','Q34_A_Part_8',\n                    'Q34_A_Part_9','Q34_A_Part_10',\n                    'Q34_A_Part_11','Q34_A_Part_12',\n                    'Q34_A_Part_13','Q34_A_Part_14',\n                    'Q34_A_Part_15','Q34_A_Part_16','Q34_A_OTHER']\ndf_viz_2021 = pd.Series(pros_2021[viz_2021].squeeze().values.ravel()).value_counts()\n    \ndf_count_viz_2021 = pd.DataFrame(df_viz_2021)\ndf_count_viz_2021 = df_count_viz_2021.reset_index()\ndf_count_viz_2021.columns = ['BI tools', '2021']\n\ndf_count_viz_2021 = df_count_viz_2021[1:] # Drop None\n\nviz_2020 = ['Q31_A_Part_1','Q31_A_Part_2',\n              'Q31_A_Part_3','Q31_A_Part_4',\n              'Q31_A_Part_5','Q31_A_Part_6',\n              'Q31_A_Part_7','Q31_A_Part_8',\n              'Q31_A_Part_9','Q31_A_Part_10',\n              'Q31_A_Part_11','Q31_A_Part_12',\n              'Q31_A_Part_13','Q31_A_Part_14','Q31_A_OTHER']\ndf_viz_2020 = pd.Series(pros_2020[viz_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_viz_2020 = pd.DataFrame(df_viz_2020)\ndf_count_viz_2020 = df_count_viz_2020.reset_index()\ndf_count_viz_2020.columns = ['BI tools', '2020']\n\ndf_count_viz_2020 = df_count_viz_2020[1:] # Drop None\n\nmerged_viz = df_count_viz_2021.set_index('BI tools').combine_first(df_count_viz_2020.set_index('BI tools'))\nmerged_viz = merged_viz.sort_values(by=['2021'], ascending = False)\n\n# Clean Merged\n\nmerged_viz['2021'].iloc[0] = merged_viz['2021'].iloc[0] + merged_viz['2021'].iloc[6] # Tableau + Tableau CRM\nmerged_viz['2020'].iloc[4] = merged_viz['2020'].iloc[4] + merged_viz['2020'].iloc[16] # Salesforce + Einstein Analytics\nmerged_viz['2021'].iloc[1] = merged_viz['2021'].iloc[1] + merged_viz['2021'].iloc[7]\n\nmerged_viz = merged_viz.drop(merged_viz.index[[6,7,16]])[:-1]\n\nmerged_viz = merged_viz.T\n\n# Pct Change\nmerged_viz_perc = merged_viz.pct_change(periods = 1)[1:]\n\n# pct_change\ndata_bi_growth = pd.DataFrame()\ndata_bi_growth['total'] = merged_viz.sum(axis=1)\ndata_bi_growth = data_bi_growth.pct_change(periods = 1)\n\navg_growth_merged_2021 = round(data_bi_growth.iloc[1].mean(),2) # avg growth rate\n\n# --- plot ----\n\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(22,8))\n\nplt.subplot(121)   #  subplot 1\n\nmerged_viz.plot(kind='bar', ax = ax1)\nax1.set(title = \"Commerical Business Intelligence tool usage by professionals in kaggle survey\")\nax1.legend(loc=1, prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.2)\n\nplt.subplot(122)   #  subplot 2\n\nmerged_viz_perc.plot(kind='bar', ax=ax2)\nax2.set(title = \"Commerical Business Intelligence growth rate compare to previous year\")\nax2.legend(loc=1, prop={'size': 9})\n\nplt.axhline(y=avg_growth_merged_2021, xmin=0.2, xmax= 0.7, color='black', linestyle='dotted', linewidth=5)\n\nax2.text(-0.495, 0.52, 'Average growth rate ' +str(avg_growth_merged_2021*100) + '%')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:35.216585Z","iopub.execute_input":"2021-11-22T00:51:35.217059Z","iopub.status.idle":"2021-11-22T00:51:35.888429Z","shell.execute_reply.started":"2021-11-22T00:51:35.217015Z","shell.execute_reply":"2021-11-22T00:51:35.887517Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Commercial BI tool growth is higher than visualization library. Monetization of data analysis","metadata":{}},{"cell_type":"code","source":"special_BI_2021 = df_count_viz_2021\nspecial_BI_2021 = special_BI_2021.reset_index(drop=True)\n\n# -----\n\nmost_often_BI = pd.DataFrame(pros_2021['Q35'].value_counts()).reset_index()\nmost_often_BI = most_often_BI.rename(columns = {\"index\": \"BI tools\"})\n# -----\n\nBI_in_2_year = ['Q34_B_Part_1',\n           'Q34_B_Part_2',\n           'Q34_B_Part_3',\n           'Q34_B_Part_4',\n           'Q34_B_Part_5',\n           'Q34_B_Part_6',\n           'Q34_B_Part_7',\n           'Q34_B_Part_8',\n           'Q34_B_Part_9',\n           'Q34_B_Part_10',\n           'Q34_B_Part_11',\n           'Q34_B_Part_12',\n           'Q34_B_Part_13',\n           'Q34_B_Part_14',\n           'Q34_B_Part_15',\n           'Q34_B_Part_16',\n           'Q34_B_OTHER']\n\ndf_BI_in_2_year = pros_2021[BI_in_2_year]\n\ncount_BI_in_2_year = pd.Series(df_BI_in_2_year[BI_in_2_year].squeeze().values.ravel()).value_counts()\n\ndf_count_BI_in_2_year = pd.DataFrame(count_BI_in_2_year)\ndf_count_BI_in_2_year = df_count_BI_in_2_year.reset_index()\ndf_count_BI_in_2_year.columns = ['BI tools', 'Counts']\n\n#-----\nall_combo_2021 = special_BI_2021.merge(most_often_BI, on=\"BI tools\").merge(df_count_BI_in_2_year, on=\"BI tools\")\nall_combo_2021 = all_combo_2021.rename(columns = {'2021': 'Regularly use',\n                                'Q35': 'Most often use',\n                                'Counts': 'Hope to get familiar in 2 years'})\nall_combo_2021 = all_combo_2021.set_index('BI tools').T\n\nfig, ax = plt.subplots(figsize =(22,10))\nall_combo_2021.plot(kind='bar', ax=ax)\nax.set(title=\"2021 BI survey set\",\n      xlabel = \"Survey\",\n      ylabel = \"Counts\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T03:10:14.974790Z","iopub.execute_input":"2021-11-22T03:10:14.975401Z","iopub.status.idle":"2021-11-22T03:10:15.557719Z","shell.execute_reply.started":"2021-11-22T03:10:14.975345Z","shell.execute_reply":"2021-11-22T03:10:15.557080Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# AutoML regular basis\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\n# AutoML regular basis\n\n# Q37_A_Part_1\tQ37_A_Part_2\tQ37_A_Part_3\tQ37_A_Part_4\tQ37_A_Part_5\tQ37_A_Part_6\tQ37_A_Part_7\tQ37_A_OTHER\n# Q34_A_Part_1\tQ34_A_Part_2\tQ34_A_Part_3\tQ34_A_Part_4\tQ34_A_Part_5\tQ34_A_Part_6\tQ34_A_Part_7\tQ34_A_Part_8\tQ34_A_Part_9\tQ34_A_Part_10\tQ34_A_Part_11\tQ34_A_OTHER\t\n# autoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\n\nautoML_2021 = ['Q37_A_Part_1','Q37_A_Part_2','Q37_A_Part_3','Q37_A_Part_4','Q37_A_Part_5','Q37_A_Part_6','Q37_A_Part_7','Q37_A_OTHER']\ndf_autoML_2021 = pros_2021[autoML_2021]\ncount_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\ndf_count_autoML_2021 = df_count_autoML_2021.reset_index()\ndf_count_autoML_2021.columns = ['AutoML', 'Counts']\n#df_count_autoML_2021\n\n#-------\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\nautoML_2020 = ['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_OTHER']\ndf_autoML_2020 = pros_2020[autoML_2020]\ncount_autoML_2020 = pd.Series(df_autoML_2020[autoML_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2020 = pd.DataFrame(count_autoML_2020)\ndf_count_autoML_2020 = df_count_autoML_2020.reset_index()\ndf_count_autoML_2020.columns = ['AutoML', 'Counts']\n#df_count_autoML_2020\n\n# ---------------\n\nautoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\ndf_autoML_2019 = pros_2019[autoML_2019]\ncount_autoML_2019 = pd.Series(df_autoML_2019[autoML_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2019 = pd.DataFrame(count_autoML_2019)\ndf_count_autoML_2019 = df_count_autoML_2019.reset_index()\ndf_count_autoML_2019.columns = ['AutoML', 'Counts']\n\n# --------------\n\nautoML_df = df_count_autoML_2021.merge(df_count_autoML_2020, on = 'AutoML', how = 'outer').merge(df_count_autoML_2019, how = 'outer')\nautoML_df = autoML_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\nautoML_df = autoML_df.drop(autoML_df.index[[0,7,8,9,10,12,13,14,15]]) # Get rid of None and Others, auto sklearn, keras, autoML, Tpot,MLbox, Xcessiv\nautoML_df.at[16, 'AutoML'] = 'Google Cloud AutoML'\nautoML_df.at[11, 'AutoML'] = 'H2O Driverless AI'\nautoML_df['AutoML'] = autoML_df['AutoML'].str.strip()\nautoML_df = autoML_df.groupby(['AutoML']).sum()\nautoML_df = autoML_df.sort_values(by=['2021'], ascending = False)\n\nautoML_df = autoML_df.T\nautoML_df = autoML_df[::-1]\n\ndummy_df = autoML_df[['DataRobot AutoML','Databricks AutoML','Google Cloud AutoML','H2O Driverless AI']]\ndummy_df['total'] = dummy_df.sum(axis=1)\ndummy_df['total'] = dummy_df['total'].pct_change(periods=1)\nautoML_growth_2020 = dummy_df['total'].iloc[1]\nautoML_growth_2021 = dummy_df['total'].iloc[2]\n\nfor col in ['Amazon Sagemaker Autopilot', 'Azure Automated Machine Learning']:\n    autoML_df[col].iloc[1] = autoML_df[col].iloc[2]/(1+autoML_growth_2021)\n    autoML_df[col].iloc[0] = autoML_df[col].iloc[1]/(1+autoML_growth_2020)\n\nautoML_df = autoML_df.round(0)\n\n# market share\n\nfor_perc_autoML_df = autoML_df\nfor_perc_autoML_df = for_perc_autoML_df.divide(for_perc_autoML_df.sum(axis=1), axis = 0)\n\nfor_perc_autoML_df = for_perc_autoML_df.round(2)\n\n# future usage in 2 years\n\nmanaged_ml_2021_2_year = ['Q31_B_Part_1','Q31_B_Part_2',\n                          'Q31_B_Part_3','Q31_B_Part_4',\n                          'Q31_B_Part_5','Q31_B_Part_6',\n                          'Q31_B_Part_7','Q31_B_Part_8',\n                          'Q31_B_Part_9','Q31_B_OTHER']\n\nautoml_in_2 = ['Q37_B_Part_1',\n               'Q37_B_Part_2',\n               'Q37_B_Part_3',\n               'Q37_B_Part_4',\n               'Q37_B_Part_5',\n               'Q37_B_Part_6',\n               'Q37_B_Part_7',\n               'Q37_B_OTHER']\n\ndf_automl_in_2 = pros_2021[automl_in_2]\n\ncount_df_automl_in_2 = pd.Series(df_automl_in_2[automl_in_2].squeeze().values.ravel()).value_counts()\n\ndf_count_df_automl_in_2 = pd.DataFrame(count_df_automl_in_2)\ndf_count_df_automl_in_2 = df_count_df_automl_in_2.reset_index()\ndf_count_df_automl_in_2.columns = ['Auto ML', 'Counts']\ndf_count_df_automl_in_2 = df_count_df_automl_in_2.set_index('Auto ML').T\ndf_count_df_automl_in_2.columns = df_count_df_automl_in_2.columns.str.strip()\ndf_count_df_automl_in_2 = df_count_df_automl_in_2[['Google Cloud AutoML','Azure Automated Machine Learning', 'Amazon Sagemaker Autopilot', 'Databricks AutoML', 'DataRobot AutoML', 'H2O Driverless AI']]\n\n\n# --- Plot ----\n\nfig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (22,8))\n\nplt.subplot(131)   #  subplot 1\nautoML_df.plot(kind='bar', ax=ax1)\n\nplt.annotate('* Numbers in Amazon Sagemaker Autopilot and Azure Automated Machine Learning in 2019 and 2020 were derived from the yearly avg industry growth', \n             (0,0), \n             (-50,-50), \n             fontsize=8, \n             xycoords='axes fraction', \n             textcoords='offset points', va='top')\nax1.set(title = \"AutoML usage from 2019 to 2021\")\n\nax1.text(-0.2, 510, 'Industry dip in 2020 then bounced off',\n        verticalalignment='bottom',\n        fontsize=12)\n\n\n\nplt.subplot(132)\n\nfor_perc_autoML_df.plot(kind='area', \n              stacked=True,\n              ax = ax2,\n             )\n\nax2.legend(loc='lower right', prop={'size': 9})\nax2.set(title = \"Share of AutoML product usage\")\n\nax2.text(0.1, 0.5, 'AWS, Azure not as dominant as in other services',\n        verticalalignment='bottom',\n        fontsize=12)\n\nplt.subplot(133)\n\ndf_count_df_automl_in_2.plot(kind='bar',ax=ax3)\nax3.legend(loc='upper right', prop={'size': 9})\nax3.set(title = \"Share of AutoML product usage\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:35.890206Z","iopub.execute_input":"2021-11-22T00:51:35.890704Z","iopub.status.idle":"2021-11-22T00:51:36.675414Z","shell.execute_reply.started":"2021-11-22T00:51:35.890661Z","shell.execute_reply":"2021-11-22T00:51:36.674167Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"ml_manage_2021 = ['Q38_A_Part_1','Q38_A_Part_2','Q38_A_Part_3',\n                  'Q38_A_Part_4','Q38_A_Part_5','Q38_A_Part_6',\n                  'Q38_A_Part_7','Q38_A_Part_8','Q38_A_Part_9',\n                  'Q38_A_Part_10','Q38_A_Part_11','Q38_A_OTHER']\n\ndf_ml_manage_2021 = pros_2021[ml_manage_2021]\n#df_ml_manage_2021 = df_ml_manage_2021.rename(columns={'Q38_A_Part_1': 'Neptune.ai',\n#                                                      'Q38_A_Part_2': 'Weights & Biases',\n#                                                      'Q38_A_Part_3': 'Comet.ml',\n#                                                      'Q38_A_Part_4': 'Sacred + Omniboard',\n#                                                      'Q38_A_Part_5': 'TensorBoard',\n#                                                      'Q38_A_Part_6': 'Guild.ai',\n#                                                      'Q38_A_Part_7': 'Polyaxon',\n#                                                      'Q38_A_Part_8': 'Trains',\n#                                                      'Q38_A_Part_9': 'Domino Model Monitor',\n#                                                      'Q38_A_Part_10': 'MLflow',\n#                                                      'Q38_A_Part_11': 'None',\n#                                                      'Q38_A_OTHER': 'Other'})\n\n\ncount_ml_manage_2021 = pd.Series(df_ml_manage_2021[ml_manage_2021].squeeze().values.ravel()).value_counts()\ndf_count_ml_manage_2021 = pd.DataFrame(count_ml_manage_2021)\ndf_count_ml_manage_2021 = df_count_ml_manage_2021.reset_index()\ndf_count_ml_manage_2021.columns = ['manage', '2021']\n\n\n# ------------\n\nml_manage_2020 = ['Q35_A_Part_1','Q35_A_Part_2',\n          'Q35_A_Part_3','Q35_A_Part_4',\n          'Q35_A_Part_5','Q35_A_Part_6',\n          'Q35_A_Part_7','Q35_A_Part_8','Q35_A_Part_9','Q35_A_Part_10','Q35_A_OTHER']\n\n\ndf_ml_manage_2020 = pros_2020[ml_manage_2020]\n\n\ncount_ml_manage_2020 = pd.Series(df_ml_manage_2020[ml_manage_2020].squeeze().values.ravel()).value_counts()\ndf_count_ml_manage_2020 = pd.DataFrame(count_ml_manage_2020)\ndf_count_ml_manage_2020 = df_count_ml_manage_2020.reset_index()\ndf_count_ml_manage_2020.columns = ['manage', '2020']\n\n#df = pd.concat([df_count_ml_manage_2021, df_count_ml_manage_2020], axis = 1)\n#df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\nmerged = df_count_ml_manage_2021.set_index('manage').combine_first(df_count_ml_manage_2020.set_index('manage'))\nmerged = merged.sort_values(by=['2021'], ascending = False)\nmerged = merged.iloc[1:, :]\n\nfig, ax = plt.subplots(figsize=(16,8))\n\nmerged.plot(kind='bar', ax=ax)\n\nax.set(title = \"Tools used to manage machine learning experiments\")\n\nax.annotate('Newly added', xy=(1.2, 1200), xytext=(2, 1300),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nax.annotate('Newly added', xy=(5.2, 260), xytext=(5.6, 300),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nax.annotate('Removed', xy=(10.8, 260), xytext=(9.8, 350),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:36.676941Z","iopub.execute_input":"2021-11-22T00:51:36.677213Z","iopub.status.idle":"2021-11-22T00:51:37.254545Z","shell.execute_reply.started":"2021-11-22T00:51:36.677181Z","shell.execute_reply":"2021-11-22T00:51:37.253569Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"cloud_stocks = pd.read_excel('../input/cloud-apm-stocks/cloud_apm_stocks.xlsx')\n#cloud_stocks = cloud_stocks.rename(columns = {'Unnamed: 0': 'Revenue'})\ncloud_stocks = cloud_stocks.iloc[1:, :]\ncloud_stocks = cloud_stocks.set_index('Date')\ncloud_stocks = cloud_stocks.div(1000000000)\ncloud_stocks = cloud_stocks.rename(columns = \n                   {'DDOG.O (Fundamental)': 'DataDog',\n                    'NEWR.K (Fundamental)': 'New Relic',\n                    'DT (Fundamental)': 'Dynatrace',\n                    'ESTC.K (Fundamental)': 'Elastic NV',\n                    'CFLT.O (Fundamental)': 'CFLT'\n                   })\n\ncloud_stocks = cloud_stocks.drop(columns = ['CFLT'])\nfig, ax = plt.subplots(figsize=(18,6))\ncloud_stocks.plot(ax=ax)\n\nplt.xlabel('Date')\nplt.ylabel('Market cap (Billions)')\nplt.title('Application Performace Management(APM) companies market cap')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:37.256280Z","iopub.execute_input":"2021-11-22T00:51:37.256599Z","iopub.status.idle":"2021-11-22T00:51:37.724850Z","shell.execute_reply.started":"2021-11-22T00:51:37.256557Z","shell.execute_reply":"2021-11-22T00:51:37.723816Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"industry_gpu = ['Q20', 'Q12_Part_1']\nindustry_by_gpu = pros_2021[industry_gpu]\nindustry_by_gpu = industry_by_gpu[industry_by_gpu['Q20'].notna()]\n\nindustry_list = list(industry_by_gpu['Q20'].unique())\n\nind_gpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_gpu = industry_by_gpu.loc[industry_by_gpu['Q20'] == ind]\n    idx = pd.Series(ind_gpu['Q12_Part_1'].squeeze().values.ravel()).value_counts()\n    ind_gpu_merged[ind] = idx\n    \n    \nindustry_tpu = ['Q20', 'Q12_Part_2']\nindustry_by_tpu = pros_2021[industry_tpu]\nindustry_by_tpu = industry_by_tpu[industry_by_tpu['Q20'].notna()]\n\nind_tpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_tpu = industry_by_tpu.loc[industry_by_tpu['Q20'] == ind]\n    idx = pd.Series(ind_tpu['Q12_Part_2'].squeeze().values.ravel()).value_counts()\n    ind_tpu_merged[ind] = idx\n\nind_gpu_tpu = ind_gpu_merged.append(ind_tpu_merged).T\nind_gpu_tpu.columns = ind_gpu_tpu.columns.str.strip()\nind_gpu_tpu = ind_gpu_tpu.sort_values(by = 'NVIDIA GPUs', ascending = False)\n\nfig, ax = plt.subplots(figsize = (22,10))\nind_gpu_tpu.plot(kind = 'barh', ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:37.726087Z","iopub.execute_input":"2021-11-22T00:51:37.726312Z","iopub.status.idle":"2021-11-22T00:51:38.383949Z","shell.execute_reply.started":"2021-11-22T00:51:37.726286Z","shell.execute_reply":"2021-11-22T00:51:38.383112Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"hardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\nhardware_2021_df = pros_2021[hardware_2021]\ncount_hardware_2021 = pd.Series(hardware_2021_df[hardware_2021].squeeze().values.ravel()).value_counts()\n\nhardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\nhardware_2020_df = pros_2020[hardware_2020]\ncount_hardware_2020 = pd.Series(hardware_2020_df[hardware_2020].squeeze().values.ravel()).value_counts()\n\nhardware_2019 = ['Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5','Q21_OTHER_TEXT']\nhardware_2019_df = pros_2019[hardware_2019]\ncount_hardware_2019 = pd.Series(hardware_2019_df[hardware_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_hardware_2021 = pd.DataFrame(count_hardware_2021)\ndf_count_hardware_2021 = df_count_hardware_2021.reset_index()\ndf_count_hardware_2021.columns = ['manage', '2021']\n\ndf_count_hardware_2020 = pd.DataFrame(count_hardware_2020)\ndf_count_hardware_2020 = df_count_hardware_2020.reset_index()\ndf_count_hardware_2020.columns = ['manage', '2020']\n\ndf_count_hardware_2019 = pd.DataFrame(count_hardware_2019)\ndf_count_hardware_2019 = df_count_hardware_2019.reset_index()\ndf_count_hardware_2019.columns = ['manage', '2019']\n\ndf_count_hardware_2019 = df_count_hardware_2019.iloc[1:6]\ndf_count_hardware_2019 = df_count_hardware_2019.set_index('manage').T[['GPUs', 'TPUs','Other']]\n\ndf_count_hardware_2020 = df_count_hardware_2020.set_index('manage').T[['GPUs', 'TPUs', 'Other']]\n\ndf_count_hardware_2021 = df_count_hardware_2021.set_index('manage').T\ndf_count_hardware_2021.columns = df_count_hardware_2021.columns.str.strip()\ndf_count_hardware_2021 = df_count_hardware_2021[['NVIDIA GPUs','Google Cloud TPUs','Other','AWS Inferentia Chips','AWS Trainium Chips']]\ndf_count_hardware_2021 = df_count_hardware_2021.rename(columns = {'NVIDIA GPUs': 'GPUs',\n                                                                    'Google Cloud TPUs': 'TPUs',\n                                                                    'Other': 'Other',\n                                                                    'AWS Inferentia Chips': 'AWS Inferentia',\n                                                                    'AWS Trainium Chips': 'AWS Trainium'})\n\ndf_hardware_merged = df_count_hardware_2019.append(df_count_hardware_2020).append(df_count_hardware_2021).fillna(0)\n\nfig, ax = plt.subplots(figsize=(18,6))\ndf_hardware_merged.plot(kind='bar', ax=ax)\nax.set(title = 'Special hardware usage trend',\n    xlabel = 'year',\n      ylabel = 'number of respondants',\n      )\n\nax.annotate(\"AWS's custom chips are added in 2021\", xy=(2.1, 1000), xytext=(2.3, 2000),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:38.385794Z","iopub.execute_input":"2021-11-22T00:51:38.386046Z","iopub.status.idle":"2021-11-22T00:51:38.819180Z","shell.execute_reply.started":"2021-11-22T00:51:38.386017Z","shell.execute_reply":"2021-11-22T00:51:38.818230Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:38.820692Z","iopub.execute_input":"2021-11-22T00:51:38.821004Z","iopub.status.idle":"2021-11-22T00:51:38.825740Z","shell.execute_reply.started":"2021-11-22T00:51:38.820969Z","shell.execute_reply":"2021-11-22T00:51:38.825099Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for q in questions_2020:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:38.826840Z","iopub.execute_input":"2021-11-22T00:51:38.827110Z","iopub.status.idle":"2021-11-22T00:51:38.881743Z","shell.execute_reply.started":"2021-11-22T00:51:38.827078Z","shell.execute_reply":"2021-11-22T00:51:38.880885Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"for q in questions_2019:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:38.883309Z","iopub.execute_input":"2021-11-22T00:51:38.883630Z","iopub.status.idle":"2021-11-22T00:51:38.926668Z","shell.execute_reply.started":"2021-11-22T00:51:38.883587Z","shell.execute_reply":"2021-11-22T00:51:38.925971Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"autoML_2021 = ['Q37_A_Part_1','Q37_A_Part_2','Q37_A_Part_3','Q37_A_Part_4','Q37_A_Part_5','Q37_A_Part_6','Q37_A_Part_7','Q37_A_OTHER']\ndf_autoML_2021 = pros_2021[autoML_2021]\ncount_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\ndf_count_autoML_2021 = df_count_autoML_2021.reset_index()\ndf_count_autoML_2021.columns = ['AutoML', 'Counts']\n#df_count_autoML_2021","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:38.927841Z","iopub.execute_input":"2021-11-22T00:51:38.928090Z","iopub.status.idle":"2021-11-22T00:51:38.947608Z","shell.execute_reply.started":"2021-11-22T00:51:38.928061Z","shell.execute_reply":"2021-11-22T00:51:38.946341Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"data_storage_regular_2021 = ['Q30_A_Part_1', 'Q30_A_Part_2','Q30_A_Part_3', 'Q30_A_Part_4', 'Q30_A_Part_5', 'Q30_A_Part_6', 'Q30_A_Part_7', 'Q30_A_OTHER']\n\ndf_data_storage_regular_2021 = pros_2021[data_storage_regular_2021]\ncount_data_storage_regular_2021 = pd.Series(df_data_storage_regular_2021[data_storage_regular_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_data_storage_regular_2021 = pd.DataFrame(count_data_storage_regular_2021)\ndf_count_data_storage_regular_2021 = df_count_data_storage_regular_2021.reset_index()\ndf_count_data_storage_regular_2021.columns = ['Storage', 'Counts']\ndf_count_data_storage_regular_2021 = df_count_data_storage_regular_2021.set_index('Storage').T\ndf_count_data_storage_regular_2021.plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T00:51:38.948948Z","iopub.execute_input":"2021-11-22T00:51:38.949162Z","iopub.status.idle":"2021-11-22T00:51:39.272187Z","shell.execute_reply.started":"2021-11-22T00:51:38.949137Z","shell.execute_reply":"2021-11-22T00:51:39.271139Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}