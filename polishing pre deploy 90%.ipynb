{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\npd.set_option('display.max_columns', 100)\npd.options.mode.chained_assignment = None  # default='warn'\n\n!pip install openpyxl\n\ndata_2021 = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2021 = data_2021.iloc[0, :].T\ndata_2021 = data_2021.iloc[1:, :]\ndata_2020 = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2020 = data_2020.iloc[0, :].T\ndata_2020 = data_2020.iloc[1:, :]\ndata_2019 = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv', low_memory = False, encoding='UTF-8')\nquestions_2019 = data_2019.iloc[0, :].T\ndata_2019 = data_2019.iloc[1:, :]\ndata_2018 = pd.read_csv('../input/kaggle-survey-2018/multipleChoiceResponses.csv', low_memory = False, encoding='UTF-8')\nquestions_2018 = data_2018.iloc[0, :].T\ndata_2018 = data_2018.iloc[1:, :]\ndata_2017 = pd.read_csv('../input/kaggle-survey-2017/multipleChoiceResponses.csv', low_memory = False, encoding='ISO-8859-1')\nquestions_2017 = data_2017.iloc[0, :].T\ndata_2017 = data_2017.iloc[1:, :]\n\nnvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\ncloud_earnings = pd.read_excel('../input/3-tech-cloud-earnings/cloud.xlsx')\n# 2021 Yes. 2020 Yes. 2019 Yes. About TPUs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T03:47:05.542271Z","iopub.execute_input":"2021-11-20T03:47:05.542990Z","iopub.status.idle":"2021-11-20T03:47:25.081345Z","shell.execute_reply.started":"2021-11-20T03:47:05.542953Z","shell.execute_reply":"2021-11-20T03:47:25.080505Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_professionals(data, column):\n    data = data.loc[data[column] != 'Student']\n    data = data.loc[data[column] != 'Currently not employed']\n    data = data.loc[data[column] != 'Not employed']\n    data = data.loc[data[column].notna()]\n    return data\n\npros_2021 = get_professionals(data_2021, 'Q5')\npros_2020 = get_professionals(data_2020, 'Q5')\n\npros_2019 = data_2019[data_2019['Q5'].notna()]\npros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\npros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:25.083087Z","iopub.execute_input":"2021-11-20T03:47:25.083332Z","iopub.status.idle":"2021-11-20T03:47:25.802760Z","shell.execute_reply.started":"2021-11-20T03:47:25.083303Z","shell.execute_reply":"2021-11-20T03:47:25.801780Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"nvda_earnings = pd.read_excel('../input/nvda-earnings-2018q1to2021q3/nvda_earnings.xlsx')\nnvda_earnings = nvda_earnings.rename(columns = {'Unnamed: 0': 'Revenue'})\nnvda_earnings","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:25.804230Z","iopub.execute_input":"2021-11-20T03:47:25.804464Z","iopub.status.idle":"2021-11-20T03:47:25.840602Z","shell.execute_reply.started":"2021-11-20T03:47:25.804436Z","shell.execute_reply":"2021-11-20T03:47:25.839589Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = nvda_earnings.T\ndf.columns = df.iloc[0]\ndf = df.drop(df.index[0])\ndf.drop('Total', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:25.841807Z","iopub.execute_input":"2021-11-20T03:47:25.842159Z","iopub.status.idle":"2021-11-20T03:47:25.850730Z","shell.execute_reply.started":"2021-11-20T03:47:25.842129Z","shell.execute_reply":"2021-11-20T03:47:25.850147Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as patches\n\nfig, ax = plt.subplots(figsize = (16,8))\ndf.plot(kind = 'bar', stacked=True, ax = ax)\nax.set(title = 'NVIDIA Earnings')\nfor c in ax.containers:\n    ax.bar_label(c, label_type='center')\n\n#for p in ax.patches:\n    #print(p)\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")\n\nplt.annotate('',\nha = 'center', va = 'bottom',\nxytext = (7.8, 1800),\nxy = (12.3, 3800),\narrowprops = { 'facecolor' : 'red', 'shrink' : 0.05 })\n\nplt.annotate('Data Center Revenue Explosion Begins',\n        fontsize = 14,\n        ha = 'center', va = 'bottom',\n        xytext = (8, 5000),\n        xy = (8, 3200),\n        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.05 })\n\n\nplt.annotate('Data Center revenue growth 100% YoY in 2020', xytext = (3, 6000), xy = (8, 6000), fontsize = 22, color = 'red', )\nplt.axhline(y=3200, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Source: Nvidia', (0,0), (-80,-80), fontsize=8, \n             xycoords='axes fraction', textcoords='offset points', va='top')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:25.852618Z","iopub.execute_input":"2021-11-20T03:47:25.853238Z","iopub.status.idle":"2021-11-20T03:47:26.822890Z","shell.execute_reply.started":"2021-11-20T03:47:25.853208Z","shell.execute_reply":"2021-11-20T03:47:26.821959Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cloud_earnings.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:26.824035Z","iopub.execute_input":"2021-11-20T03:47:26.824280Z","iopub.status.idle":"2021-11-20T03:47:26.839433Z","shell.execute_reply.started":"2021-11-20T03:47:26.824253Z","shell.execute_reply":"2021-11-20T03:47:26.838597Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_colwidth\n\ndata_center_segment = nvda_earnings.iloc[[2]]\ndata_center_segment = data_center_segment.set_index(['Revenue'])\ndata_center_aws =  data_center_segment.copy() * 0.31\ndata_center_aws = data_center_aws.rename(index = {'data center': 'Aws'})\n\ndata_center_azure = data_center_segment.copy() * 0.22\ndata_center_azure = data_center_azure.rename(index = {'data center': 'Azure'})\n\ndata_center_gcp = data_center_segment.copy() * 0.08\ndata_center_gcp = data_center_gcp.rename(index = {'data center': 'GCP'})\n\ndata_center_others = data_center_segment.copy() * 0.39\ndata_center_others = data_center_others.rename(index = {'data center': 'Others'})\n\ndf = pd.concat([data_center_aws, data_center_azure, data_center_gcp, data_center_others])\ndf.iloc[2, 0] = 0\ndf.iloc[2, 1] = 0\ndf.iloc[2, 2] = 0 \ndf = df.T\n\nfig, ax = plt.subplots(figsize = (16,8))\n\ndf.plot(kind = 'bar', ax = ax)\nplt.axvline(x=2.5, linestyle='dashed', linewidth=2, color = 'black') \nplt.annotate('Google disclosed GCP as of 2019', xytext = (2.6, 600), xy = (8, 600), fontsize = 14, color = 'black' )\nax.set(title = \"Estimated Nvidia' data center revenue from the big 3\")\n\nax.legend(loc='upper left',\n          ncol=1, fancybox=True, shadow=True)\n\nax.set_xlabel(\"Adj Fiscal Year\")\nax.set_ylabel(\"in Million USD\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:26.841086Z","iopub.execute_input":"2021-11-20T03:47:26.841304Z","iopub.status.idle":"2021-11-20T03:47:27.289630Z","shell.execute_reply.started":"2021-11-20T03:47:26.841277Z","shell.execute_reply":"2021-11-20T03:47:27.289087Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n<div class=\"alert alert-warning\">\n  <strong>Note: </strong> For all charts in this module, I only selected working Professionals.\n</div>\n</div>\n\n<br>\n<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\nNon-professionals were defined as those who answered Job Title as either: \n<ul>\n<li>Student</li>\n<li>Currently not employed</li>\n<li>Who didn't answer the question (NaN)</li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1: Data Science Professionals distribution by industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# Exhibit 1. Data Science Professionals distribution by industry 2018 vs. 2021\n\n# Get data from 2021\n\nindustry_2021 = data_2021[data_2021['Q20'].notna()]\nc = industry_2021['Q20'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#c =industry_2021['Q20'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# Get data from 2018\n\nindustry_2018 = data_2018[data_2018['Q7'] != 'I am a student']\nindustry_2018 = industry_2018[industry_2018['Q7'].notna()]\nd = industry_2018['Q7'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n#d = industry_2018['Q7'].value_counts().rename_axis('industry').reset_index(name='counts')\n\n# compute the industry\n\nk = pd.merge(left = d, right = c, on = 'industry')\nk = k.rename(columns = {'counts_x': '2018', 'counts_y': '2021'})\nk = k.sort_values(by=['2021'], ascending=False)\n\n# compute the difference\ndiff_industry = k.copy()\ndiff_industry['dff'] = k['2021'] - k['2018']\n\n# plot\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \nax1 = plt.subplot(gs[0])\n\nk.plot.barh(x = \"industry\", ax= ax1)\n#ax.grid(False)\nax1.set(title = \"Data Science professionals distribution by Industry. 2018 vs 2021\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax1.invert_yaxis()\n\nax2 = plt.subplot(gs[1])\ndiff_industry['dff'].plot(kind='barh', x = 'industry', ax = ax2,\n                    color=(diff_industry['dff'] > 0).map({True: 'g',\n                                                    False: 'r'}))\nax2.set(title = \"Change\",\n      xlabel = \"Percentage\",\n      ylabel = \"Industry\")\nax2.set_yticks([])\n\nplt.gca().invert_yaxis()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-20T03:47:27.290587Z","iopub.execute_input":"2021-11-20T03:47:27.291447Z","iopub.status.idle":"2021-11-20T03:47:28.280576Z","shell.execute_reply.started":"2021-11-20T03:47:27.291402Z","shell.execute_reply":"2021-11-20T03:47:28.279636Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n\n<ul>\n<li> Computer/Technology field is no longer the only game in town. It declined <strong>7.5%</strong></li>\n\n<li> Academic/Education industry gained <strong>3%</strong></li>\n<li> Manufactruing industry gained <strong>2%</strong></li>\n\n<li> A sign that Data Science is <strong>penetrating broadly</strong>. </li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"code","source":"# ----------------\n# Job title filter\n# ----------------\n\njob_title = {'Other':'Other',\n     'Product Manager': 'Product/Project Manager',\n 'Program/Project Manager':'Product/Project Manager',\n 'Principal Investigator':'Product/Project Manager',\n 'Chief Officer':'Product/Project Manager',\n 'Manager':'Product/Project Manager',\n 'Software Developer/Software Engineer': 'Software Engineer',\n 'Operations Research Practitioner': 'Research Scientist',\n 'Computer Scientist': 'Research Scientist',\n 'Scientist/Researcher': 'Research Scientist',\n 'Researcher': 'Research Scientist',\n 'Data Scientist': 'Data Scientist',\n     'Business Analyst': 'Business Analyst',\n     'Engineer': 'Other',\n     'DBA/Database Engineer': 'DBA/Database Engineer',\n     'Data Analyst':'Data Analyst',\n     'Machine Learning Engineer': 'Machine Learning Engineer',\n     'Statistician':'Statistician',\n     'Predictive Modeler':'Research Scientist',\n     'Programmer': 'Software Engineer',\n     'Data Miner': 'Data Engineer',\n     'Consultant': 'Other',\n     'Research Assistant': 'Research Scientist',\n     'Chief Officer':'Product/Project Manager',\n     'Data Engineer':'Data Engineer',\n     'Developer Advocate': 'Developer Relations/Advocacy',\n     'Marketing Analyst': 'Business Analyst',\n     'Data Analyst': 'Data Analyst',\n     'Software Engineer': 'Software Engineer',\n     'Research Scientist': 'Research Scientist',\n     'Data Journalist': 'Data Analyst',\n     'Salesperson':'Developer Relations/Advocacy',\n     'Product/Project Manager': 'Product/Project Manager',\n     'Developer Relations/Advocacy': 'Developer Relations/Advocacy'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:28.281847Z","iopub.execute_input":"2021-11-20T03:47:28.282105Z","iopub.status.idle":"2021-11-20T03:47:28.289063Z","shell.execute_reply.started":"2021-11-20T03:47:28.282075Z","shell.execute_reply":"2021-11-20T03:47:28.288199Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n    \n**Exhibit 1.1: Data Science Professional roles in different industry 2018 vs. 2021**\n</div>","metadata":{}},{"cell_type":"code","source":"# cheat\npd.options.mode.chained_assignment = None \n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nworkforce_2021 = get_professionals(data_2021, 'Q5')\nprofessional_2021 = workforce_2021[workforce_2021['Q20'].notna()]\nprofessional_2021['Q5'] = professional_2021['Q5'].map(job_title)\nindustry_2021 = professional_2021['Q20'].unique()\ndf_2021 = professional_2021[['Q5','Q20']]\n\ntemp_d = {}\n\nfor industry in industry_2021:\n    temp_df = df_2021[df_2021['Q20'] == industry]\n    temp_dict = dict(temp_df['Q5'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2021 = {}\n\nh_lst = list(k['industry'])\n\nfor i in h_lst:\n    d_2021[i] = temp_d[i]\n\ndf_industry_2021 = pd.DataFrame.from_dict(d_2021, orient='index')\ndf_industry_2021.fillna(0, inplace = True)\ndf_industry_2021 = df_industry_2021.sort_values(by=df_industry_2021.index[0], ascending=False, axis=1)\ndf_industry_2021\n\n# -----------------------------------------\n# Heatmap of job title within industry 2021\n# -----------------------------------------\n\nstudent_2018 = data_2018.loc[data_2018['Q7'] == 'I am a student']\nworkforce_2018 = data_2018.loc[data_2018['Q7'] != 'I am a student']\n\nprofessional_2018 = workforce_2018[workforce_2018['Q7'].notna()]\nprofessional_2018['Q6'] = professional_2018['Q6'].map(job_title)\n\nindustry_2018 = professional_2018['Q7'].unique()\n\ndf_2018 = professional_2018[['Q6','Q7']]\n\ntemp_d = {}\n\nfor industry in industry_2018:\n    temp_df = df_2018[df_2018['Q7'] == industry]\n    temp_dict = dict(temp_df['Q6'].value_counts())\n    temp_d[industry] = temp_dict\n\ndef sorted_simple_dict(d):\n    return {k: v for k, v in sorted(d.items())}\n\ndef sorted_once_nested_dict(d):\n    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n\ntemp_d = sorted_once_nested_dict(temp_d)\n\nd_2018 = {}\n\nfor i in h_lst:\n    d_2018[i] = temp_d[i]\n\ndf_industry_2018 = pd.DataFrame.from_dict(d_2018, orient='index')\ndf_industry_2018.fillna(0, inplace = True)\ndf_industry_2018 = df_industry_2018.sort_values(by=df_industry_2018.index[0], ascending=False, axis=1)\n#df_industry_2018\n\n# ---------------\n#  SUBPLOTS - 1x2\n# ---------------\n\nfig = plt.figure(figsize=(22,10))\n\nplt.subplot(121)   #  subplot 1\nplt.title('2018 heatmap')\nsns.heatmap(df_industry_2018, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(122)   #  subplot 2\nplt.title('2021 heatmap')\nsns.heatmap(df_industry_2021, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n\nplt.axvline(x = 2, ymin= -0.05, ymax= 1.1, color='red', linestyle='solid', linewidth=5)\nplt.axvline(x = 3, ymin= -0.05, ymax= 1.1, color='red', linestyle='solid', linewidth=5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:28.290381Z","iopub.execute_input":"2021-11-20T03:47:28.290626Z","iopub.status.idle":"2021-11-20T03:47:31.571627Z","shell.execute_reply.started":"2021-11-20T03:47:28.290598Z","shell.execute_reply":"2021-11-20T03:47:31.570758Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Machine Learning Engineer role is added in 2021. <strong>Large portion of data scientist and software engineer moved to machine learning engineer.</strong></li>\n    \n<li><strong>Decline in Research Scientist roles</strong> in Computer/Tech and Academic fields.</li>\n</ul>\n</div>\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom math import pi\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n# activities at work\n\n# Q24_Part_1\tQ24_Part_2\tQ24_Part_3\tQ24_Part_4\tQ24_Part_5\tQ24_Part_6\tQ24_Part_7\tQ24_OTHER\n\nactivities_2021 = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_OTHER']\n\nrole_2021 = ['Q5']\n\nrole_activities_2021 = ['Q5','Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_OTHER']\n\njob_name = ['Data Scientist', 'Machine Learning Engineer',  'Software Engineer', 'Data Analyst', 'Research Scientist']\n\ndf_role_act_2021 = pros_2021[role_activities_2021]\n\ndf_role_act_2021 = df_role_act_2021[df_role_act_2021['Q5'].isin(job_name)]\n\ndf_role_act_2021[activities_2021] = df_role_act_2021[activities_2021].notnull().astype('int')\n\n# --------------\n\ndf_SE = df_role_act_2021[df_role_act_2021['Q5'] == 'Software Engineer']\ndf_SE = df_SE.groupby(by='Q5', dropna=False).sum()\ndf_SE = df_SE.rename(columns = {'Q24_Part_1': 'Analyze data', \n                     'Q24_Part_2': 'Build infrastructure', \n                     'Q24_Part_3': 'Build ML prototypes', \n                     'Q24_Part_4': 'Deploy & Improve',\n                     'Q24_Part_5': 'Improve existing ML',\n                     'Q24_Part_6': 'Do research',\n                     'Q24_Part_7': 'None',\n                     'Q24_OTHER': 'Other'\n                    })\n\ndf_SE = df_SE.T.reset_index()\n\n# --------------\n\ndf_DS = df_role_act_2021[df_role_act_2021['Q5'] == 'Data Scientist']\ndf_DS = df_DS.groupby(by='Q5', dropna=False).sum()\ndf_DS = df_DS.rename(columns = {'Q24_Part_1': 'Analyze data', \n                     'Q24_Part_2': 'Build infrastructure', \n                     'Q24_Part_3': 'Build ML prototypes', \n                     'Q24_Part_4': 'Deploy & Improve',\n                     'Q24_Part_5': 'Improve existing ML',\n                     'Q24_Part_6': 'Do research',\n                     'Q24_Part_7': 'None',\n                     'Q24_OTHER': 'Other'\n                    })\ndf_DS = df_DS.T.reset_index()\n\n# -------------\n\ndf_MLE = df_role_act_2021[df_role_act_2021['Q5'] == 'Machine Learning Engineer']\n#print(df)\ndf_MLE = df_MLE.groupby(by='Q5', dropna=False).sum()\ndf_MLE = df_MLE.rename(columns = {'Q24_Part_1': 'Analyze data', \n                     'Q24_Part_2': 'Build infrastructure', \n                     'Q24_Part_3': 'Build ML prototypes', \n                     'Q24_Part_4': 'Deploy & Improve',\n                     'Q24_Part_5': 'Improve existing ML',\n                     'Q24_Part_6': 'Do research',\n                     'Q24_Part_7': 'None',\n                     'Q24_OTHER': 'Other'\n                    })\ndf_MLE = df_MLE.T.reset_index()\n\n#----------\n\n\n\ndf_MLE['percent'] = (df_MLE['Machine Learning Engineer'] / \n                  df_MLE['Machine Learning Engineer'].sum()) * 100\ndf_MLE = df_MLE.drop('Machine Learning Engineer', axis = 1)\n\ndf_DS['percent'] = (df_DS['Data Scientist'] / \n                  df_DS['Data Scientist'].sum()) * 100\ndf_DS = df_DS.drop('Data Scientist', axis = 1)\n\ndf_SE['percent'] = (df_SE['Software Engineer'] / \n                  df_SE['Software Engineer'].sum()) * 100\ndf_SE = df_SE.drop('Software Engineer', axis = 1)\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatterpolar(\n      r=df_SE['percent'],\n      theta=df_SE['index'],\n      fill='toself',\n      name='Software Engineer'\n))\n\n\nfig.add_trace(go.Scatterpolar(\n      r=df_DS['percent'],\n      theta=df_DS['index'],\n      fill='toself',\n      name='Data Scientist'\n))\n\nfig.add_trace(go.Scatterpolar(\n      r=df_MLE['percent'],\n      theta=df_MLE['index'],\n      fill='toself',\n      name='Machine Learning Engineer'\n))\n\n\nfig.update_layout(\n     title={\n        'text': \"Tasks in workplace SE vs. DS vs. MLE\",\n        'y':0.92,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n  polar=dict(\n    radialaxis=dict(\n      visible=True,\n      range=[0, 27]\n    )),\n  showlegend=True\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:31.572999Z","iopub.execute_input":"2021-11-20T03:47:31.573237Z","iopub.status.idle":"2021-11-20T03:47:32.809303Z","shell.execute_reply.started":"2021-11-20T03:47:31.573202Z","shell.execute_reply":"2021-11-20T03:47:32.808405Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Machine learning engineer's tasks are hybrid of traditional software engineer and data scientist. <strong>MLEs conduct more resources on managing products than analyzing data or building infrastructure.</strong></li>\n    <li>The rise of Machine learning enginner and decline in research scientist in academic field suggests that <strong>the data science industry is moving from research to business/operation oriented</strong></li>\n\n</ul>\n</div>\n","metadata":{}},{"cell_type":"code","source":"# Exhibit 1.1 Data Science distribution by company size 2021.\n\ntest = get_professionals(data_2021, 'Q5')\n#print(len(test))\ntest = test[test['Q21'].notna()]\n#print(len(test))\n\ncategory_test = test.groupby(['Q20', 'Q21']).size()\n#category_test.plot(kind='bar')\nnew_df = category_test.to_frame(name = 'size').reset_index()\nnew_df_2= pd.pivot(\n    data = new_df,\n    index = 'Q20',\n    columns = 'Q21',\n    values = 'size')\nnew_df_2.index.names = ['Industry']\nnew_df_2.columns.names = ['Company Size']\n\ncolumns_order = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees','10,000 or more employees']\n\nnew_df_2 = new_df_2.reindex(columns = columns_order)\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns='total')\n\n# -----\n\n\nnew_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\nnew_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\nnew_df_2 = new_df_2.drop(columns = 'total')\nres = new_df_2.div(new_df_2.sum(axis=1), axis = 0)\nres\n\n# -----\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (16,8))\n#plt.style.use('IPython_default')\ngs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n\nax1 = plt.subplot(gs[0])\n\nnew_df_2.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax1,\n              )\n\nax1.set(title = \"DS professional distibution by company size across different industry 2021\",\n      xlabel = \"Counts\",\n      ylabel = \"Industry\")\n\n\nax2 = plt.subplot(gs[1])\n\nres.plot(use_index = True,  \n              kind='barh', \n              stacked=True, \n              ax = ax2,\n              )\n\nax2.set(title='Company Size portion within industry',\n      xlabel = \"Percentage\",\n      ylabel = \" \")\n\nplt.legend(title = \"Company Size\", bbox_to_anchor=(1.04,1), loc=\"upper left\")\nax2.set_yticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:32.811091Z","iopub.execute_input":"2021-11-20T03:47:32.811539Z","iopub.status.idle":"2021-11-20T03:47:34.103635Z","shell.execute_reply.started":"2021-11-20T03:47:32.811495Z","shell.execute_reply":"2021-11-20T03:47:34.102803Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>The survey data suggests that Data science professionals are distributed proportionally across general industry.</li>\n    <li>Start-up (0-49 employees) accounts the most in Non-profit/Service.</li>\n    <li>Large corporation (10,000 + employees) accounts the most in Insurance/Risk Assessment </li>\n</ul>\n</div>\n","metadata":{}},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\ntest = test[test['Q26'].notna()]\ntest['Q26'].unique()\n#test = test[test['Q26'] != '$0 ($USD)']\ntest = test.groupby(['Q26', 'Q20']).size()\ndf = test.to_frame(name = 'size').reset_index()\ndf= pd.pivot(\n    data = df,\n    index = 'Q20',\n    columns = 'Q26',\n    values = 'size')\ndf.index.names = ['Industry']\ndf.columns.names = ['Money Spent']\n\n#c = ['$0 ($USD)', '$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\nc = ['$1-$99','$100-$999', '$1000-$9,999','$10,000-$99,999', '$100,000 or more ($USD)']\ndf = df.reindex(c, axis = 1)\ndf = df.sort_values(by='$100,000 or more ($USD)', ascending = False)\n\nfig, ax1 = plt.subplots(figsize = (21,10))\ndf.plot(kind = 'barh', ax = ax1)\nax1.set(title = \"Money Spent on ML or Cloud computing service by industry ranked in 100,000+ in 2021\",\n       xlabel = \"Counts\",\n       ylabel = \"Industry\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:34.105150Z","iopub.execute_input":"2021-11-20T03:47:34.105620Z","iopub.status.idle":"2021-11-20T03:47:35.469319Z","shell.execute_reply.started":"2021-11-20T03:47:34.105580Z","shell.execute_reply":"2021-11-20T03:47:35.468705Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Computers/Technology accounts the highest number of companies that spend over $100,000+</li>\n    <li>While the number of data science professionals working in Academic/Education industry ranked the second(in previous chart), the number of institutions that spend over 100,000+ are ranked only at 6th.</li>\n\n</ul>\n</div>\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = {'$0 ($USD)': '$0 ($USD)',\n     '$1-$99': '$1-$99',\n     '$100-$999': '$100-$999',\n     '$1000-$9,999': '$1000-$9,999',\n     '$10,000-$99,999': '$10,000-$99,999',\n     '$100,000 or more ($USD)': '$100,000 or +',\n     '> $100,000 ($USD)': '$100,000 or +',\n}\n\ntemp_2021 = get_professionals(data_2021, 'Q5')\ntemp_2020 = get_professionals(data_2020, 'Q5')\n\n\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\n#data_2019['Q11'] = data_2019['Q11'].map(c)\n\nmoney_spent_2021 = temp_2021[temp_2021['Q26'].notna()]\nmoney_spent_2021['Q26'] = money_spent_2021['Q26'].map(c)\nmoney_spent_2021 = money_spent_2021[money_spent_2021['Q26'] != '$0 ($USD)']\n\nmoney_spent_2020 = temp_2020[temp_2020['Q25'].notna()]\nmoney_spent_2020['Q25'] = money_spent_2020['Q25'].map(c)\nmoney_spent_2020 = money_spent_2020[money_spent_2020['Q25'] != '$0 ($USD)']\n\nmoney_spent_2019 = data_2019[data_2019['Q11'].notna()]\nmoney_spent_2019['Q11'] = money_spent_2019['Q11'].map(c)\n\nrow_order = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or +']\n\ndf_2021 = pd.DataFrame(money_spent_2021['Q26'].value_counts(), index = row_order)\ndf_2020 = pd.DataFrame(money_spent_2020['Q25'].value_counts(), index = row_order)\ndf_2019 = pd.DataFrame(money_spent_2019['Q11'].value_counts(), index = row_order)\n\ndf_final = pd.concat([df_2019, df_2020, df_2021], axis = 1)\ndf_final.rename(columns = {'Q26': '2021', 'Q25': '2020', 'Q11': '2019'}, inplace= True)\ndf_final = df_final.T\n\nfig, ax1 = plt.subplots(figsize = (16,8))\ndf_final.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"The amount and number of companies/institutions spending on ML infrastructure from 2019 to 2021\",\n       xlabel = \"Year\",\n       ylabel = \"Counts\")\nax1.legend(title='money spent')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T06:01:23.861162Z","iopub.execute_input":"2021-11-20T06:01:23.861502Z","iopub.status.idle":"2021-11-20T06:01:25.129029Z","shell.execute_reply.started":"2021-11-20T06:01:23.861467Z","shell.execute_reply":"2021-11-20T06:01:25.127962Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Total aggregate spending on ML went up from 2019 to 2021. The dip in 2020 is likely due to covid-19</li>\n\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"hardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\nhardware_2021_df = pros_2021[hardware_2021]\ncount_hardware_2021 = pd.Series(hardware_2021_df[hardware_2021].squeeze().values.ravel()).value_counts()\n\nhardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\nhardware_2020_df = pros_2020[hardware_2020]\ncount_hardware_2020 = pd.Series(hardware_2020_df[hardware_2020].squeeze().values.ravel()).value_counts()\n\nhardware_2019 = ['Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5','Q21_OTHER_TEXT']\nhardware_2019_df = pros_2019[hardware_2019]\ncount_hardware_2019 = pd.Series(hardware_2019_df[hardware_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_hardware_2021 = pd.DataFrame(count_hardware_2021)\ndf_count_hardware_2021 = df_count_hardware_2021.reset_index()\ndf_count_hardware_2021.columns = ['manage', '2021']\n\ndf_count_hardware_2020 = pd.DataFrame(count_hardware_2020)\ndf_count_hardware_2020 = df_count_hardware_2020.reset_index()\ndf_count_hardware_2020.columns = ['manage', '2020']\n\ndf_count_hardware_2019 = pd.DataFrame(count_hardware_2019)\ndf_count_hardware_2019 = df_count_hardware_2019.reset_index()\ndf_count_hardware_2019.columns = ['manage', '2019']\n\ndf_count_hardware_2019 = df_count_hardware_2019.iloc[1:6]\ndf_count_hardware_2019 = df_count_hardware_2019.set_index('manage').T[['GPUs', 'TPUs','Other']]\n\ndf_count_hardware_2020 = df_count_hardware_2020.set_index('manage').T[['GPUs', 'TPUs', 'Other']]\n\ndf_count_hardware_2021 = df_count_hardware_2021.set_index('manage').T\ndf_count_hardware_2021.columns = df_count_hardware_2021.columns.str.strip()\ndf_count_hardware_2021 = df_count_hardware_2021[['NVIDIA GPUs','Google Cloud TPUs','Other','AWS Inferentia Chips','AWS Trainium Chips']]\ndf_count_hardware_2021 = df_count_hardware_2021.rename(columns = {'NVIDIA GPUs': 'GPUs',\n                                                                    'Google Cloud TPUs': 'TPUs',\n                                                                    'Other': 'Other',\n                                                                    'AWS Inferentia Chips': 'AWS Inferentia',\n                                                                    'AWS Trainium Chips': 'AWS Trainium'})\n\ndf_hardware_merged = df_count_hardware_2019.append(df_count_hardware_2020).append(df_count_hardware_2021).fillna(0)\n\nfig, ax = plt.subplots(figsize=(18,6))\ndf_hardware_merged.plot(kind='bar', ax=ax)\nax.set(title = 'Special hardware usage trend',\n    xlabel = 'year',\n      ylabel = 'number of respondants',\n      )\n\nax.annotate(\"AWS's custom chips are added in 2021\", xy=(2.1, 1000), xytext=(2.3, 2000),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nax.legend(title='Special hardware')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:58:20.016439Z","iopub.execute_input":"2021-11-20T05:58:20.016844Z","iopub.status.idle":"2021-11-20T05:58:20.444572Z","shell.execute_reply.started":"2021-11-20T05:58:20.016789Z","shell.execute_reply":"2021-11-20T05:58:20.443634Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>AWS launched its own chipset in early 2021. Newly added</li>\n    <li>While GPU usage stagnated <strong>there is significant jump in TPU usage in 2021</strong></li>\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"large_spender_2020 = pros_2020.loc[pros_2020['Q25'].isin(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)'])]\nhardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\n\nspender_hardware_2020 = pd.DataFrame()\n\nfor idx, comp_size in enumerate(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)']):\n    spender_comp_size = large_spender_2020.loc[large_spender_2020['Q25'] == comp_size]\n    idx = pd.Series(spender_comp_size[hardware_2020].squeeze().values.ravel()).value_counts()\n    spender_hardware_2020[comp_size] = idx\n    \nspender_hardware_2020 = spender_hardware_2020.rename(columns = {'$100,000 or more ($USD)': '100,000 +'})\nspender_hardware_2020 = spender_hardware_2020.T[['GPUs','TPUs', 'Other']]\n\nlarge_spender_2021 = pros_2021.loc[pros_2021['Q26'].isin(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)'])]\n\nhardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\n# ------------------\n\nspender_hardware_2021 = pd.DataFrame()\n\nfor idx, comp_size in enumerate(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)']):\n    spender_comp_size = large_spender_2021.loc[large_spender_2021['Q26'] == comp_size]\n    idx = pd.Series(spender_comp_size[hardware_2021].squeeze().values.ravel()).value_counts()\n    spender_hardware_2021[comp_size] = idx\n    \nspender_hardware_2021 = spender_hardware_2021.rename(columns = {'$100,000 or more ($USD)': '100,000 +'})\nspender_hardware_2021 = spender_hardware_2021[1:].T\n\n# ---- plot\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (22,10))\n\nplt.subplot(121)\nspender_hardware_2020.plot(kind='bar', ax=ax1)\nax1.set(title = \"Special hardware usage by spending size in 2020\")\nax1.legend(loc=1, prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.2)\n\nplt.subplot(122)\nspender_hardware_2021.plot(kind='bar', ax=ax2)\nax2.set(title = \"Special hardware usage by spending size in 2021\")\nax2.legend(loc=1, prop={'size': 9})","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:37.026792Z","iopub.execute_input":"2021-11-20T03:47:37.027285Z","iopub.status.idle":"2021-11-20T03:47:37.726825Z","shell.execute_reply.started":"2021-11-20T03:47:37.027250Z","shell.execute_reply":"2021-11-20T03:47:37.726128Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-family:Helvetica Neue; font-size:16px; line-height:1.7; color:black;\">\n<ul>\n    <li>Broad increase in TPU usage.</li>\n\n</ul>\n</div>","metadata":{}},{"cell_type":"code","source":"# ---------------------\n# ML Algos 2019 to 2021\n# ---------------------\n\n# ----\n# 2021\n# ----\ntest = get_professionals(data_2021, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2021')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2021 = algo_df\n\n# ----\n# 2020\n# ----\n\ntest = get_professionals(data_2020, 'Q5')\n\nold_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\n\nalgos = test[['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11','Q17_OTHER']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2020')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2020 = algo_df\n\n# ----\n# 2019\n# ----\n\nold_colnames = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11', 'Q24_Part_12']\n#new_colnames = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11']\n\nnew_colnames = ['Regression', 'Decision Trees', 'Gradient Boosting', 'Bayesian', 'Evolutionary', 'DNN', 'CNN', 'GAN', 'RNN', 'Transformer', 'None', 'Other']\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\n\n\npd.set_option('display.max_columns', None)\ndata_2019.head()\ndata_2019 = data_2019[data_2019['Q5'].notna()]\ndata_2019 = data_2019[data_2019['Q5'] != 'Student']\ndata_2019 = data_2019[data_2019['Q5'] != 'Not employed']\nalgos = data_2019[['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8','Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12']]\ncol_rename_dict = {i:j for i,j in zip(old_colnames,new_colnames)}\nalgos.rename(columns=col_rename_dict, inplace=True)\nalgos = algos.fillna(0)\nalgos[algos != 0] = 1\nalgos.replace({False: 0, True: 1}, inplace=True)\nalgo_df = algos[algos==True].count(axis=0).rename_axis('Algo').reset_index(name='2019')\nalgo_df = algo_df.set_index('Algo').T\nstuff_2019 = algo_df\n\n# ---------------\n# Merge the frame\n# ---------------\n\nalgo_set = stuff_2021.append([stuff_2020, stuff_2019])\nalgo_set = algo_set.T\nalgo_set = algo_set[['2019', '2020', '2021']]\nalgo_set = algo_set.sort_values(by='2021',ascending = False)\n\n# -------------\n\ngpu_algo = ['Q12_Part_1',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\ntpu_algo = ['Q12_Part_2',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\nalgo = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\ngpu_use_algo = pros_2021[gpu_algo]\ngpu_use_algo = gpu_use_algo[gpu_use_algo['Q12_Part_1'].notna()]\n\ngpu_algo_count = pd.Series(gpu_use_algo[algo].squeeze().values.ravel()).value_counts()\ndf_gpu_algo_count = pd.DataFrame(gpu_algo_count)\n\n\n# ---------\n\n\ngpu_algo = ['Q12_Part_1',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\ntpu_algo = ['Q12_Part_2',\n           'Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\n\nalgo = ['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4', 'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9','Q17_Part_10', 'Q17_Part_11', 'Q17_OTHER']\ntpu_algo_algo = pros_2021[tpu_algo]\ntpu_algo_algo = tpu_algo_algo[tpu_algo_algo['Q12_Part_2'].notna()]\n\ntpu_algo_count = pd.Series(tpu_algo_algo[algo].squeeze().values.ravel()).value_counts()\ndf_tpu_algo_count = pd.DataFrame(tpu_algo_count)\n\n# -----------\n\ngpu_tpu_algo = pd.DataFrame()\ngpu_tpu_algo['NVIDIA GPUs'] = df_gpu_algo_count\ngpu_tpu_algo['Google Cloud TPUs'] = df_tpu_algo_count\n\ngpu_tpu_algo = gpu_tpu_algo.T\ngpu_tpu_algo = gpu_tpu_algo.rename(columns = \n{'Linear or Logistic Regression': 'Regression',\n 'Decision Trees or Random Forests': 'Decision Trees',\n 'Convolutional Neural Networks': 'CNN',\n 'Gradient Boosting Machines (xgboost, lightgbm, etc)': 'Gradient Boosting',\n 'Dense Neural Networks (MLPs, etc)': 'DNN',\n 'Recurrent Neural Networks': 'RNN',\n 'Bayesian Approaches': 'Bayesian',\n 'Transformer Networks (BERT, gpt-3, etc)': 'Transformer',\n 'Generative Adversarial Networks': 'GAN',\n 'Evolutionary Approaches': 'Evolutionary',\n 'None': 'None',\n 'Other': 'Other'})\n\ngpu_tpu_algo = gpu_tpu_algo.T\ngpu_tpu_algo = gpu_tpu_algo.sort_values(by = 'Google Cloud TPUs', ascending = False)\n\n# --------------\n# Plot the chart\n# --------------\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (22,8))\n\nplt.subplot(121)\nalgo_set.plot(kind = 'bar', ax = ax1)\nax1.set(title = \"ML Algo\")\nplt.axvline(x = 2.5, ymin= -0.05, ymax= 1.1, color='black', linestyle='dashed', linewidth=3)\nplt.annotate(\"Deep learning algos\", xytext=(2.8, 6000), xy=(8, 3500), \n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nfig.subplots_adjust(wspace=0.2)\n\nplt.subplot(122)\ngpu_tpu_algo.plot(kind = 'bar', ax = ax2)\nax2.set(title = \"ML algo and GPU/TPU in 2021\")\nplt.axvline(x = 2.5, ymin= -0.05, ymax= 1.1, color='black', linestyle='dashed', linewidth=3)\nplt.annotate(\"Less CNN user than Gradient boost, but higher demand in GPU/TPU\", xytext=(2.8, 3000), xy=(2, 2500), \n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.annotate(\"\", xytext=(3, 3000), xy=(2.8, 2400), \n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:52:47.682653Z","iopub.execute_input":"2021-11-20T05:52:47.682989Z","iopub.status.idle":"2021-11-20T05:52:49.670878Z","shell.execute_reply.started":"2021-11-20T05:52:47.682954Z","shell.execute_reply":"2021-11-20T05:52:49.670015Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"test = get_professionals(data_2021, 'Q5')\n\n# ----------------------------------------------------------------------------------------\n# 2021 (#18 and #19), 2020 (#18 and #19), 2019 (#26 and #27) About Computer vision and NLP\n# ----------------------------------------------------------------------------------------\n\n# ---------------------------------\n# COMPUTER VISION YES OR NO in 2021\n# ---------------------------------\n\nvision = test[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER']]\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nvision = vision.fillna(0)\nvision[vision != 0] = 1\nvision_df = vision[vision==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nvision_df = vision_df.set_index('Algo').T\nstuff_2020 = vision_df\n\nvision['yes'] = vision[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_OTHER']].sum(axis = 1)\nvision['yes'] = vision['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nvision['no'] = (vision['yes'].apply(lambda x: x == 0) | vision['Q18_Part_6'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nvision['Q20'] = test['Q20']\nvision = vision.drop(columns=['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER'])\nvision.replace({False: 0, True: 1}, inplace=True)\nvision_df = vision[vision['yes'] == 1].groupby('Q20').size()\n\ntotal_boss = vision['Q20'].value_counts()\n\nboss = pd.DataFrame(vision_df)\ntotal_boss = pd.DataFrame(total_boss)\nfinal_boss = total_boss.join(boss)\nfinal_boss.rename(columns = {final_boss.columns[0]: 'NO', final_boss.columns[1]: 'YES'}, inplace = True)\n#final_boss\n\n# ---------------------\n# NLP YES OR NO in 2021\n# ---------------------\n\nnlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\nnlp = nlp.fillna(0)\nnlp[nlp != 0] = 1\nnlp_df = nlp[nlp==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\nnlp_df = nlp_df.set_index('Algo').T\n\nnlp['yes'] = nlp[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_OTHER']].sum(axis = 1)\nnlp['yes'] = nlp['yes'].apply(lambda x: x>=1)\n#vision['yes'].value_counts()\nnlp['no'] = (nlp['yes'].apply(lambda x: x == 0) | nlp['Q19_Part_5'].apply(lambda x: x == 1))\n#vision['no'].value_counts()\n\nnlp['Q20'] = test['Q20']\nnlp = nlp.drop(columns=['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER'])\nnlp.replace({False: 0, True: 1}, inplace=True)\nnlp_df = nlp[nlp['yes'] == 1].groupby('Q20').size()\n\ntotal_boss2 = nlp['Q20'].value_counts()\n\nboss2 = pd.DataFrame(nlp_df)\ntotal_boss2 = pd.DataFrame(total_boss2)\nfinal_boss2 = total_boss.join(boss2)\nfinal_boss2.rename(columns = {final_boss2.columns[1]: 'hello'}, inplace = True)\n#final_boss2['perc'] = final_boss2['hello'] * 100 / final_boss2['Q20']\nfinal_boss2.rename(columns = {final_boss2.columns[0]: 'NO', final_boss2.columns[1]: 'YES'}, inplace = True)\nfinal_boss2\n\n# --------------- \n#  SUBPLOTS - 1x2\n# ---------------\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(18,11))\n\nplt.subplot(121)   #  subplot 1\nfinal_boss.plot(kind='barh', ax = ax1)\nax1.set(title = \"Computer Vision Yes / No\",\n       xlabel = \"Counts\",\n       ylabel = \"Industry\")\n\n\n\nfor i,j in zip(ax1.containers[0], ax1.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(1)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax1.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax1.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nfig.subplots_adjust(wspace=1)\n\nplt.subplot(122)   #  subplot 2\nfinal_boss2.plot(kind='barh', ax = ax2)\nax2.set(title = \"NLP Yes / No\",\n       xlabel = \"Counts\",\n       ylabel = \"Industry\")\n\nfor i,j in zip(ax2.containers[0], ax2.containers[1]):\n\n    perc = j.get_width() / i.get_width()\n    perc = (perc*100).round(1)\n    non_perc = (100 - perc).round(2)\n    \n    width = i.get_width()\n    height = i.get_height()\n    x, y = i.get_xy()\n    ax2.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n    \n    width2 = j.get_width()\n    height2 = j.get_height()\n    x2, y2 = j.get_xy() \n    ax2.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:56:39.621922Z","iopub.execute_input":"2021-11-20T05:56:39.622272Z","iopub.status.idle":"2021-11-20T05:56:41.351465Z","shell.execute_reply.started":"2021-11-20T05:56:39.622236Z","shell.execute_reply":"2021-11-20T05:56:41.350561Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"industry_gpu = ['Q20', 'Q12_Part_1']\nindustry_by_gpu = pros_2021[industry_gpu]\nindustry_by_gpu = industry_by_gpu[industry_by_gpu['Q20'].notna()]\n\nindustry_list = list(industry_by_gpu['Q20'].unique())\n\nind_gpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_gpu = industry_by_gpu.loc[industry_by_gpu['Q20'] == ind]\n    idx = pd.Series(ind_gpu['Q12_Part_1'].squeeze().values.ravel()).value_counts()\n    ind_gpu_merged[ind] = idx\n    \n    \nindustry_tpu = ['Q20', 'Q12_Part_2']\nindustry_by_tpu = pros_2021[industry_tpu]\nindustry_by_tpu = industry_by_tpu[industry_by_tpu['Q20'].notna()]\n\nind_tpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_tpu = industry_by_tpu.loc[industry_by_tpu['Q20'] == ind]\n    idx = pd.Series(ind_tpu['Q12_Part_2'].squeeze().values.ravel()).value_counts()\n    ind_tpu_merged[ind] = idx\n\nind_gpu_tpu = ind_gpu_merged.append(ind_tpu_merged).T\nind_gpu_tpu.columns = ind_gpu_tpu.columns.str.strip()\nind_gpu_tpu = ind_gpu_tpu.sort_values(by = 'NVIDIA GPUs', ascending = False)\n\nfig, ax = plt.subplots(figsize = (11,10))\nind_gpu_tpu.plot(kind = 'barh', ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T05:53:41.928610Z","iopub.execute_input":"2021-11-20T05:53:41.928979Z","iopub.status.idle":"2021-11-20T05:53:42.538551Z","shell.execute_reply.started":"2021-11-20T05:53:41.928937Z","shell.execute_reply":"2021-11-20T05:53:42.537883Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n\n# Which of the following cloud computing platforms do you use on a regular basis? \n# 2021 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\t\n# 2020 Q26_A_Part_1\tQ26_A_Part_2\tQ26_A_Part_3\tQ26_A_Part_4\tQ26_A_Part_5\tQ26_A_Part_6\tQ26_A_Part_7\tQ26_A_Part_8\tQ26_A_Part_9\tQ26_A_Part_10\tQ26_A_Part_11\tQ26_A_OTHER\n# 2019 Q29_Part_1\tQ29_Part_2\tQ29_Part_3\tQ29_Part_4\tQ29_Part_5\tQ29_Part_6\tQ29_Part_7\tQ29_Part_8\tQ29_Part_9\tQ29_Part_10\tQ29_Part_11\tQ29_Part_12\n\n# Do you use any of the following cloud computing products on a regular basis? (Select all that apply)\n# 2021  Q29_A_Part_1\tQ29_A_Part_2\tQ29_A_Part_3\tQ29_A_Part_4\tQ29_A_OTHER\n#Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected the relevant answer choices for Question 27-A (which of the following companies).\n# 2020 Q27_A_Part_1\tQ27_A_Part_2\tQ27_A_Part_3\tQ27_A_Part_4\tQ27_A_Part_5\tQ27_A_Part_6\tQ27_A_Part_7\tQ27_A_Part_8\tQ27_A_Part_9\tQ27_A_Part_10\tQ27_A_Part_11\tQ27_A_OTHER\n# 2019 Q30_Part_1\tQ30_Part_2\tQ30_Part_3\tQ30_Part_4\tQ30_Part_5\tQ30_Part_6\tQ30_Part_7\tQ30_Part_8\tQ30_Part_9\tQ30_Part_10\tQ30_Part_11\n\n# Which of the following automated machine learning tools (or partial AutoML tools) do you use on aregular basis? (Select all that apply)\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\tQ28_A_OTHER\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\tQ32_OTHER_TEXT\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:42.221232Z","iopub.execute_input":"2021-11-20T03:47:42.221464Z","iopub.status.idle":"2021-11-20T03:47:42.226689Z","shell.execute_reply.started":"2021-11-20T03:47:42.221437Z","shell.execute_reply":"2021-11-20T03:47:42.225667Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pros_2021 = get_professionals(data_2021, 'Q5')\npros_2020 = get_professionals(data_2020, 'Q5')\n\npros_2019 = data_2019[data_2019['Q5'].notna()]\npros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\npros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:42.228088Z","iopub.execute_input":"2021-11-20T03:47:42.228324Z","iopub.status.idle":"2021-11-20T03:47:42.892274Z","shell.execute_reply.started":"2021-11-20T03:47:42.228296Z","shell.execute_reply":"2021-11-20T03:47:42.891300Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cloud usage\n\ncloud_2021 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8',\n 'Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_2021 = pros_2021[cloud_2021]\ndf_2021\n\ncount_2021 = pd.Series(df_2021[cloud_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_2021 = pd.DataFrame(count_2021)\ndf_count_2021 = df_count_2021.reset_index()\ndf_count_2021.columns = ['Cloud', 'Counts']\n\n# --------------------------------------------\n\ncloud_2020 = ['Q26_A_Part_1','Q26_A_Part_2','Q26_A_Part_3','Q26_A_Part_4','Q26_A_Part_5','Q26_A_Part_6',\n'Q26_A_Part_7','Q26_A_Part_8','Q26_A_Part_9','Q26_A_Part_10','Q26_A_Part_11','Q26_A_OTHER']\ndf_2020 = pros_2020[cloud_2020]\n\ncount_2020 = pd.Series(df_2020[cloud_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_2020 = pd.DataFrame(count_2020)\ndf_count_2020 = df_count_2020.reset_index()\ndf_count_2020.columns = ['Cloud', 'Counts']\n\n# ----------------------------------------------\n\n\ncloud_2019 = ['Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7',\n              'Q29_Part_8','Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12'] #Q29_OTHER_TEXT\n\ndf_2019 = pros_2019[cloud_2019]\n\ncount_2019 = pd.Series(df_2019[cloud_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_2019 = pd.DataFrame(count_2019)\ndf_count_2019 = df_count_2019.reset_index()\ndf_count_2019.columns = ['Cloud', 'Counts']\ndf_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\ndf_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\n\n# -------- merge ------\n\n\n\ncloud_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_df['Counts'][4] = 451\ncloud_df = cloud_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\ncloud_df_bar = cloud_df.set_index('Cloud').T[::-1]\n\n# --------- 2nd chart -----\n\ncloud_df = cloud_df.T\ncloud_df.columns = cloud_df.iloc[0]\ncloud_df = cloud_df.drop(cloud_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_df = cloud_df.iloc[::-1] # reverse ro\n\nfor_perc = cloud_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\n\n# ------------- plot ------\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(22,8))\n\n\nplt.subplot(121)   #  subplot 1\n\ncloud_df_bar.plot(kind = 'bar', ax= ax1)\nax1.set(title = \"Cloud computing platform usage\")\nax1.legend(loc='lower right', bbox_to_anchor=(1.34, 0), prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.4)\n\n\nplt.subplot(122) #  subplot 2\n\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax2,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n             )\nax2.set(title = \"Cloud market share surveyed\")\nax2.legend(loc='lower right', bbox_to_anchor=(1.34, 0), prop={'size': 9})\nax2.annotate('Share of none is decreasing', xy=(1.6, 0.55), xytext=(0.06, 0.6),\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize=12,\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:42.893495Z","iopub.execute_input":"2021-11-20T03:47:42.893798Z","iopub.status.idle":"2021-11-20T03:47:43.861262Z","shell.execute_reply.started":"2021-11-20T03:47:42.893743Z","shell.execute_reply":"2021-11-20T03:47:43.860342Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloud_computing_2019 = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_OTHER_TEXT']\ndf_computing_2019 = pros_2019[cloud_computing_2019]\ncount_compute_2019 = pd.Series(df_computing_2019[cloud_computing_2019].squeeze().values.ravel()).value_counts()\n\n#-----------------\ndf_count_compute_2019 = pd.DataFrame(count_compute_2019)\ndf_count_compute_2019 = df_count_compute_2019.reset_index()\ndf_count_compute_2019.columns = ['Cloud Compute', 'Counts']\n#------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].str.strip()\ndf_count_compute_2019 = df_count_compute_2019[(df_count_compute_2019['Cloud Compute'] == 'AWS Elastic Compute Cloud (EC2)') |\n                      (df_count_compute_2019['Cloud Compute'] == 'Google Compute Engine (GCE)') |\n                     (df_count_compute_2019['Cloud Compute'] == 'Azure Virtual Machines') |\n                     (df_count_compute_2019['Cloud Compute'] == 'None')\n                                             ]\n#----------------------\ndf_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].replace({\n                                                'AWS Elastic Compute Cloud (EC2)': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Compute Engine (GCE)': 'Google Cloud Compute Engine',\n                                                'Azure Virtual Machines': 'Microsoft Azure Virtual Machines',\n                                                'None': 'No / None'\n                                               })\n\n\n\ncloud_computing_2020 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8','Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\ndf_computing_2020 = pros_2020[cloud_computing_2020]\ncount_compute_2020 = pd.Series(df_computing_2020[cloud_computing_2020].squeeze().values.ravel()).value_counts()\n#------------\ndf_count_compute_2020 = pd.DataFrame(count_compute_2020)\ndf_count_compute_2020 = df_count_compute_2020.reset_index()\ndf_count_compute_2020.columns = ['Cloud Compute', 'Counts']\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].str.strip()\ndf_count_compute_2020 = df_count_compute_2020[(df_count_compute_2020['Cloud Compute'] == 'Amazon EC2') |\n                      (df_count_compute_2020['Cloud Compute'] == 'Google Cloud Compute Engine') |\n                     (df_count_compute_2020['Cloud Compute'] == 'Azure Cloud Services') |\n                     (df_count_compute_2020['Cloud Compute'] == 'No / None')\n                     ]\n#--------------\ndf_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].replace({\n                                                'Amazon EC2': 'Amazon Elastic Compute Cloud (EC2)',\n                                               'Google Cloud Compute Engine': 'Google Cloud Compute Engine',\n                                                'Azure Cloud Services': 'Microsoft Azure Virtual Machines'\n                                               })\n\n\n\n#----------\ncloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\ndf_computing_2021 = pros_2021[cloud_computing_2021]\ncount_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n# ----------\ndf_count_compute_2021 = pd.DataFrame(count_compute_2021)\ndf_count_compute_2021 = df_count_compute_2021.reset_index()\ndf_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n#------------\ndf_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()\ndf_count_compute_2021 = df_count_compute_2021[(df_count_compute_2021['Cloud Compute'] != 'Other')]\n\ncloud_compute_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\ncloud_compute_df = df_count_compute_2021.merge(df_count_compute_2020, on = 'Cloud Compute').merge(df_count_compute_2019, how = 'left')\ncloud_compute_df = cloud_compute_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\n\ncloud_compute_df = cloud_compute_df.T\ncloud_compute_df.columns = cloud_compute_df.iloc[0]\ncloud_compute_df = cloud_compute_df.drop(cloud_compute_df.index[0])\n#cloud_df.index.name = 'Cloud'\ncloud_compute_df = cloud_compute_df.iloc[::-1] # reverse ro\n\n# ---- percentage ----\n\nfor_perc = cloud_compute_df\nfor_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n\n\n\n# --- plot ---\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (22,8))\nplt.subplot(121)   #  subplot 1\n\ncloud_compute_df.plot(kind = 'bar', ax= ax1)\nax1.set(title = \"Cloud computing product usage\")\nax1.legend(loc='lower right', bbox_to_anchor=(1.35, 0), prop={'size': 9})\n\n\nfig.subplots_adjust(wspace=0.4)\n\nplt.subplot(122) #  subplot 2\n\nfor_perc.plot(kind='area', \n              stacked=True,\n              ax = ax2,\n             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',)\n             )\nax2.set(title = \"Cloud computing product share\")\nax2.legend(loc='lower right', bbox_to_anchor=(1.36, 0), prop={'size': 9})\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:43.862463Z","iopub.execute_input":"2021-11-20T03:47:43.862675Z","iopub.status.idle":"2021-11-20T03:47:44.394802Z","shell.execute_reply.started":"2021-11-20T03:47:43.862648Z","shell.execute_reply":"2021-11-20T03:47:44.393962Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Machine learning tools\n# Google cloud Speect-to-Text, Google Cloud Natural Language, Google Cloud Vision, Google Cloud Translation are assumed under Google Cloud Machine Learning\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# 2021 Q31_A_Part_1\tQ31_A_Part_2\tQ31_A_Part_3\tQ31_A_Part_4\tQ31_A_Part_5\tQ31_A_Part_6\tQ31_A_Part_7\tQ31_A_Part_8\tQ31_A_Part_9\tQ31_A_OTHER\n# 2020 Q28_A_Part_1\tQ28_A_Part_2\tQ28_A_Part_3\tQ28_A_Part_4\tQ28_A_Part_5\tQ28_A_Part_6\tQ28_A_Part_7\tQ28_A_Part_8\tQ28_A_Part_9\tQ28_A_Part_10\n# 2019 Q32_Part_1\tQ32_Part_2\tQ32_Part_3\tQ32_Part_4\tQ32_Part_5\tQ32_Part_6\tQ32_Part_7\tQ32_Part_8\tQ32_Part_9\tQ32_Part_10\tQ32_Part_11\tQ32_Part_12\nml_product_2019 = ['Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8','Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12']\ndf_ml_product_2019 = pros_2019[ml_product_2019]\ncount_ml_product_2019 = pd.Series(df_ml_product_2019[ml_product_2019].squeeze().values.ravel()).value_counts()\n#count_ml_product_2019\n\ndf_count_ml_2019 = pd.DataFrame(count_ml_product_2019)\ndf_count_ml_2019 = df_count_ml_2019.reset_index()\ndf_count_ml_2019.columns = ['ML engine', 'Counts']\n\n#-------\n\nml_product_2020 = ['Q28_A_Part_1','Q28_A_Part_2','Q28_A_Part_3','Q28_A_Part_4','Q28_A_Part_5','Q28_A_Part_6','Q28_A_Part_7','Q28_A_Part_8','Q28_A_Part_9','Q28_A_Part_10']\ndf_ml_product_2020 = pros_2020[ml_product_2020]\ncount_ml_product_2020 = pd.Series(df_ml_product_2020[ml_product_2020].squeeze().values.ravel()).value_counts()\n#count_ml_product_2020\n\ndf_count_ml_2020 = pd.DataFrame(count_ml_product_2020)\ndf_count_ml_2020 = df_count_ml_2020.reset_index()\ndf_count_ml_2020.columns = ['ML engine', 'Counts']\n\n#-------\n\nml_product_2021 = ['Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_OTHER']\ndf_ml_product_2021 = pros_2021[ml_product_2021]\ncount_ml_product_2021 = pd.Series(df_ml_product_2021[ml_product_2021].squeeze().values.ravel()).value_counts()\n#count_ml_product_2021\n\ndf_count_ml_2021 = pd.DataFrame(count_ml_product_2021)\ndf_count_ml_2021 = df_count_ml_2021.reset_index()\ndf_count_ml_2021.columns = ['ML engine', 'Counts']\n\n\n# --------------\n\n# Products are merged into one big category. \n# ex1) google vision, google NLP - > Google Cloud Vertex AI\n# ex2) Amazon forecast, recognition - > Amazon SageMaker\n\ndf_count_ml_2019 = df_count_ml_2019.drop(df_count_ml_2019.index[[0,5,7,8,9,11]])\n#df_count_ml_2019\n\ndf_count_ml_2020 = df_count_ml_2020.drop(df_count_ml_2020.index[[0,4,5,6,7,8,9]])\n#df_count_ml_2020\n\ndf_count_ml_2021 = df_count_ml_2021.drop(df_count_ml_2021.index[[0, 7]])\n#df_count_ml_2021\n\nengine_df = df_count_ml_2021.merge(df_count_ml_2020, on = 'ML engine', how = 'outer').merge(df_count_ml_2019, how = 'outer')\nengine_df = engine_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\nengine_df['ML engine'] = engine_df['ML engine'].str.strip()\nengine_df.at[8, 'ML engine'] = 'Google Cloud Vertex AI'\nengine_df.at[9, 'ML engine'] = 'Google Cloud Vertex AI'\nengine_df = engine_df.groupby(['ML engine']).sum()\nengine_df = engine_df.sort_values(by=['2021'], ascending = False).reset_index()\n\nengine_df = engine_df.set_index('ML engine').T[::-1]\ncolumns_clean = ['Amazon SageMaker','Azure Machine Learning Studio','Databricks','Google Cloud Vertex AI','DataRobot','Rapidminer','Alteryx','Dataiku']\nengine_df = engine_df[columns_clean]\n\ndummy_df = engine_df[['Amazon SageMaker','Azure Machine Learning Studio','Google Cloud Vertex AI']]\ndummy_df['multiplier'] = None\ndummy_df['multiplier'] = dummy_df.sum(axis=1).pct_change(periods = 1)\ngrowth_multiplier_2020 = dummy_df['multiplier'].iloc[1]\ngrowth_multiplier_2021 = dummy_df['multiplier'].iloc[2]\n\n\nfor col in ['Databricks', 'DataRobot', 'Rapidminer', 'Alteryx', 'Dataiku']:\n    engine_df[col].iloc[1] = engine_df[col].iloc[2]/(1+growth_multiplier_2021)\n    engine_df[col].iloc[0] = engine_df[col].iloc[1]/(1+growth_multiplier_2020)\n\nengine_df = engine_df.round(0)\nengine_df\n\n# color_dict = {'Databricks': '#FF0000', 'Rapidminer': '#0000FF'}\n# engine_df.plot(kind='bar', ax=ax1, color = [color_dict.get(x, '#333333') for x in engine_df.columns])\n\nfig, ax1 = plt.subplots(figsize = (22,8))\nengine_df.plot(kind='bar', ax=ax1)\n\nplt.annotate('Note: Number of Databricks, Datarobot, RapidMiner, Alteryx and Dataiku in 2019 and 2020 were derived from the yearly avg industry growth', \n             (0,0), \n             (-50,-50), \n             fontsize=8, \n             xycoords='axes fraction', \n             textcoords='offset points', va='top')\nax1.set(title = \"Managed machine learning product usage from 2019 to 2021\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:44.396458Z","iopub.execute_input":"2021-11-20T03:47:44.397037Z","iopub.status.idle":"2021-11-20T03:47:44.779923Z","shell.execute_reply.started":"2021-11-20T03:47:44.396998Z","shell.execute_reply":"2021-11-20T03:47:44.778920Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# AutoML regular basis\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\n# AutoML regular basis\n\n# Q37_A_Part_1\tQ37_A_Part_2\tQ37_A_Part_3\tQ37_A_Part_4\tQ37_A_Part_5\tQ37_A_Part_6\tQ37_A_Part_7\tQ37_A_OTHER\n# Q34_A_Part_1\tQ34_A_Part_2\tQ34_A_Part_3\tQ34_A_Part_4\tQ34_A_Part_5\tQ34_A_Part_6\tQ34_A_Part_7\tQ34_A_Part_8\tQ34_A_Part_9\tQ34_A_Part_10\tQ34_A_Part_11\tQ34_A_OTHER\t\n# autoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\n\nautoML_2021 = ['Q37_A_Part_1','Q37_A_Part_2','Q37_A_Part_3','Q37_A_Part_4','Q37_A_Part_5','Q37_A_Part_6','Q37_A_Part_7','Q37_A_OTHER']\ndf_autoML_2021 = pros_2021[autoML_2021]\ncount_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\ndf_count_autoML_2021 = df_count_autoML_2021.reset_index()\ndf_count_autoML_2021.columns = ['AutoML', 'Counts']\n#df_count_autoML_2021\n\n#-------\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\nautoML_2020 = ['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_OTHER']\ndf_autoML_2020 = pros_2020[autoML_2020]\ncount_autoML_2020 = pd.Series(df_autoML_2020[autoML_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2020 = pd.DataFrame(count_autoML_2020)\ndf_count_autoML_2020 = df_count_autoML_2020.reset_index()\ndf_count_autoML_2020.columns = ['AutoML', 'Counts']\n#df_count_autoML_2020\n\n# ---------------\n\nautoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\ndf_autoML_2019 = pros_2019[autoML_2019]\ncount_autoML_2019 = pd.Series(df_autoML_2019[autoML_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2019 = pd.DataFrame(count_autoML_2019)\ndf_count_autoML_2019 = df_count_autoML_2019.reset_index()\ndf_count_autoML_2019.columns = ['AutoML', 'Counts']\n\n# --------------\n\nautoML_df = df_count_autoML_2021.merge(df_count_autoML_2020, on = 'AutoML', how = 'outer').merge(df_count_autoML_2019, how = 'outer')\nautoML_df = autoML_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\nautoML_df = autoML_df.drop(autoML_df.index[[0,7,8,9,10,12,13,14,15]]) # Get rid of None and Others, auto sklearn, keras, autoML, Tpot,MLbox, Xcessiv\nautoML_df.at[16, 'AutoML'] = 'Google Cloud AutoML'\nautoML_df.at[11, 'AutoML'] = 'H2O Driverless AI'\nautoML_df['AutoML'] = autoML_df['AutoML'].str.strip()\nautoML_df = autoML_df.groupby(['AutoML']).sum()\nautoML_df = autoML_df.sort_values(by=['2021'], ascending = False)\n\nautoML_df = autoML_df.T\nautoML_df = autoML_df[::-1]\n\ndummy_df = autoML_df[['DataRobot AutoML','Databricks AutoML','Google Cloud AutoML','H2O Driverless AI']]\ndummy_df['total'] = dummy_df.sum(axis=1)\ndummy_df['total'] = dummy_df['total'].pct_change(periods=1)\nautoML_growth_2020 = dummy_df['total'].iloc[1]\nautoML_growth_2021 = dummy_df['total'].iloc[2]\n\nfor col in ['Amazon Sagemaker Autopilot', 'Azure Automated Machine Learning']:\n    autoML_df[col].iloc[1] = autoML_df[col].iloc[2]/(1+autoML_growth_2021)\n    autoML_df[col].iloc[0] = autoML_df[col].iloc[1]/(1+autoML_growth_2020)\n\nautoML_df = autoML_df.round(0)\n\n# --- Plot ----\n\nfig, ax1 = plt.subplots(figsize = (22,8))\nautoML_df.plot(kind='bar', ax=ax1)\n\nplt.annotate('Note: Numbers in Amazon Sagemaker Autopilot and Azure Automated Machine Learning in 2019 and 2020 were derived from the yearly avg industry growth', \n             (0,0), \n             (-50,-50), \n             fontsize=8, \n             xycoords='axes fraction', \n             textcoords='offset points', va='top')\nax1.set(title = \"AutoML usage from 2019 to 2021\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:44.781185Z","iopub.execute_input":"2021-11-20T03:47:44.781408Z","iopub.status.idle":"2021-11-20T03:47:45.171480Z","shell.execute_reply.started":"2021-11-20T03:47:44.781381Z","shell.execute_reply":"2021-11-20T03:47:45.170616Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# autoML in 2 years\n\n# 2021 : Q37_B_Part_1\tQ37_B_Part_2\tQ37_B_Part_3\tQ37_B_Part_4\tQ37_B_Part_5\tQ37_B_Part_6\tQ37_B_Part_7\tQ37_B_OTHER\n\n\nautoML_2021 = ['Q37_B_Part_1','Q37_B_Part_2','Q37_B_Part_3','Q37_B_Part_4','Q37_B_Part_5','Q37_B_Part_6','Q37_B_Part_7','Q37_B_OTHER']\ndf_autoML_2021 = pros_2021[autoML_2021]\ncount_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\ndf_count_autoML_2021 = df_count_autoML_2021.reset_index()\ndf_count_autoML_2021.columns = ['Cloud Compute', 'Counts']\n\n#autoML Familiar\n\n#pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', 100)\n\nautoML_2020 = ['Q34_B_Part_1','Q34_B_Part_2','Q34_B_Part_3','Q34_B_Part_4','Q34_B_Part_5','Q34_B_Part_6','Q34_B_Part_7','Q34_B_Part_8','Q34_B_Part_9','Q34_B_Part_10','Q34_B_Part_11','Q34_B_OTHER']\ndf_autoML_2020 = pros_2020[autoML_2020]\ncount_autoML_2020 = pd.Series(df_autoML_2020[autoML_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2020 = pd.DataFrame(count_autoML_2020)\ndf_count_autoML_2020 = df_count_autoML_2020.reset_index()\ndf_count_autoML_2020.columns = ['Cloud Compute', 'Counts']\n\n\n# autoML Familiar\n\nautoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\ndf_autoML_2019 = pros_2019[autoML_2019]\ncount_autoML_2019 = pd.Series(df_autoML_2019[autoML_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_autoML_2019 = pd.DataFrame(count_autoML_2019)\ndf_count_autoML_2019 = df_count_autoML_2019.reset_index()\ndf_count_autoML_2019.columns = ['Cloud Compute', 'Counts']","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:45.172648Z","iopub.execute_input":"2021-11-20T03:47:45.172893Z","iopub.status.idle":"2021-11-20T03:47:45.211555Z","shell.execute_reply.started":"2021-11-20T03:47:45.172849Z","shell.execute_reply":"2021-11-20T03:47:45.210945Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Big data products\n\nbig_data_2021 = ['Q32_A_Part_1','Q32_A_Part_2',\n                 'Q32_A_Part_3','Q32_A_Part_4',\n                 'Q32_A_Part_5','Q32_A_Part_6',\n                 'Q32_A_Part_7','Q32_A_Part_8',\n                 'Q32_A_Part_9','Q32_A_Part_10',\n                 'Q32_A_Part_11','Q32_A_Part_12',\n                 'Q32_A_Part_13','Q32_A_Part_14',\n                 'Q32_A_Part_15','Q32_A_Part_16',\n                 'Q32_A_Part_17','Q32_A_Part_18',\n                 'Q32_A_Part_19','Q32_A_Part_20','Q32_A_OTHER']\n\n\n\ndf_bigdata_2021 = pros_2021[big_data_2021]\ncount_bigdata_2021 = pd.Series(df_bigdata_2021[big_data_2021].squeeze().values.ravel()).value_counts()\n#count_bigdata_2021\n\ndf_count_bigdata_2021 = pd.DataFrame(count_bigdata_2021)\ndf_count_bigdata_2021 = df_count_bigdata_2021.reset_index()\ndf_count_bigdata_2021.columns = ['big data', 'Counts']\n\n# --------------------\n\nbig_data_2020 = ['Q29_A_Part_1','Q29_A_Part_2',\n                 'Q29_A_Part_3','Q29_A_Part_4',\n                 'Q29_A_Part_5','Q29_A_Part_6',\n                 'Q29_A_Part_7','Q29_A_Part_8',\n                 'Q29_A_Part_9','Q29_A_Part_10',\n                 'Q29_A_Part_11','Q29_A_Part_12',\n                 'Q29_A_Part_13','Q29_A_Part_14',\n                 'Q29_A_Part_15','Q29_A_Part_16',\n                 'Q29_A_Part_17','Q29_A_OTHER']\n\ndf_bigdata_2020 = pros_2020[big_data_2020]\ncount_bigdata_2020 = pd.Series(df_bigdata_2020[big_data_2020].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_bigdata_2020 = pd.DataFrame(count_bigdata_2020)\ndf_count_bigdata_2020 = df_count_bigdata_2020.reset_index()\ndf_count_bigdata_2020.columns = ['big data', 'Counts']\n\n# ----------------------\n\nbig_data_2019 = ['Q34_Part_1','Q34_Part_2',\n                 'Q34_Part_3','Q34_Part_4',\n                 'Q34_Part_5','Q34_Part_6',\n                 'Q34_Part_7','Q34_Part_8',\n                 'Q34_Part_9','Q34_Part_10',\n                 'Q34_Part_11','Q34_Part_12',\n                 'Q34_OTHER_TEXT']\n\ndf_bigdata_2019 = pros_2019[big_data_2019]\ncount_bigdata_2019 = pd.Series(df_bigdata_2019[big_data_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_bigdata_2019 = pd.DataFrame(count_bigdata_2019)\ndf_count_bigdata_2019 = df_count_bigdata_2019.reset_index()\ndf_count_bigdata_2019.columns = ['big data', 'Counts']\ndf_count_bigdata_2019 = df_count_bigdata_2019[(df_count_bigdata_2019['big data'] == 'MySQL') |\n                                              (df_count_bigdata_2019['big data'] == 'PostgresSQL') |\n                                              (df_count_bigdata_2019['big data'] == 'Microsoft SQL Server') |\n                                              (df_count_bigdata_2019['big data'] == 'SQLite') |\n                                              (df_count_bigdata_2019['big data'] == 'Oracle Database') |\n                                              (df_count_bigdata_2019['big data'] == 'AWS Relational Database Service') |\n                                              (df_count_bigdata_2019['big data'] == 'Microsoft Access') |\n                                              (df_count_bigdata_2019['big data'] == 'Google Cloud SQL') |\n                                              (df_count_bigdata_2019['big data'] == 'Azure SQL Database') |\n                                              (df_count_bigdata_2019['big data'] == 'AWS DynamoDB')\n                                             ]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:45.213080Z","iopub.execute_input":"2021-11-20T03:47:45.213608Z","iopub.status.idle":"2021-11-20T03:47:45.269553Z","shell.execute_reply.started":"2021-11-20T03:47:45.213573Z","shell.execute_reply":"2021-11-20T03:47:45.268932Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_count_bigdata_2019","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:45.270906Z","iopub.execute_input":"2021-11-20T03:47:45.271387Z","iopub.status.idle":"2021-11-20T03:47:45.281717Z","shell.execute_reply.started":"2021-11-20T03:47:45.271346Z","shell.execute_reply":"2021-11-20T03:47:45.280826Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def open_source(x):\n    if x == 'MySQL':\n        return 1\n    elif x == 'PostgreSQL':\n        return 1\n    elif x == 'MongoDB':\n        return 1\n    elif x == 'SQLite':\n        return 1\n    elif x == 'PostgresSQL':\n        return 1\n    else:\n        return 0\n    \ndef aws(x):\n    if 'Amazon' in x:\n        return 1\n    elif 'AWS' in x:\n        return 1\n    else:\n        return 0\n    \ndef gcp(x):\n    if 'Google' in x:\n        return 1\n    else:\n        return 0\n    \ndef azure(x):\n    if 'Microsoft' in x:\n        return 1\n    elif 'Azure' in x:\n        return 1\n    else: return 0\n\ndf_count_bigdata_2021['big data'] = df_count_bigdata_2021['big data'].str.strip()\ndf_count_bigdata_2021['open source'] = df_count_bigdata_2021['big data'].apply(open_source)\ndf_count_bigdata_2021['aws'] = df_count_bigdata_2021['big data'].apply(aws)\ndf_count_bigdata_2021['gcp'] = df_count_bigdata_2021['big data'].apply(gcp)\ndf_count_bigdata_2021['azure'] = df_count_bigdata_2021['big data'].apply(azure)\n\nopen_source_2021 = df_count_bigdata_2021[df_count_bigdata_2021['open source'] == 1]\nopen_source_2021 = open_source_2021[['big data', 'Counts']]\n\naws_2021 = df_count_bigdata_2021[df_count_bigdata_2021['aws'] == 1]\ngcp_2021 = df_count_bigdata_2021[df_count_bigdata_2021['gcp'] == 1]\nazure_2021 = df_count_bigdata_2021[df_count_bigdata_2021['azure'] == 1]\nothers_2021 = df_count_bigdata_2021[(df_count_bigdata_2021['aws'] != 1) & \n                                    (df_count_bigdata_2021['gcp'] != 1) & \n                                    (df_count_bigdata_2021['azure'] != 1) &\n                                    (df_count_bigdata_2021['open source'] != 1)]\n\naws_2021['big data'].iloc[0] = 'aws'\ngcp_2021['big data'].iloc[0] = 'gcp'\nazure_2021['big data'].iloc[0] = 'azure'\n\ncommercial_2021 = aws_2021.iloc[:1].append([gcp_2021.iloc[:1], azure_2021.iloc[:1], others_2021])\nto_drop = ['None', 'Other']\ncommercial_2021 = commercial_2021[~commercial_2021['big data'].isin(to_drop)]\ncommercial_2021 = commercial_2021[['big data', 'Counts']]\n\nopen_source_2021 = open_source_2021.merge(commercial_2021, on = 'big data', how = 'outer')\nopen_source_2021 = open_source_2021.rename(columns = {'Counts_x' : 'open source_2021', 'Counts_y' : 'commercial_2021'})\n\nopen_source_2021 = open_source_2021.set_index('big data').T\n\n#fig, ax1 = plt.subplots(figsize = (16,8))\n#open_source_2021.plot(kind = 'bar', stacked = True, ax = ax1)\n\n\n# -------------\n\ndf_count_bigdata_2020['big data'] = df_count_bigdata_2020['big data'].str.strip()\ndf_count_bigdata_2020['open source'] = df_count_bigdata_2020['big data'].apply(open_source)\ndf_count_bigdata_2020['aws'] = df_count_bigdata_2020['big data'].apply(aws)\ndf_count_bigdata_2020['gcp'] = df_count_bigdata_2020['big data'].apply(gcp)\ndf_count_bigdata_2020['azure'] = df_count_bigdata_2020['big data'].apply(azure)\n\nopen_source_2020 = df_count_bigdata_2020[df_count_bigdata_2020['open source'] == 1]\nopen_source_2020 = open_source_2020[['big data', 'Counts']]\n\naws_2020 = df_count_bigdata_2020[df_count_bigdata_2020['aws'] == 1]\ngcp_2020 = df_count_bigdata_2020[df_count_bigdata_2020['gcp'] == 1]\nazure_2020 = df_count_bigdata_2020[df_count_bigdata_2020['azure'] == 1]\nothers_2020 = df_count_bigdata_2020[(df_count_bigdata_2020['aws'] != 1) & \n                                    (df_count_bigdata_2020['gcp'] != 1) & \n                                    (df_count_bigdata_2020['azure'] != 1) &\n                                    (df_count_bigdata_2020['open source'] != 1)]\n\naws_2020['big data'].iloc[0] = 'aws'\ngcp_2020['big data'].iloc[0] = 'gcp'\nazure_2020['big data'].iloc[0] = 'azure'\n\ncommercial_2020 = aws_2020.iloc[:1].append([gcp_2020.iloc[:1], azure_2020.iloc[:1], others_2020])\nto_drop = ['None', 'Other']\ncommercial_2020 = commercial_2020[~commercial_2020['big data'].isin(to_drop)]\ncommercial_2020 = commercial_2020[['big data', 'Counts']]\n\nopen_source_2020 = open_source_2020.merge(commercial_2020, on = 'big data', how = 'outer')\nopen_source_2020 = open_source_2020.rename(columns = {'Counts_x' : 'open source_2020', 'Counts_y' : 'commercial_2020'})\n\nopen_source_2020 = open_source_2020.set_index('big data').T\n\n# -------------\n\ndf_count_bigdata_2019['big data'] = df_count_bigdata_2019['big data'].str.strip()\ndf_count_bigdata_2019['open source'] = df_count_bigdata_2019['big data'].apply(open_source)\ndf_count_bigdata_2019['aws'] = df_count_bigdata_2019['big data'].apply(aws)\ndf_count_bigdata_2019['gcp'] = df_count_bigdata_2019['big data'].apply(gcp)\ndf_count_bigdata_2019['azure'] = df_count_bigdata_2019['big data'].apply(azure)\n\nopen_source_2019 = df_count_bigdata_2019[df_count_bigdata_2019['open source'] == 1]\nopen_source_2019 = open_source_2019[['big data', 'Counts']]\n\naws_2019 = df_count_bigdata_2019[df_count_bigdata_2019['aws'] == 1]\ngcp_2019 = df_count_bigdata_2019[df_count_bigdata_2019['gcp'] == 1]\nazure_2019 = df_count_bigdata_2019[df_count_bigdata_2019['azure'] == 1]\nothers_2019 = df_count_bigdata_2019[(df_count_bigdata_2019['aws'] != 1) & \n                                    (df_count_bigdata_2019['gcp'] != 1) & \n                                    (df_count_bigdata_2019['azure'] != 1) &\n                                    (df_count_bigdata_2019['open source'] != 1)]\n\naws_2019['big data'].iloc[0] = 'aws'\ngcp_2019['big data'].iloc[0] = 'gcp'\nazure_2019['big data'].iloc[0] = 'azure'\n\ncommercial_2019 = aws_2019.iloc[:1].append([gcp_2019.iloc[:1], azure_2019.iloc[:1], others_2019])\nto_drop = ['None', 'Other']\ncommercial_2019 = commercial_2019[~commercial_2019['big data'].isin(to_drop)]\ncommercial_2019 = commercial_2019[['big data', 'Counts']]\n\nopen_source_2019 = open_source_2019.merge(commercial_2019, on = 'big data', how = 'outer')\nopen_source_2019 = open_source_2019.rename(columns = {'Counts_x' : 'open source_2019', 'Counts_y' : 'commercial_2019'})\n\nopen_source_2019 = open_source_2019.set_index('big data').T\n\nbig_data_usage = pd.concat([open_source_2021, open_source_2020, open_source_2019])\nbig_data_usage['PostgresSQL'] = big_data_usage['PostgresSQL'].fillna(big_data_usage['PostgreSQL'])\nbig_data_usage = big_data_usage.drop(['PostgreSQL'], axis = 1)\nbig_data_usage\n\n#fig, ax1 = plt.subplots(figsize = (16,8))\n#big_data_usage.plot(kind='bar', \n#              stacked=True,\n#              ax = ax1,\n#             )\n#ax1.set(title = \"big data\")","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:45.283814Z","iopub.execute_input":"2021-11-20T03:47:45.284107Z","iopub.status.idle":"2021-11-20T03:47:45.379787Z","shell.execute_reply.started":"2021-11-20T03:47:45.284066Z","shell.execute_reply":"2021-11-20T03:47:45.379213Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"big_data_usage[\"total\"] = big_data_usage.sum(axis=1)\nexample = big_data_usage['total']\nexample_2021 = example[:2]\nexample_2020 = example[2:4]\nexample_2019 = example[4:6]\n\nk_2021 = pd.DataFrame(example_2021)\nk_2021 = k_2021.rename(index = ({'open source_2021': 'open source', 'commercial_2021': 'commercial'}), columns=({'total': '2021'}))\n\n\nk_2020 = pd.DataFrame(example_2020)\nk_2020 = k_2020.rename(index = ({'open source_2020': 'open source', 'commercial_2020': 'commercial'}), columns=({'total': '2020'}))\n\n\n\nk_2019 = pd.DataFrame(example_2019)\nk_2019 = k_2019.rename(index = ({'open source_2019': 'open source', 'commercial_2019': 'commercial'}), columns=({'total': '2019'}))\n\nk_2021['2020'] = k_2020\nk_2021['2019'] = k_2019\nk_2021 = k_2021.iloc[:, ::-1]\nk_2021 = k_2021.T\n\nk_2021.plot(kind='bar', stacked = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:45.380718Z","iopub.execute_input":"2021-11-20T03:47:45.381367Z","iopub.status.idle":"2021-11-20T03:47:45.611481Z","shell.execute_reply.started":"2021-11-20T03:47:45.381332Z","shell.execute_reply":"2021-11-20T03:47:45.610626Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"big_data_usage.drop(['total'], axis = 1, inplace = True)\nbig_data_usage = big_data_usage.T\n\nbig_data_usage_open_source = big_data_usage[['open source_2021', 'open source_2020', 'open source_2019']]\nbig_data_usage_open_source.dropna(axis = 0, how = 'all', inplace = True)\n\nbig_data_usage_commercial = big_data_usage[['commercial_2021', 'commercial_2020', 'commercial_2019']]\nbig_data_usage_commercial.dropna(axis = 0, how = 'all', inplace = True)\n\nfig, axes = plt.subplots(1,3, figsize=(16,8))\nfor ax, col in zip(axes, big_data_usage_open_source.columns):\n    big_data_usage_open_source[col].plot(kind='pie', legend=False, ax=ax, autopct='%0.2f', title=col)\n    ax.set(ylabel='', aspect='equal')\n\naxes[0].legend(bbox_to_anchor=(0, 0.5))\n\n\nfig, axes = plt.subplots(1,3, figsize=(16,8))\nfor ax, col in zip(axes, big_data_usage_commercial.columns):\n    big_data_usage_commercial[col].plot(kind='pie', legend=False, ax=ax, autopct='%0.2f', title=col)\n    ax.set(ylabel='', aspect='equal')\n\naxes[0].legend(bbox_to_anchor=(0, 0.5))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:45.612834Z","iopub.execute_input":"2021-11-20T03:47:45.613079Z","iopub.status.idle":"2021-11-20T03:47:46.489511Z","shell.execute_reply.started":"2021-11-20T03:47:45.613051Z","shell.execute_reply":"2021-11-20T03:47:46.488618Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Business Intelligence","metadata":{}},{"cell_type":"code","source":"viz_bi_2020 =['Q14_Part_1','Q14_Part_2',\n              'Q14_Part_3','Q14_Part_4',\n              'Q14_Part_5','Q14_Part_6',\n              'Q14_Part_7','Q14_Part_8',\n              'Q14_Part_9','Q14_Part_10',\n              'Q14_Part_11','Q14_OTHER',\n              'Q31_A_Part_1','Q31_A_Part_2',\n              'Q31_A_Part_3','Q31_A_Part_4',\n              'Q31_A_Part_5','Q31_A_Part_6',\n              'Q31_A_Part_7','Q31_A_Part_8',\n              'Q31_A_Part_9','Q31_A_Part_10',\n              'Q31_A_Part_11','Q31_A_Part_12',\n              'Q31_A_Part_13','Q31_A_Part_14','Q31_A_OTHER']\n\nlib_BI_2020 = pros_2020[viz_bi_2020].rename(columns ={\n    'Q14_Part_1': 'Matplotlib',\n    'Q14_Part_2': 'Seaborn',\n    'Q14_Part_3': 'Plotly',\n    'Q14_Part_4': 'Ggplot',\n    'Q14_Part_5': 'Shiny',\n    'Q14_Part_6': 'D3 js',\n    'Q14_Part_7': 'Altair',\n    'Q14_Part_8': 'Bokeh',\n    'Q14_Part_9': 'Geoplotlib',\n    'Q14_Part_10': 'Leaflet',\n    'Q14_Part_11': 'None',\n    'Q14_OTHER': 'Other',\n    \n    'Q31_A_Part_1': 'Amazon QuickSight',\n    'Q31_A_Part_2': 'MS Power BI',\n    'Q31_A_Part_3': 'Google Data Studio',\n    'Q31_A_Part_4': 'Looker',\n    'Q31_A_Part_5': 'Tableau',\n    'Q31_A_Part_6': 'Salesforce',\n    'Q31_A_Part_7': 'Einstein Analytics',\n    'Q31_A_Part_8': 'Qlik',\n    'Q31_A_Part_9': 'Domo',\n    'Q31_A_Part_10': 'TIBCO',\n    'Q31_A_Part_11': 'Alteryx',\n    'Q31_A_Part_12': 'Sisense',\n    'Q31_A_Part_13': 'SAP',\n    'Q31_A_Part_14': 'None',\n    'Q31_A_OTHER': 'Other'\n})\n\nlib_2020 = ['Matplotlib',\n    'Seaborn',\n    'Plotly',\n    'Ggplot']\n\nBI_2020 = ['Amazon QuickSight',\n    'MS Power BI',\n    'Google Data Studio',\n    'Looker',\n    'Tableau',\n    'Salesforce',\n    'Einstein Analytics',\n    'Qlik',\n    'Domo',\n    'TIBCO',\n    'Alteryx',\n    'Sisense',\n    'SAP'\n    ]","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:46.491084Z","iopub.execute_input":"2021-11-20T03:47:46.491330Z","iopub.status.idle":"2021-11-20T03:47:46.505697Z","shell.execute_reply.started":"2021-11-20T03:47:46.491303Z","shell.execute_reply":"2021-11-20T03:47:46.504780Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"\n# ----- library growth -----\n\ndata_viz_li_2019 = ['Q20_Part_1',\n                    'Q20_Part_2',\n                    'Q20_Part_3',\n                    'Q20_Part_4',\n                    'Q20_Part_5',\n                    'Q20_Part_6',\n                    'Q20_Part_7',\n                    'Q20_Part_8',\n                    'Q20_Part_9',\n                    'Q20_Part_10',\n                    'Q20_Part_11',\n                    'Q20_Part_12']\n\ndf_data_viz_li_2019 = pros_2019[data_viz_li_2019]\n\n\ncount_data_viz_li_2019 = pd.Series(df_data_viz_li_2019[data_viz_li_2019].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_data_viz_li_2019 = pd.DataFrame(count_data_viz_li_2019)\ndf_count_data_viz_li_2019 = df_count_data_viz_li_2019.reset_index()\ndf_count_data_viz_li_2019.columns = ['lib', 'Counts']\ndf_count_data_viz_li_2019\n\n\ndata_viz_li_2020 =['Q14_Part_1','Q14_Part_2',\n              'Q14_Part_3','Q14_Part_4',\n              'Q14_Part_5','Q14_Part_6',\n              'Q14_Part_7','Q14_Part_8',\n              'Q14_Part_9','Q14_Part_10',\n              'Q14_Part_11','Q14_OTHER']\n\ndf_data_viz_li_2020 = pros_2020[data_viz_li_2020]\n\n\ncount_data_viz_li_2020 = pd.Series(df_data_viz_li_2020[data_viz_li_2020].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_data_viz_li_2020 = pd.DataFrame(count_data_viz_li_2020)\ndf_count_data_viz_li_2020 = df_count_data_viz_li_2020.reset_index()\ndf_count_data_viz_li_2020.columns = ['lib', 'Counts']\ndf_count_data_viz_li_2020\n\nviz_bi_2021 = ['Q14_Part_1','Q14_Part_2',\n                         'Q14_Part_3','Q14_Part_4',\n                         'Q14_Part_5','Q14_Part_6',\n                         'Q14_Part_7','Q14_Part_8',\n                         'Q14_Part_9','Q14_Part_10',\n                         'Q14_Part_11','Q14_OTHER']\n\ndf_data_viz_li_2021 = pros_2021[viz_bi_2021]\n\n\ncount_data_viz_li_2021 = pd.Series(df_data_viz_li_2021[viz_bi_2021].squeeze().values.ravel()).value_counts()\n#count_bigdata_2020\n\ndf_count_data_viz_li_2021 = pd.DataFrame(count_data_viz_li_2021)\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.reset_index()\ndf_count_data_viz_li_2021.columns = ['lib', 'Counts']\n\n# ---------------\n\n#print(df_count_data_viz_li_2021)\n#print(df_count_data_viz_li_2020)\n#print(df_count_data_viz_li_2019)\n\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.merge(df_count_data_viz_li_2020, on = 'lib', how = 'outer')\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.merge(df_count_data_viz_li_2019, on = 'lib', how = 'outer')\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.rename(columns = {'Counts_x' : '2021 ', 'Counts_y' : '2020', 'Counts': '2019'})\ndf_count_data_viz_li_2021.at[8,'lib'] = 'D3.js'\ndf_count_data_viz_li_2021.at[8,'2019'] = df_count_data_viz_li_2021.at[12,'2019']\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021[:-1]\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.set_index('lib').T\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021[::-1]\ndf_count_data_viz_li_2021 = df_count_data_viz_li_2021.drop(columns = ['None'])\n\ndf_count_data_viz_li_2021_perc = df_count_data_viz_li_2021.pct_change(periods = 1)[1:]\n\n# pct_change\ndata_viz_growth = pd.DataFrame()\ndata_viz_growth['total'] = df_count_data_viz_li_2021.sum(axis=1)\ndata_viz_growth_perc = data_viz_growth.pct_change(periods = 1)\n\n\navg_growth_2020 = round(data_viz_growth_perc.iloc[1].mean(),2)\navg_growth_2021 = round(data_viz_growth_perc.iloc[2].mean(),2)\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(22,8))\n\nplt.subplot(121)   #  subplot 1\n\ndf_count_data_viz_li_2021.plot(kind='bar', ax = ax1)\nax1.set(title = \"Visualization Library usage by professionals in kaggle survey\")\nax1.legend(loc=2, prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.2)\n\n\nplt.subplot(122)   #  subplot 2\n\ndf_count_data_viz_li_2021_perc.plot(kind = 'bar', ax=ax2)\nax2.legend(loc=4, prop={'size': 9})\nplt.axhline(y=0, xmin=-1, xmax= 2, color='red', linestyle='dotted', linewidth=5)\n\nplt.axhline(y=avg_growth_2020, xmin=0.05, xmax= 0.45, color='black', linestyle='dotted', linewidth=5)\nplt.axhline(y=avg_growth_2021, xmin=0.55, xmax= 0.95, color='black', linestyle='dotted', linewidth=5)\n\nax2.text(0.26, 0.08, 'Average growth rate ' +str(avg_growth_2020*100) + '%')\nax2.text(0.25, 0.35, 'Average growth rate '+ str(avg_growth_2021*100) + '%')\n\nax2.set(title = \"Visualization library usage growth rate compare to previous year\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:46.507329Z","iopub.execute_input":"2021-11-20T03:47:46.507615Z","iopub.status.idle":"2021-11-20T03:47:47.145029Z","shell.execute_reply.started":"2021-11-20T03:47:46.507585Z","shell.execute_reply":"2021-11-20T03:47:47.144402Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Covid related spike","metadata":{}},{"cell_type":"code","source":"viz_2021 = ['Q34_A_Part_1','Q34_A_Part_2',\n                    'Q34_A_Part_3','Q34_A_Part_4',\n                    'Q34_A_Part_5','Q34_A_Part_6',\n                    'Q34_A_Part_7','Q34_A_Part_8',\n                    'Q34_A_Part_9','Q34_A_Part_10',\n                    'Q34_A_Part_11','Q34_A_Part_12',\n                    'Q34_A_Part_13','Q34_A_Part_14',\n                    'Q34_A_Part_15','Q34_A_Part_16','Q34_A_OTHER']\ndf_viz_2021 = pd.Series(pros_2021[viz_2021].squeeze().values.ravel()).value_counts()\n    \ndf_count_viz_2021 = pd.DataFrame(df_viz_2021)\ndf_count_viz_2021 = df_count_viz_2021.reset_index()\ndf_count_viz_2021.columns = ['BI tools', '2021']\n\ndf_count_viz_2021 = df_count_viz_2021[1:] # Drop None\n\nviz_2020 = ['Q31_A_Part_1','Q31_A_Part_2',\n              'Q31_A_Part_3','Q31_A_Part_4',\n              'Q31_A_Part_5','Q31_A_Part_6',\n              'Q31_A_Part_7','Q31_A_Part_8',\n              'Q31_A_Part_9','Q31_A_Part_10',\n              'Q31_A_Part_11','Q31_A_Part_12',\n              'Q31_A_Part_13','Q31_A_Part_14','Q31_A_OTHER']\ndf_viz_2020 = pd.Series(pros_2020[viz_2020].squeeze().values.ravel()).value_counts()\n\ndf_count_viz_2020 = pd.DataFrame(df_viz_2020)\ndf_count_viz_2020 = df_count_viz_2020.reset_index()\ndf_count_viz_2020.columns = ['BI tools', '2020']\n\ndf_count_viz_2020 = df_count_viz_2020[1:] # Drop None\n\nmerged_viz = df_count_viz_2021.set_index('BI tools').combine_first(df_count_viz_2020.set_index('BI tools'))\nmerged_viz = merged_viz.sort_values(by=['2021'], ascending = False)\n\n# Clean Merged\n\nmerged_viz['2021'].iloc[0] = merged_viz['2021'].iloc[0] + merged_viz['2021'].iloc[6] # Tableau + Tableau CRM\nmerged_viz['2020'].iloc[4] = merged_viz['2020'].iloc[4] + merged_viz['2020'].iloc[16] # Salesforce + Einstein Analytics\nmerged_viz['2021'].iloc[1] = merged_viz['2021'].iloc[1] + merged_viz['2021'].iloc[7]\n\nmerged_viz = merged_viz.drop(merged_viz.index[[6,7,16]])[:-1]\n\nmerged_viz = merged_viz.T\n\n# Pct Change\nmerged_viz_perc = merged_viz.pct_change(periods = 1)[1:]\n\n# pct_change\ndata_bi_growth = pd.DataFrame()\ndata_bi_growth['total'] = merged_viz.sum(axis=1)\ndata_bi_growth = data_bi_growth.pct_change(periods = 1)\n\navg_growth_merged_2021 = round(data_bi_growth.iloc[1].mean(),2) # avg growth rate\n\n# --- plot ----\n\n\nfig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(22,8))\n\nplt.subplot(121)   #  subplot 1\n\nmerged_viz.plot(kind='bar', ax = ax1)\nax1.set(title = \"Commerical Business Intelligence tool usage by professionals in kaggle survey\")\nax1.legend(loc=1, prop={'size': 9})\n\nfig.subplots_adjust(wspace=0.2)\n\nplt.subplot(122)   #  subplot 2\n\nmerged_viz_perc.plot(kind='bar', ax=ax2)\nax2.set(title = \"Commerical Business Intelligence growth rate compare to previous year\")\nax2.legend(loc=1, prop={'size': 9})\n\nplt.axhline(y=avg_growth_merged_2021, xmin=0.2, xmax= 0.7, color='black', linestyle='dotted', linewidth=5)\n\nax2.text(-0.495, 0.52, 'Average growth rate ' +str(avg_growth_merged_2021*100) + '%')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:47.146198Z","iopub.execute_input":"2021-11-20T03:47:47.146663Z","iopub.status.idle":"2021-11-20T03:47:47.745904Z","shell.execute_reply.started":"2021-11-20T03:47:47.146633Z","shell.execute_reply":"2021-11-20T03:47:47.745254Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Commercial BI tool growth is higher than visualization library. Monetization of data analysis","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml_manage_2021 = ['Q38_A_Part_1','Q38_A_Part_2','Q38_A_Part_3',\n                  'Q38_A_Part_4','Q38_A_Part_5','Q38_A_Part_6',\n                  'Q38_A_Part_7','Q38_A_Part_8','Q38_A_Part_9',\n                  'Q38_A_Part_10','Q38_A_Part_11','Q38_A_OTHER']\n\ndf_ml_manage_2021 = pros_2021[ml_manage_2021]\n#df_ml_manage_2021 = df_ml_manage_2021.rename(columns={'Q38_A_Part_1': 'Neptune.ai',\n#                                                      'Q38_A_Part_2': 'Weights & Biases',\n#                                                      'Q38_A_Part_3': 'Comet.ml',\n#                                                      'Q38_A_Part_4': 'Sacred + Omniboard',\n#                                                      'Q38_A_Part_5': 'TensorBoard',\n#                                                      'Q38_A_Part_6': 'Guild.ai',\n#                                                      'Q38_A_Part_7': 'Polyaxon',\n#                                                      'Q38_A_Part_8': 'Trains',\n#                                                      'Q38_A_Part_9': 'Domino Model Monitor',\n#                                                      'Q38_A_Part_10': 'MLflow',\n#                                                      'Q38_A_Part_11': 'None',\n#                                                      'Q38_A_OTHER': 'Other'})\n\n\ncount_ml_manage_2021 = pd.Series(df_ml_manage_2021[ml_manage_2021].squeeze().values.ravel()).value_counts()\ndf_count_ml_manage_2021 = pd.DataFrame(count_ml_manage_2021)\ndf_count_ml_manage_2021 = df_count_ml_manage_2021.reset_index()\ndf_count_ml_manage_2021.columns = ['manage', '2021']\n\n\n# ------------\n\nml_manage_2020 = ['Q35_A_Part_1','Q35_A_Part_2',\n          'Q35_A_Part_3','Q35_A_Part_4',\n          'Q35_A_Part_5','Q35_A_Part_6',\n          'Q35_A_Part_7','Q35_A_Part_8','Q35_A_Part_9','Q35_A_Part_10','Q35_A_OTHER']\n\n\ndf_ml_manage_2020 = pros_2020[ml_manage_2020]\n\n\ncount_ml_manage_2020 = pd.Series(df_ml_manage_2020[ml_manage_2020].squeeze().values.ravel()).value_counts()\ndf_count_ml_manage_2020 = pd.DataFrame(count_ml_manage_2020)\ndf_count_ml_manage_2020 = df_count_ml_manage_2020.reset_index()\ndf_count_ml_manage_2020.columns = ['manage', '2020']\n\n#df = pd.concat([df_count_ml_manage_2021, df_count_ml_manage_2020], axis = 1)\n#df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\nmerged = df_count_ml_manage_2021.set_index('manage').combine_first(df_count_ml_manage_2020.set_index('manage'))\nmerged = merged.sort_values(by=['2021'], ascending = False)\nmerged = merged.iloc[1:, :]\n\nfig, ax = plt.subplots(figsize=(16,8))\n\nmerged.plot(kind='bar', ax=ax)\n\nax.set(title = \"Tools used to manage machine learning experiments\")\n\nax.annotate('Newly added', xy=(1.2, 1200), xytext=(2, 1300),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nax.annotate('Newly added', xy=(5.2, 260), xytext=(5.6, 300),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\n\nax.annotate('Removed', xy=(10.8, 260), xytext=(9.8, 350),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:47.746909Z","iopub.execute_input":"2021-11-20T03:47:47.747650Z","iopub.status.idle":"2021-11-20T03:47:48.280163Z","shell.execute_reply.started":"2021-11-20T03:47:47.747602Z","shell.execute_reply":"2021-11-20T03:47:48.279221Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"cloud_stocks = pd.read_excel('../input/cloud-apm-stocks/cloud_apm_stocks.xlsx')\n#cloud_stocks = cloud_stocks.rename(columns = {'Unnamed: 0': 'Revenue'})\ncloud_stocks = cloud_stocks.iloc[1:, :]\ncloud_stocks = cloud_stocks.set_index('Date')\ncloud_stocks = cloud_stocks.div(1000000000)\ncloud_stocks = cloud_stocks.rename(columns = \n                   {'DDOG.O (Fundamental)': 'DataDog',\n                    'NEWR.K (Fundamental)': 'New Relic',\n                    'DT (Fundamental)': 'Dynatrace',\n                    'ESTC.K (Fundamental)': 'Elastic NV',\n                    'CFLT.O (Fundamental)': 'CFLT'\n                   })\n\ncloud_stocks = cloud_stocks.drop(columns = ['CFLT'])\nfig, ax = plt.subplots(figsize=(18,6))\ncloud_stocks.plot(ax=ax)\n\nplt.xlabel('Date')\nplt.ylabel('Market cap (Billions)')\nplt.title('Application Performace Management(APM) companies market cap')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:48.281384Z","iopub.execute_input":"2021-11-20T03:47:48.281598Z","iopub.status.idle":"2021-11-20T03:47:48.715056Z","shell.execute_reply.started":"2021-11-20T03:47:48.281571Z","shell.execute_reply":"2021-11-20T03:47:48.713966Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"industry_gpu = ['Q20', 'Q12_Part_1']\nindustry_by_gpu = pros_2021[industry_gpu]\nindustry_by_gpu = industry_by_gpu[industry_by_gpu['Q20'].notna()]\n\nindustry_list = list(industry_by_gpu['Q20'].unique())\n\nind_gpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_gpu = industry_by_gpu.loc[industry_by_gpu['Q20'] == ind]\n    idx = pd.Series(ind_gpu['Q12_Part_1'].squeeze().values.ravel()).value_counts()\n    ind_gpu_merged[ind] = idx\n    \n    \nindustry_tpu = ['Q20', 'Q12_Part_2']\nindustry_by_tpu = pros_2021[industry_tpu]\nindustry_by_tpu = industry_by_tpu[industry_by_tpu['Q20'].notna()]\n\nind_tpu_merged = pd.DataFrame()\n\nfor idx, ind in enumerate(industry_list):\n    ind_tpu = industry_by_tpu.loc[industry_by_tpu['Q20'] == ind]\n    idx = pd.Series(ind_tpu['Q12_Part_2'].squeeze().values.ravel()).value_counts()\n    ind_tpu_merged[ind] = idx\n\nind_gpu_tpu = ind_gpu_merged.append(ind_tpu_merged).T\nind_gpu_tpu.columns = ind_gpu_tpu.columns.str.strip()\nind_gpu_tpu = ind_gpu_tpu.sort_values(by = 'NVIDIA GPUs', ascending = False)\n\nfig, ax = plt.subplots(figsize = (22,10))\nind_gpu_tpu.plot(kind = 'barh', ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:48.716616Z","iopub.execute_input":"2021-11-20T03:47:48.716926Z","iopub.status.idle":"2021-11-20T03:47:49.284929Z","shell.execute_reply.started":"2021-11-20T03:47:48.716866Z","shell.execute_reply":"2021-11-20T03:47:49.284062Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"hardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\nhardware_2021_df = pros_2021[hardware_2021]\ncount_hardware_2021 = pd.Series(hardware_2021_df[hardware_2021].squeeze().values.ravel()).value_counts()\n\nhardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\nhardware_2020_df = pros_2020[hardware_2020]\ncount_hardware_2020 = pd.Series(hardware_2020_df[hardware_2020].squeeze().values.ravel()).value_counts()\n\nhardware_2019 = ['Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5','Q21_OTHER_TEXT']\nhardware_2019_df = pros_2019[hardware_2019]\ncount_hardware_2019 = pd.Series(hardware_2019_df[hardware_2019].squeeze().values.ravel()).value_counts()\n\ndf_count_hardware_2021 = pd.DataFrame(count_hardware_2021)\ndf_count_hardware_2021 = df_count_hardware_2021.reset_index()\ndf_count_hardware_2021.columns = ['manage', '2021']\n\ndf_count_hardware_2020 = pd.DataFrame(count_hardware_2020)\ndf_count_hardware_2020 = df_count_hardware_2020.reset_index()\ndf_count_hardware_2020.columns = ['manage', '2020']\n\ndf_count_hardware_2019 = pd.DataFrame(count_hardware_2019)\ndf_count_hardware_2019 = df_count_hardware_2019.reset_index()\ndf_count_hardware_2019.columns = ['manage', '2019']\n\ndf_count_hardware_2019 = df_count_hardware_2019.iloc[1:6]\ndf_count_hardware_2019 = df_count_hardware_2019.set_index('manage').T[['GPUs', 'TPUs','Other']]\n\ndf_count_hardware_2020 = df_count_hardware_2020.set_index('manage').T[['GPUs', 'TPUs', 'Other']]\n\ndf_count_hardware_2021 = df_count_hardware_2021.set_index('manage').T\ndf_count_hardware_2021.columns = df_count_hardware_2021.columns.str.strip()\ndf_count_hardware_2021 = df_count_hardware_2021[['NVIDIA GPUs','Google Cloud TPUs','Other','AWS Inferentia Chips','AWS Trainium Chips']]\ndf_count_hardware_2021 = df_count_hardware_2021.rename(columns = {'NVIDIA GPUs': 'GPUs',\n                                                                    'Google Cloud TPUs': 'TPUs',\n                                                                    'Other': 'Other',\n                                                                    'AWS Inferentia Chips': 'AWS Inferentia',\n                                                                    'AWS Trainium Chips': 'AWS Trainium'})\n\ndf_hardware_merged = df_count_hardware_2019.append(df_count_hardware_2020).append(df_count_hardware_2021).fillna(0)\n\nfig, ax = plt.subplots(figsize=(18,6))\ndf_hardware_merged.plot(kind='bar', ax=ax)\nax.set(title = 'Special hardware usage trend',\n    xlabel = 'year',\n      ylabel = 'number of respondants',\n      )\n\nax.annotate(\"AWS's custom chips are added in 2021\", xy=(2.1, 1000), xytext=(2.3, 2000),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:49.286103Z","iopub.execute_input":"2021-11-20T03:47:49.286327Z","iopub.status.idle":"2021-11-20T03:47:49.877767Z","shell.execute_reply.started":"2021-11-20T03:47:49.286301Z","shell.execute_reply":"2021-11-20T03:47:49.876942Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 300)\npd.set_option('display.max_rows', 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:49.879947Z","iopub.execute_input":"2021-11-20T03:47:49.880475Z","iopub.status.idle":"2021-11-20T03:47:49.885032Z","shell.execute_reply.started":"2021-11-20T03:47:49.880428Z","shell.execute_reply":"2021-11-20T03:47:49.884127Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for q in questions_2020:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:49.890213Z","iopub.execute_input":"2021-11-20T03:47:49.890429Z","iopub.status.idle":"2021-11-20T03:47:49.938418Z","shell.execute_reply.started":"2021-11-20T03:47:49.890405Z","shell.execute_reply":"2021-11-20T03:47:49.935991Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"for q in questions_2019:\n    print(q)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T03:47:49.939582Z","iopub.execute_input":"2021-11-20T03:47:49.939804Z","iopub.status.idle":"2021-11-20T03:47:49.974497Z","shell.execute_reply.started":"2021-11-20T03:47:49.939780Z","shell.execute_reply":"2021-11-20T03:47:49.973488Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}